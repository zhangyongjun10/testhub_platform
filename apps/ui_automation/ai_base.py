import logging

logger = logging.getLogger('django')

import os

# ç¦ç”¨ browser-use é¥æµ‹
os.environ['ANONYMIZED_TELEMETRY'] = 'false'

import asyncio
import functools
import json
import re
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# ============================================================================
# PART 1: Common Patches (Pydantic, ActionModel, TokenCost, Basic Connection)
# ============================================================================

# Patch ChatOpenAI to allow setting attributes (required for browser-use token counting)
try:
    from pydantic import ConfigDict

    if hasattr(ChatOpenAI, 'model_config'):
        if isinstance(ChatOpenAI.model_config, dict):
            ChatOpenAI.model_config['extra'] = 'allow'
        else:
            ChatOpenAI.model_config = ConfigDict(extra='allow', arbitrary_types_allowed=True)
    else:
        ChatOpenAI.model_config = ConfigDict(extra='allow', arbitrary_types_allowed=True)
except ImportError:
    if hasattr(ChatOpenAI, 'model_config'):
        ChatOpenAI.model_config['extra'] = 'allow'

# ä¿®æ”¹ ActionModel é…ç½®ä»¥å…è®¸é¢å¤–å­—æ®µ
try:
    from browser_use.tools.registry.views import ActionModel
    from pydantic import ConfigDict

    ActionModel.model_config = ConfigDict(arbitrary_types_allowed=True, extra='allow')
    logger.info("âœ… Modified ActionModel.model_config to allow extra fields")
except Exception as e:
    logger.warning(f"âš ï¸ Failed to modify ActionModel config: {e}")

# Patch Agent.get_model_output æ–¹æ³•
try:
    from browser_use.agent.service import Agent
    from browser_use.agent.message_manager.service import AgentOutput
    import json as json_module

    _original_get_model_output = Agent.get_model_output


    async def _patched_get_model_output(self, input_messages):
        """ä¿®è¡¥åçš„ get_model_outputï¼Œç›´æ¥ä» response.content è§£æ JSON"""
        # logger.info("ğŸ”§ _patched_get_model_output called")

        if hasattr(self, '_task_was_done') and self._task_was_done:
            logger.info("ğŸ”§ Task was marked as done, stopping LLM interaction")
            raise KeyboardInterrupt("Task finished")

        kwargs = {'output_format': self.AgentOutput}

        # Add retry logic for LLM invocation with timeout
        max_retries = 2  # é‡è¯•æ¬¡æ•°ä¸º2æ¬¡
        last_exception = None
        response = None
        for attempt in range(max_retries):
            try:
                # æ·»åŠ è¶…æ—¶æ§åˆ¶ï¼Œè®¾ç½®ä¸º60ç§’ï¼ˆæ”¯æŒç¡…åŸºæµåŠ¨ç­‰å¤§æ¨¡å‹APIçš„å“åº”æ—¶é—´ï¼‰
                response = await asyncio.wait_for(
                    self.llm.ainvoke(input_messages, **kwargs),
                    timeout=60.0  # è¶…æ—¶æ—¶é—´60ç§’
                )
                break
            except asyncio.TimeoutError as te:
                last_exception = te
                logger.warning(f"âš ï¸ LLM invocation timed out (attempt {attempt + 1}/{max_retries}): {te}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(0.5)  # é‡è¯•é—´éš”0.5ç§’
            except Exception as e:
                last_exception = e
                logger.warning(f"âš ï¸ LLM invocation failed (attempt {attempt + 1}/{max_retries}): {e}")
                if attempt < max_retries - 1:
                    await asyncio.sleep(0.5)  # é‡è¯•é—´éš”0.5ç§’
        else:
            logger.error(f"âŒ LLM invocation failed after {max_retries} attempts.")
            raise last_exception

        # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©ºæˆ–æ— æ•ˆ
        if not response or not hasattr(response, 'content'):
            error_msg = "LLM returned invalid response (no content attribute)"
            logger.error(f"âŒ {error_msg}")
            raise ValueError(error_msg)

        # æ£€æŸ¥contentæ˜¯å¦ä¸ºç©ºå­—ç¬¦ä¸²
        content = response.content
        if not content or not isinstance(content, str) or not content.strip():
            error_msg = "LLM returned empty content - possible API error or timeout"
            logger.error(f"âŒ {error_msg}")
            raise ValueError(error_msg)

        try:
            if hasattr(response, 'content') and isinstance(response.content, str):
                content_dict = json_module.loads(response.content)

                # è§„èŒƒåŒ– action å­—å…¸
                if 'action' in content_dict:
                    normalized_actions = []
                    for action_dict in content_dict['action']:
                        normalized_action = {}
                        for action_name, action_params in action_dict.items():
                            # è‡ªåŠ¨ä¿®å¤: å°† int å‚æ•°è½¬æ¢ä¸º index å­—å…¸
                            if isinstance(action_params, int):
                                normalized_action[action_name] = {'index': action_params}
                            # è‡ªåŠ¨ä¿®å¤: switch_tab çš„ tab_id å­—ç¬¦ä¸²å‚æ•°
                            elif action_name == 'switch_tab' and isinstance(action_params, str) and not isinstance(
                                    action_params, dict):
                                normalized_action[action_name] = {'tab_id': action_params}
                            elif isinstance(action_params, dict):
                                normalized_params = {}
                                for k, v in action_params.items():
                                    if k == 'element_index':
                                        normalized_params['index'] = v
                                    else:
                                        normalized_params[k] = v
                                normalized_action[action_name] = normalized_params
                            else:
                                normalized_action[action_name] = action_params
                        normalized_actions.append(normalized_action)
                    content_dict['action'] = normalized_actions

                parsed = AgentOutput.model_construct(
                    thinking=content_dict.get('thinking'),
                    evaluation_previous_goal=content_dict.get('evaluation_previous_goal'),
                    memory=content_dict.get('memory'),
                    next_goal=content_dict.get('next_goal'),
                    action=[]
                )

                class _ActionWrapper:
                    def __init__(self, action_dict):
                        self._action_dict = action_dict

                    def model_dump(self, **kwargs):
                        return self._action_dict

                    def get_index(self):
                        for action_params in self._action_dict.values():
                            if isinstance(action_params, dict) and 'index' in action_params:
                                return action_params['index']
                        return None

                action_list = []
                for action_dict in content_dict.get('action', []):
                    action_list.append(_ActionWrapper(action_dict))

                object.__setattr__(parsed, 'action', action_list)

                if len(parsed.action) > self.settings.max_actions_per_step:
                    parsed.action = parsed.action[:self.settings.max_actions_per_step]

                return parsed
        except Exception as e:
            # If our complex normalization fails, fall back to the original method
            logger.warning(f"âš ï¸ Custom output normalization failed, falling back: {e}")
            return await _original_get_model_output(self, input_messages)


    Agent.get_model_output = _patched_get_model_output
    logger.info("âœ… Successfully patched Agent.get_model_output")
except Exception as e:
    logger.error(f"âŒ Failed to patch Agent.get_model_output: {e}")

# Patch TokenCost
try:
    from browser_use.tokens.service import TokenCost
    from langchain_core.messages import HumanMessage, SystemMessage as LangChainSystemMessage, AIMessage


    def _patched_register_llm(self, llm):
        """ä¿®è¡¥åçš„ register_llmï¼Œä¿®å¤ langchain å…¼å®¹æ€§"""
        instance_id = str(id(llm))
        if instance_id in self.registered_llms:
            return llm

        self.registered_llms[instance_id] = llm
        _original_ainvoke = llm.ainvoke
        _token_service = self

        async def _fixed_tracked_ainvoke(messages, output_format=None, **kwargs):
            # Sanitize message contents
            def _content_to_str(content):
                if isinstance(content, str): return content
                if isinstance(content, list):
                    parts = []
                    for item in content:
                        if isinstance(item, str):
                            parts.append(item)
                        elif isinstance(item, dict):
                            if 'text' in item:
                                parts.append(str(item['text']))
                            elif 'image' in item or 'image_url' in item:
                                parts.append("[image]")
                        else:
                            parts.append(str(item))
                    return "\n".join(parts)
                if isinstance(content, dict):
                    if 'text' in content: return str(content['text'])
                    if 'content' in content: return str(content['content'])
                    if 'image' in content or 'image_url' in content: return "[image]"
                return str(content)

            def _sanitize_message(msg):
                msg_type_name = type(msg).__name__
                content = getattr(msg, 'content', msg)
                content_str = _content_to_str(content)
                if msg_type_name == 'SystemMessage': return LangChainSystemMessage(content=content_str)
                if msg_type_name in ('HumanMessage', 'UserMessage'): return HumanMessage(content=content_str)
                if msg_type_name == 'AIMessage': return AIMessage(content=content_str)
                if isinstance(msg, (HumanMessage, LangChainSystemMessage, AIMessage)): return type(msg)(
                    content=content_str)
                return HumanMessage(content=str(content_str))

            sanitized_messages = [_sanitize_message(m) for m in messages]

            output_format = kwargs.pop('output_format', None)
            if output_format:
                kwargs['response_format'] = {"type": "json_object"}

            # Add retry logic for LLM invocation
            max_retries = 2  # é‡è¯•æ¬¡æ•°ä¸º2æ¬¡
            last_exception = None
            for attempt in range(max_retries):
                try:
                    result = await _original_ainvoke(sanitized_messages, **kwargs)
                    break
                except Exception as e:
                    last_exception = e
                    if "response_format" in str(e):
                        kwargs.pop('response_format', None)
                        # retry immediately without response_format
                        continue

                    logger.warning(f"âš ï¸ LLM ainvoke failed (attempt {attempt + 1}/{max_retries}): {e}")
                    if attempt < max_retries - 1:
                        await asyncio.sleep(0.5)  # ç­‰å¾…0.5ç§’
            else:
                logger.error(f"âŒ LLM ainvoke failed after {max_retries} attempts.")
                raise last_exception

            # Enhance response parsing
            import json as json_module
            clean_content = result.content.strip() if hasattr(result, 'content') else str(result).strip()

            # Remove Markdown
            if '```' in clean_content:
                match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', clean_content, re.DOTALL)
                if match:
                    clean_content = match.group(1).strip()
                else:
                    clean_content = re.sub(r'```[a-z]*', '', clean_content).replace('```', '').strip()

            parsed_data = None
            try:
                parsed_data = json_module.loads(clean_content)
            except:
                try:
                    match = re.search(r'(\{.*\})', clean_content, re.DOTALL)
                    if match: parsed_data = json_module.loads(match.group(1))
                except:
                    pass

            # Wrapper classes
            class _ActionWrapper:
                def __init__(self, action_dict):
                    self._dict = {}
                    for k, v in action_dict.items():
                        if isinstance(v, dict):
                            norm = {}
                            for subk, subv in v.items():
                                if subk == 'element_index':
                                    norm['index'] = subv
                                else:
                                    norm[subk] = subv
                            self._dict[k] = norm
                        else:
                            self._dict[k] = v
                    for k, v in self._dict.items(): setattr(self, k, v)

                def model_dump(self, **kwargs):
                    return self._dict

                def get_index(self):
                    for v in self._dict.values():
                        if isinstance(v, dict) and 'index' in v: return v['index']
                    return None

            # Construct AgentOutput manually
            agent_output = None
            if parsed_data and 'action' in parsed_data:
                # Normalize actions
                normalized_actions = []
                for action_dict in parsed_data['action']:
                    normalized_action = {}
                    for action_name, action_params in action_dict.items():
                        if isinstance(action_params, dict):
                            normalized_params = {}
                            for k, v in action_params.items():
                                if k == 'element_index':
                                    normalized_params['index'] = v
                                else:
                                    normalized_params[k] = v
                            normalized_action[action_name] = normalized_params
                        else:
                            normalized_action[action_name] = action_params
                    normalized_actions.append(normalized_action)
                parsed_data['action'] = normalized_actions

                try:
                    from browser_use.agent.message_manager.service import AgentOutput
                    agent_output = AgentOutput.model_construct(
                        thinking=parsed_data.get('thinking'),
                        evaluation_previous_goal=parsed_data.get('evaluation_previous_goal'),
                        memory=parsed_data.get('memory'),
                        next_goal=parsed_data.get('next_goal'),
                        action=[]
                    )
                    action_list = []
                    for action_dict in parsed_data.get('action', []):
                        action_list.append(_ActionWrapper(action_dict))
                    object.__setattr__(agent_output, 'action', action_list)
                except Exception as e:
                    logger.error(f"ğŸ”§ Failed to create AgentOutput: {e}")

            class _ResponseWrapper:
                def __init__(self, orig, completion_obj):
                    self._orig = orig
                    self.content = getattr(orig, 'content', '')
                    self.response_metadata = getattr(orig, 'response_metadata', {})
                    self.completion = completion_obj
                    usage = getattr(orig, 'usage', None) or (
                        orig.response_metadata.get('token_usage') if hasattr(orig, 'response_metadata') else None)
                    if not usage: usage = {}
                    # Fix usage
                    usage = dict(usage) if hasattr(usage, '__dict__') else usage
                    usage.setdefault('prompt_tokens', 0)
                    usage.setdefault('completion_tokens', 0)
                    usage.setdefault('total_tokens', 0)
                    self.usage = usage

                def __getattr__(self, name): return getattr(self._orig, name)

            wrapped = _ResponseWrapper(result, agent_output)
            if hasattr(wrapped, 'usage') and wrapped.usage:
                try:
                    _token_service.add_usage(llm.model, wrapped.usage)
                except:
                    pass

            return wrapped

        setattr(llm, 'ainvoke', _fixed_tracked_ainvoke)
        return llm


    TokenCost.register_llm = _patched_register_llm
    logger.info("âœ… Successfully patched TokenCost.register_llm")
except Exception as e:
    logger.error(f"âŒ Failed to patch TokenCost: {e}")

# Patch BrowserSession.connect (Windows CDP fix)
try:
    from browser_use.browser.session import BrowserSession
    import httpx

    _original_connect = BrowserSession.connect


    async def _patched_connect(self, cdp_url=None):
        if cdp_url: return await _original_connect(self, cdp_url=cdp_url)

        browser_profile = getattr(self, 'browser_profile', None)
        if hasattr(browser_profile, 'cdp_url') and browser_profile.cdp_url:
            return await _original_connect(self, cdp_url=browser_profile.cdp_url)

        port = 9222
        if hasattr(browser_profile, 'extra_chromium_args'):
            for arg in browser_profile.extra_chromium_args:
                if '--remote-debugging-port=' in str(arg):
                    try:
                        port = int(arg.split('=')[1]); break
                    except:
                        pass
        if hasattr(browser_profile, 'remote_debugging_port'):
            port = browser_profile.remote_debugging_port

        cdp_endpoint = f"http://localhost:{port}/json/version"

        for attempt in range(10): # å¢åŠ é‡è¯•æ¬¡æ•°
            try:
                async with httpx.AsyncClient(timeout=10.0) as client:
                    response = await client.get(cdp_endpoint)
                    if response.status_code == 200 and response.text:
                        version_info = response.json()
                        browser_profile.cdp_url = version_info['webSocketDebuggerUrl']
                        return await _original_connect(self, cdp_url=browser_profile.cdp_url)
            except Exception:
                if attempt < 4: await asyncio.sleep(1.0)

        return await _original_connect(self, cdp_url=cdp_url)


    BrowserSession.connect = _patched_connect
    logger.info("âœ… Successfully patched BrowserSession.connect")
except Exception as e:
    logger.error(f"âŒ Failed to patch BrowserSession.connect: {e}")

# Patch ClickElementAction parameters
try:
    from browser_use.tools.views import ClickElementAction

    _original_click_init = ClickElementAction.__init__


    def _patched_click_init(self, **kwargs):
        fixed_kwargs = {}
        for key, value in kwargs.items():
            if isinstance(value, int) and key not in ['index']:
                fixed_kwargs['index'] = value
            else:
                fixed_kwargs[key] = value
        if len(kwargs) == 1:
            key, value = list(kwargs.items())[0]
            if isinstance(value, int) and key != 'index':
                fixed_kwargs = {'index': value}
        try:
            return _original_click_init(self, **fixed_kwargs)
        except TypeError:
            if fixed_kwargs and isinstance(list(fixed_kwargs.values())[0], int):
                return _original_click_init(self, **{'index': list(fixed_kwargs.values())[0]})
            raise


    ClickElementAction.__init__ = _patched_click_init
except Exception:
    pass

# Patch ToolRegistry
try:
    from browser_use.tools.registry.service import Registry as ToolRegistry

    # Force patch Registry class
    _original_execute_action = ToolRegistry.execute_action


    async def _patched_execute_action(self, action_name: str, params: dict, **kwargs):
        # è‡ªåŠ¨æ˜ å°„ switch_tab -> switch (å¼ºåˆ¶æ˜ å°„)
        if action_name == 'switch_tab':
            logger.info(f"ğŸ”§ Force aliasing: switch_tab -> switch")
            action_name = 'switch'

        if isinstance(params, int):
            params = {'index': params}
        elif not isinstance(params, dict) and params is not None:
            # é’ˆå¯¹ switch_tab å¯èƒ½æ˜¯çº¯å­—ç¬¦ä¸²çš„æƒ…å†µ
            if action_name in ['switch_tab', 'switch']:
                params = {'tab_id': params}
            else:
                params = {'value': params} if params else {}

        # ğŸ”§ ä¿®å¤ input action çš„å‚æ•°æ ¼å¼ï¼šå°† content/value è½¬æ¢ä¸º text
        # é€‚é…ä¸åŒLLMæ¨¡å‹ç”Ÿæˆçš„å‚æ•°æ ¼å¼
        if action_name in ['input', 'input_text'] and isinstance(params, dict):
            # æ£€æŸ¥æ˜¯å¦æœ‰ content æˆ– value å­—æ®µï¼Œè½¬æ¢ä¸º text
            if 'text' not in params:
                if 'content' in params:
                    params['text'] = params.pop('content')
                    logger.info(f"ğŸ”§ Converted 'content' -> 'text' for input action: {params.get('index', '?')}")
                elif 'value' in params:
                    params['text'] = params.pop('value')
                    logger.info(f"ğŸ”§ Converted 'value' -> 'text' for input action: {params.get('index', '?')}")

        # é’ˆå¯¹ç‚¹å‡»å¢åŠ å»¶è¿Ÿï¼Œç¡®ä¿ UI æ›´æ–° (å¦‚å¼¹çª—å¼¹å‡ºã€ä¸‹æ‹‰æ¡†å±•å¼€)
        if action_name in ['click_element', 'click']:
            result = await _original_execute_action(self, action_name, params, **kwargs)
            # å¢åŠ å»¶è¿Ÿåˆ° 1.5sï¼Œå¹¶å¼ºåˆ¶åœ¨ç‚¹å‡»åç­‰å¾…æµè§ˆå™¨æ¸²æŸ“
            # å°¤å…¶æ˜¯å¯¹äº element-plus ç­‰ UI æ¡†æ¶ï¼Œä¸‹æ‹‰åˆ—è¡¨æ¸²æŸ“éœ€è¦æ—¶é—´
            await asyncio.sleep(1.5)
            return result

        return await _original_execute_action(self, action_name, params, **kwargs)


    ToolRegistry.execute_action = _patched_execute_action
    logger.info("âœ… Successfully patched ToolRegistry.execute_action with alias support")
except Exception as e:
    logger.error(f"âŒ Failed to patch ToolRegistry: {e}")

# Patch ScreenshotWatchdog GLOBALLY to fix timeouts
try:
    from browser_use.browser.watchdogs.screenshot_watchdog import ScreenshotWatchdog

    _original_on_screenshot_event = ScreenshotWatchdog.on_ScreenshotEvent

    # Check if already patched to avoid double patching
    if not getattr(_original_on_screenshot_event, '_is_patched_global', False):
        async def on_ScreenshotEvent(self, event):
            """
            Patched screenshot event handler with increased timeout and optimized parameters.
            """
            try:
                # Try original method first with strict timeout
                result = await asyncio.wait_for(
                    _original_on_screenshot_event(self, event),
                    timeout=3.0  # Reduced for fail-fast
                )
                return result
            except asyncio.TimeoutError:
                logger.warning(f"DEBUG: Watchdog timeout (3s), trying optimized approach...")
                try:
                    # Get CDP session
                    cdp_session = await self.browser_session.get_or_create_cdp_session(target_id=None)
                    if not cdp_session: raise Exception("Failed to get CDP session")

                    params = {'format': 'png', 'quality': 50, 'from_surface': True, 'capture_beyond_viewport': False}

                    # One quick retry
                    result = await asyncio.wait_for(
                        cdp_session.cdp_client.send.Page.captureScreenshot(params=params,
                                                                           session_id=cdp_session.session_id),
                        timeout=3.0
                    )
                    return result

                except Exception as ex:
                    # In Text Mode especially, we don't want to die on screenshot
                    logger.warning(f"DEBUG: Screenshot failed optimized, returning placeholder: {ex}")
                    import base64
                    # 1x1 transparent pixel
                    placeholder = base64.b64decode(
                        'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==')
                    return {'data': placeholder}
            except Exception as e:
                logger.error(f"DEBUG: Screenshot unexpected error: {e}")
                import base64
                placeholder = base64.b64decode(
                    'iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAADUlEQVR42mNk+M9QDwADhgGAWjR9awAAAABJRU5ErkJggg==')
                return {'data': placeholder}


        on_ScreenshotEvent._is_patched_global = True
        ScreenshotWatchdog.on_ScreenshotEvent = on_ScreenshotEvent
        logger.info("âœ… Applied Global ScreenshotWatchdog Patch")

    # Patch DOMWatchdog
    from browser_use.browser.watchdogs.dom_watchdog import DOMWatchdog

    _original_capture_clean_screenshot = DOMWatchdog._capture_clean_screenshot

    if not getattr(_original_capture_clean_screenshot, '_is_patched_global', False):
        async def _capture_clean_screenshot(self):
            try:
                # Very short timeout for DOM clean screenshot checks
                return await asyncio.wait_for(_original_capture_clean_screenshot(self), timeout=3.0)
            except Exception as e:
                logger.warning(f"DEBUG: Clean screenshot failed/timed out: {e}, continuing...")
                return None


        _capture_clean_screenshot._is_patched_global = True
        DOMWatchdog._capture_clean_screenshot = _capture_clean_screenshot
        logger.info("âœ… Applied Global DOMWatchdog Patch")

except Exception as e:
    logger.error(f"âŒ Failed to apply Global Watchdog patches: {e}")

# Patch Agent verdict
try:
    from browser_use.agent.service import Agent
    from browser_use.agent.message_manager.service import AgentOutput

    _original_judge_and_log = Agent._judge_and_log


    def _agent_output_getattr(self, name):
        if name == 'verdict':
            if hasattr(self, 'next_goal') and self.next_goal:
                if any(
                    w in str(self.next_goal).lower() for w in ['complete', 'done', 'finished', 'success']): return True
            if hasattr(self, 'evaluation_previous_goal') and self.evaluation_previous_goal:
                if any(w in str(self.evaluation_previous_goal).lower() for w in ['success', 'complete']): return True
            return False
        raise AttributeError(f"'{type(self).__name__}' object has no attribute '{name}'")


    if not hasattr(AgentOutput, '__getattr__'):
        AgentOutput.__getattr__ = _agent_output_getattr


    async def _patched_judge_and_log(self):
        try:
            return await _original_judge_and_log(self)
        except AttributeError as e:
            if 'verdict' in str(e):
                return None
            raise


    Agent._judge_and_log = _patched_judge_and_log
except Exception:
    pass

# Patch LocalBrowserWatchdog._find_free_port to force port 9222 on Linux
try:
    from browser_use.browser.watchdogs.local_browser_watchdog import LocalBrowserWatchdog
    import platform

    _original_find_free_port = LocalBrowserWatchdog._find_free_port

    # åˆ›å»ºè¡¥ä¸å‡½æ•° - å§‹ç»ˆä½œä¸ºå®ä¾‹æ–¹æ³•ï¼ˆæ¥å— selfï¼‰
    def _patched_find_free_port(self):
        if platform.system() == 'Linux':
            logger.info("ğŸ”§ Force using port 9222 for Linux environment")
            return 9222
        # å°è¯•è°ƒç”¨åŸå§‹æ–¹æ³•ï¼Œå…¼å®¹ä¸åŒç­¾å
        try:
            return _original_find_free_port(self)
        except TypeError:
            # å¦‚æœåŸå§‹æ–¹æ³•ä¸æ¥å— selfï¼Œå°è¯•ä¸å¸¦å‚æ•°è°ƒç”¨
            return _original_find_free_port()

    LocalBrowserWatchdog._find_free_port = _patched_find_free_port
    logger.info("âœ… Successfully patched LocalBrowserWatchdog._find_free_port")
except Exception as e:
    logger.error(f"âŒ Failed to patch LocalBrowserWatchdog._find_free_port: {e}")

# ============================================================================
# PART 2: Helper Classes
# ============================================================================

from langchain_core.callbacks import BaseCallbackHandler
from typing import Any


class RawResponseLogger(BaseCallbackHandler):
    def on_llm_new_token(self, token: str, **kwargs: Any) -> Any:
        pass

    def on_llm_end(self, response: Any, **kwargs: Any) -> Any:
        try:
            generation = response.generations[0][0]
            logger.info(f"DEBUG: Raw LLM Response: {generation.text}")
        except:
            pass


# ============================================================================
# PART 3: Base Browser Agent
# ============================================================================

from browser_use import Agent, Controller
from browser_use.browser.profile import BrowserProfile


class BaseBrowserAgent:
    def __init__(self, execution_mode='text', enable_gif=True, case_name=None):
        self.execution_mode = 'text'
        self.enable_gif = enable_gif  # GIFå½•åˆ¶å¼€å…³
        self.case_name = case_name or "Adhoc Task"  # ç”¨ä¾‹åç§°

        # Load Config from DB
        from apps.requirement_analysis.models import AIModelConfig

        # Select Config (always use text mode config)
        role_name = 'browser_use_text'
        config_obj = AIModelConfig.objects.filter(role=role_name, is_active=True).first()

        model_config = {}
        if config_obj:
            model_config = {
                'api_key': config_obj.api_key,
                'base_url': config_obj.base_url,
                'model_name': config_obj.model_name,
                'provider': config_obj.model_type,
                'temperature': config_obj.temperature  # è¯»å–é…ç½®çš„temperature
            }

        self.api_key = model_config.get('api_key') or os.getenv('AUTH_TOKEN')
        self.base_url = model_config.get('base_url') or os.getenv('BASE_URL')
        self.model_name = model_config.get('model_name') or os.getenv('MODEL_NAME')
        self.provider = model_config.get('provider', 'openai')

        if not self.api_key:
            raise ValueError(f"No API Key found for mode: {execution_mode}")

        # æ™ºèƒ½temperatureå¤„ç†ï¼šç‰¹æ®Šæ¨¡å‹å¼ºåˆ¶ä½¿ç”¨ç‰¹å®štemperatureå€¼
        # æ ¼å¼: {'æ¨¡å‹åç§°å…³é”®å­—': temperatureå€¼}
        special_model_temperature_map = {
            'kimi-2.5': 1.0,  # Moonshot AI Kimi 2.5 åªæ”¯æŒ temperature=1
            'kimi-k2.5': 1.0,  # Moonshot AI Kimi K2.5 åªæ”¯æŒ temperature=1
            'kimi': 1.0,  # é€šç”¨Kimiæ¨¡å‹åŒ¹é…ï¼ˆå…œåº•ï¼‰
            # æœªæ¥å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ å…¶ä»–ç‰¹æ®Šæ¨¡å‹ï¼Œä¾‹å¦‚ï¼š
            # 'claude-3.5-sonnet': 0.7,
            # 'gpt-4-turbo': 0.0,
        }

        # ç¡®å®šæœ€ç»ˆä½¿ç”¨çš„temperatureå€¼
        final_temperature = 0.0  # é»˜è®¤å€¼
        model_name_lower = self.model_name.lower()

        # 1. ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹æ®Šæ¨¡å‹
        for model_keyword, temp in special_model_temperature_map.items():
            if model_keyword in model_name_lower:
                final_temperature = temp
                logger.info(f"âœ… æ£€æµ‹åˆ°ç‰¹æ®Šæ¨¡å‹ '{self.model_name}'ï¼Œä½¿ç”¨å¼ºåˆ¶ temperature={temp}")
                break
        else:
            # 2. å¦‚æœä¸æ˜¯ç‰¹æ®Šæ¨¡å‹ï¼Œä½¿ç”¨é…ç½®ä¸­çš„å€¼
            if 'temperature' in model_config:
                final_temperature = model_config['temperature']
                logger.info(f"ğŸ“‹ ä½¿ç”¨é…ç½®çš„ temperature={final_temperature}")
            else:
                # 3. å¦‚æœé…ç½®ä¸­æ²¡æœ‰ï¼Œä½¿ç”¨é»˜è®¤å€¼
                final_temperature = 0.0
                logger.info(f"âš™ï¸ ä½¿ç”¨é»˜è®¤ temperature={final_temperature}")

        self.llm = ChatOpenAI(
            model=self.model_name,
            api_key=self.api_key,
            base_url=self.base_url,
            temperature=final_temperature,
            callbacks=[RawResponseLogger()]
        )

        # browser-use requirement
        try:
            object.__setattr__(self.llm, 'provider', self.provider)
            object.__setattr__(self.llm, 'model', self.model_name)
        except:
            if not hasattr(self.llm, '__pydantic_extra__') or self.llm.__pydantic_extra__ is None:
                self.llm.__pydantic_extra__ = {}
            self.llm.__pydantic_extra__['provider'] = self.provider
            self.llm.__pydantic_extra__['model'] = self.model_name

    def _format_action(self, action):
        try:
            action_dict = {}
            if hasattr(action, 'model_dump'):
                action_dict = action.model_dump()
            elif hasattr(action, '_action_dict'):
                action_dict = action._action_dict
            elif hasattr(action, '_dict'):
                action_dict = action._dict
            elif isinstance(action, dict):
                action_dict = action
            else:
                return str(action)

            if not action_dict: return "å¾…æœº"

            descriptions = []
            for name, params in action_dict.items():
                if not params and name not in ['scroll_down', 'scroll_up', 'done']: continue

                if name in ['go_to_url', 'navigate']:
                    url = params.get('url') if isinstance(params, dict) else params
                    descriptions.append(f"è®¿é—®: {url}")
                elif name in ['click_element', 'click']:
                    index = params.get('index') if isinstance(params, dict) else params
                    descriptions.append(f"ç‚¹å‡»[{index}]")
                elif name in ['input_text', 'input']:
                    text = params.get('text') if isinstance(params, dict) else None
                    descriptions.append(f"è¾“å…¥: '{text}'")
                elif name == 'switch_tab':
                    index = params.get('index', params)
                    descriptions.append(f"åˆ‡æ¢æ ‡ç­¾ {index}")
                elif name == 'open_new_tab':
                    url = params.get('url', params)
                    descriptions.append(f"æ–°æ ‡ç­¾æ‰“å¼€: {url}")
                elif name == 'done':
                    descriptions.append("ä»»åŠ¡å®Œæˆ")
                else:
                    descriptions.append(f"{name}")
            return " | ".join(descriptions)
        except:
            return "æ‰§è¡Œæ“ä½œ"

    async def analyze_task(self, task_description: str):
        try:
            prompt = f"Break down this task into steps: {task_description}. Return JSON list of strings."
            response = await self.llm.ainvoke(prompt)
            content = response.content.strip() if hasattr(response, 'content') else str(response)

            steps = []
            try:
                import json
                match = re.search(r'(\[.*\])', content, re.DOTALL)
                if match: steps = json.loads(match.group(1))
            except:
                pass

            if not steps:
                steps = [s.strip() for s in task_description.split('\n') if s.strip()]

            # å½»åº•æ¸…ç†ç”Ÿæˆçš„æ­¥éª¤æè¿°ä¸­çš„é‡å¤ç¼–å·
            cleaned_steps = []
            for s in steps:
                desc = s
                while True:
                    match = re.match(r'^\s*\d+[\.\sã€:]+(.*)', desc)
                    if not match: break
                    desc = match.group(1).strip()
                if desc:
                    cleaned_steps.append(desc)

            return [{'id': i + 1, 'description': s, 'status': 'pending'} for i, s in enumerate(cleaned_steps)]
        except:
            return [{'id': 1, 'description': task_description, 'status': 'pending'}]

    def _cleanup_zombie_chrome(self):
        """Clean up any existing Chrome processes on port 9222 (Linux only)"""
        import platform
        import psutil
        
        if platform.system() != 'Linux':
            return

        logger.info("ğŸ§¹ Cleaning up zombie Chrome processes...")
        cleaned_count = 0
        try:
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    # Check for chrome/chromium
                    if proc.info['name'] and ('chrome' in proc.info['name'] or 'chromium' in proc.info['name']):
                        # Check command line for port 9222
                        cmdline = proc.info.get('cmdline', [])
                        if cmdline and any('9222' in str(arg) for arg in cmdline):
                            logger.info(f"Killing zombie chrome pid={proc.pid}")
                            proc.kill()
                            cleaned_count += 1
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    pass
        except Exception as e:
            logger.warning(f"âš ï¸ Failed to cleanup zombie chrome: {e}")
        
        if cleaned_count > 0:
            logger.info(f"âœ… Cleaned up {cleaned_count} zombie Chrome processes")

    def _create_browser_profile(self):
        # Default implementation, can be overridden
        chrome_path = None
        import platform

        system = platform.system()
        if system == 'Windows':
            paths = [
                r"C:\Program Files\Google\Chrome\Application\chrome.exe",
                r"C:\Program Files (x86)\Google\Chrome\Application\chrome.exe",
                os.path.expanduser(r"~\AppData\Local\Google\Chrome\Application\chrome.exe")
            ]
            for p in paths:
                if os.path.exists(p):
                    chrome_path = p
                    break
        elif system == 'Linux':
            # Linux ç³»ç»Ÿå¸¸è§çš„ Chrome è·¯å¾„ - ä¼˜å…ˆä½¿ç”¨æˆ‘ä»¬é¢„è£…çš„æµè§ˆå™¨
            paths = [
                # ä¼˜å…ˆä½¿ç”¨Dockerå®¹å™¨ä¸­é¢„è£…çš„Chromium
                '/usr/bin/chromium-browser',
                '/usr/bin/chromium',
                '/usr/bin/google-chrome',
                # æ£€æŸ¥Playwrightå®‰è£…çš„æµè§ˆå™¨
                '/ms-playwright/chromium-*/chromium-linux/chromium',
                '/root/.cache/ms-playwright/chromium-*/chromium-linux/chromium',
                # å¤‡ç”¨è·¯å¾„
                '/usr/bin/google-chrome-stable',
                '/opt/google/chrome/chrome',
                '/snap/bin/chromium',
            ]
            for p in paths:
                # æ”¯æŒé€šé…ç¬¦è·¯å¾„
                if '*' in p:
                    import glob
                    matches = glob.glob(p)
                    if matches:
                        for match in matches:
                            if os.path.exists(match) and os.access(match, os.X_OK):
                                chrome_path = match
                                logger.info(f"æ‰¾åˆ°æµè§ˆå™¨: {chrome_path}")
                                break
                        if chrome_path:
                            break
                elif os.path.exists(p) and os.access(p, os.X_OK):
                    chrome_path = p
                    logger.info(f"æ‰¾åˆ°æµè§ˆå™¨: {chrome_path}")
                    break
            
            # å¦‚æœè¿˜æ˜¯æ²¡æ‰¾åˆ°ï¼Œå°è¯•æŸ¥æ‰¾Playwrightçš„é»˜è®¤è·¯å¾„æˆ–è®©browser-useè‡ªè¡Œå®‰è£…
            if not chrome_path:
                import glob
                playwright_paths = glob.glob('/ms-playwright/**/chromium', recursive=True)
                playwright_paths.extend(glob.glob('/root/.cache/ms-playwright/**/chromium', recursive=True))
                playwright_paths.extend(glob.glob('/ms-playwright/**/chromium-linux/chromium', recursive=True))
                playwright_paths.extend(glob.glob('/root/.cache/ms-playwright/**/chromium-linux/chromium', recursive=True))
                for p in playwright_paths:
                    if os.path.exists(p) and os.access(p, os.X_OK):
                        chrome_path = p
                        logger.info(f"é€šè¿‡Playwrightæ‰¾åˆ°æµè§ˆå™¨: {chrome_path}")
                        break
                
                # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆï¼šè®©browser-useè‡ªè¡Œå¤„ç†æµè§ˆå™¨å®‰è£…
                if not chrome_path:
                    logger.info("æœªæ‰¾åˆ°é¢„è£…æµè§ˆå™¨ï¼Œå°†è®©browser-useè‡ªåŠ¨å®‰è£…")
                    chrome_path = None  # è®©browser-useå¤„ç†

        # åŸºç¡€æ€§èƒ½ä¼˜åŒ–å‚æ•°
        extra_args = [
            '--disable-blink-features=AutomationControlled',
            '--disable-infobars', '--disable-notifications',
            '--disable-background-networking',
            '--disable-background-timer-throttling',
            '--disable-renderer-backgrounding',
            '--disable-backgrounding-occluded-windows',
            '--disable-extensions',
            '--disable-web-security',  # å…è®¸è·¨åŸŸè¯·æ±‚
        ]

        # æ ¹æ®æ“ä½œç³»ç»Ÿæ·»åŠ ç‰¹å®šå‚æ•°
        if system == 'Linux':
            # Linux æœåŠ¡å™¨ç¯å¢ƒï¼ˆç‰¹åˆ«æ˜¯æ— å¤´ç¯å¢ƒï¼‰å¿…éœ€çš„å‚æ•°
            extra_args.extend([
                '--no-sandbox',  # Linux å¿…éœ€ï¼šç¦ç”¨æ²™ç®±
                '--disable-setuid-sandbox',  # Linux å¿…éœ€ï¼šç¦ç”¨ setuid æ²™ç®±
                '--disable-dev-shm-usage',  # Linux å¿…éœ€ï¼šä½¿ç”¨ /tmp è€Œä¸æ˜¯ /dev/shm
                '--disable-gpu',  # ç¦ç”¨ GPU åŠ é€Ÿï¼ˆæœåŠ¡å™¨é€šå¸¸æ—  GPUï¼‰
                '--headless=new',  # Linux æœåŠ¡å™¨ä½¿ç”¨æ— å¤´æ¨¡å¼
                '--disable-software-rasterizer',  # ç¦ç”¨è½¯ä»¶å…‰æ …åŒ–å™¨
                '--remote-debugging-port=9222',  # ä½¿ç”¨å›ºå®šç«¯å£ï¼Œé¿å…éšæœºç«¯å£å¯¼è‡´è¿æ¥å¤±è´¥
                '--remote-debugging-address=0.0.0.0', # å…è®¸è¿œç¨‹è¿æ¥ï¼Œè€Œä¸ä»…ä»…æ˜¯ 127.0.0.1
                '--no-zygote',  # å‡å°‘è¿›ç¨‹æ•°
                '--single-process',  # å•è¿›ç¨‹æ¨¡å¼ï¼Œè™½ç„¶ä¸ç¨³å®šä½†èƒ½è§£å†³æŸäº› Docker ç¯å¢ƒä¸‹çš„ PID é—®é¢˜
            ])
        else:
            # macOS å’Œ Windows ä½¿ç”¨æ˜¾ç¤ºæ¨¡å¼
            extra_args.extend([
                '--no-sandbox',  # å…¼å®¹æ€§
                '--disable-gpu',
                '--remote-debugging-port=9222',
            ])

        return BrowserProfile(
            headless=(system == 'Linux'),  # Linux ä½¿ç”¨æ— å¤´æ¨¡å¼ï¼Œå…¶ä»–ç³»ç»Ÿä½¿ç”¨æ˜¾ç¤ºæ¨¡å¼
            disable_security=True,
            executable_path=chrome_path,
            args=extra_args,
            wait_for_network_idle_page_load_time=0.2,
            minimum_wait_page_load_time=0.05,
            wait_between_actions=0.1,
            enable_default_extensions=False
        )

    async def run_task(self, task_description: str, planned_tasks=None, callback=None, should_stop=None):
        # Cleanup potential zombie processes before starting
        self._cleanup_zombie_chrome()

        try:
            loop = asyncio.get_running_loop()
        except RuntimeError:
            loop = None

        controller = Controller()
        _task_was_done = False

        @controller.action('Done')
        async def done(success: bool = True, text: str = ""):
            nonlocal _task_was_done
            _task_was_done = True
            return f"Finished: {text}"

        @controller.action('mark_task_complete')
        async def mark_task_complete(task_id: int):
            logger.info(f"âœ… Explicitly marking task {task_id} as completed")
            if callback:
                try:
                    data = {'task_id': int(task_id), 'status': 'completed'}
                    if asyncio.iscoroutinefunction(callback):
                        await callback(data)
                    else:
                        callback(data)
                except Exception as e:
                    logger.warning(f"Failed to execute mark_task_complete callback: {e}")
            return f"Task {task_id} marked completed"

        # æ„å»ºå¼ºåŒ–ç‰ˆ Prompt
        final_task = task_description
        if planned_tasks:
            final_task += "\n\nIMPORTANT INSTRUCTION:\n"
            final_task += "You have a list of sub-tasks. Execute strictly in order.\n"
            final_task += "CRITICAL: MUST call 'mark_task_complete(task_id=...)' IMMEDIATELY after verifying each sub-task completion. NEVER skip this step. For every action you take, there MUST be a corresponding mark_task_complete call.\n"
            final_task += "IMPORTANT: If a sub-task (like opening a URL) is already fulfilled by the initial state, YOU MUST mark it complete in your VERY FIRST STEP.\n"
            final_task += "Sub-tasks (Execute in order):\n"
            cleaned_tasks = []
            for t in planned_tasks:
                desc = t['description']
                # é€’å½’å»é™¤æ‰€æœ‰å±‚çº§çš„é‡å¤åºå·ï¼Œä¾‹å¦‚ "1. 1. xxx" -> "xxx"
                while True:
                    match = re.match(r'^\s*\d+[\.\sã€:]+(.*)', desc)
                    if not match: break
                    desc = match.group(1).strip()
                cleaned_tasks.append(f"{t['id']}. {desc}")
            final_task += "\n".join(cleaned_tasks)

        # æé™æ•ˆç‡ç‰ˆæ ‡è®°æŒ‡ä»¤
        from datetime import datetime
        final_task += f"\n\nCURRENT TIME: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        final_task += "\nCRITICAL PERFORMANCE & SYNC RULES:\n"
        final_task += "1. ACTION-TASK MAPPING: For EVERY sub-task that requires an action (click, input, select), you MUST call 'mark_task_complete(task_id=...)' in the SAME STEP as that action. DO NOT skip any task ID. Example: After clicking a button for task 8, immediately call mark_task_complete(task_id=8). IF YOU PERFORM MULTIPLE ACTIONS IN ONE STEP, YOU MUST CALL mark_task_complete FOR EACH CORRESPONDING TASK.\n"
        final_task += "2. NO JAVASCRIPT IN INPUT: When a task asks for a timestamp, YOU MUST compute the final string yourself (e.g., 'V8.01734892400').\n"
        final_task += "   - DO NOT output 'Date.now()' or '{{...}}' strings. Use the CURRENT TIME provided above to estimate a timestamp.\n"
        final_task += "3. DROPDOWN & MODAL ISOLATION: If an action (clicking a button/dropdown) triggers a UI change (modal opens/dropdown expands), YOU MUST STOP and WAIT for the next step to see the new elements. DO NOT attempt to interact with newly appeared elements (like dropdown options) in the same step as the click that opened them.\n"
        final_task += "4. ULTRALIGHT THINKING: Keep 'thinking' under 10 words. Just list next actions. Merge multiple INPUTS if they are on the same form, but NEVER merge a UI-opening click with its subsequent interaction. SPEED IS CRITICAL - respond as quickly as possible.\n"
        final_task += "5. RETRY LOGIC: If a previous 'save' or 'submit' failed (e.g., error toast), RE-VERIFY all fields. Re-select dropdowns and re-input text to ensure the form is complete. Often errors are caused by missing project selection.\n"
        final_task += "6. DO NOT REPEAT: If a task is complete, mark it and MOVE ON. Don't re-confirm unless the system requires it.\n"
        final_task += "7. VERIFICATION: Task 15/16 usually require checking the list. Ensure you are on the correct page and the new data is visible before marking complete.\n"

        if 'qwen' in self.model_name.lower() or 'deepseek' in self.model_name.lower():
            final_task += "8. EXTREMELY MINIMIZE output tokens for speed. Keep responses as short as possible while maintaining accuracy.\n"

        # æ ¸å¿ƒä¿®å¤: æ¸…ç† task é•¿æ–‡æœ¬ä¸­çš„ URLï¼Œé˜²æ­¢ä¸­æ–‡æ ‡ç‚¹ç´§è´´ URL å¯¼è‡´ browser-use è§£æé”™è¯¯
        # ä¾‹å¦‚ "http://localhost:3000ï¼Œ" -> "http://localhost:3000 "
        try:
            # åœ¨ä¸­æ–‡æ ‡ç‚¹å‰åŠ ç©ºæ ¼ï¼Œé¿å…å®ƒä»¬æˆä¸º URL çš„ä¸€éƒ¨åˆ†
            final_task = re.sub(r'(https?://[^\s\u4e00-\u9fa5]+?)(?=[ï¼Œï¼›ã€‚ã€ï¼])', r'\1 ', final_task)
            logger.info(f"ğŸ”§ Optimized task description for URL extraction")
        except:
            pass

        browser_profile = self._create_browser_profile()

        agent = Agent(
            task=final_task,
            llm=self.llm,
            controller=controller,
            browser_profile=browser_profile,
            use_vision=False,
            max_actions_per_step=10,  # å¢åŠ æ­¥è¿›å¯†åº¦ï¼Œå‡å°‘æ€»æ­¥éª¤æ•°ï¼Œé™ä½è¶…æ—¶é£é™©
            max_retries=1,  # å‡å°‘é‡è¯•æ¬¡æ•°ä»¥æé«˜é€Ÿåº¦ (ä»2æ”¹ä¸º1)
            max_failures=2,  # å‡å°‘æœ€å¤§å¤±è´¥æ¬¡æ•°ï¼Œé¿å…è¿‡é•¿ç­‰å¾… (ä»é»˜è®¤3æ”¹ä¸º2)
            llm_timeout=60,  # è®¾ç½®LLMè°ƒç”¨è¶…æ—¶ä¸º60ç§’ï¼ˆæ”¯æŒç¡…åŸºæµåŠ¨ç­‰å¤§æ¨¡å‹APIï¼‰
            step_timeout=90,  # è®¾ç½®æ¯æ­¥è¶…æ—¶ä¸º90ç§’
            generate_gif=self.enable_gif,  # æ ¹æ®å¼€å…³å†³å®šæ˜¯å¦ç”ŸæˆGIF
        )
        agent._task_was_done = False

        # Callback helper - æ·»åŠ ä»»åŠ¡æ ‡è®°è·Ÿè¸ª
        last_processed_step = 0
        last_marked_task_id = 0  # è·Ÿè¸ªä¸Šä¸€æ¬¡æ ‡è®°çš„ä»»åŠ¡ID

        async def on_step_end(agent_instance):
            nonlocal last_processed_step, last_marked_task_id

            if should_stop:
                do_stop = await should_stop() if asyncio.iscoroutinefunction(should_stop) else should_stop()
                if do_stop: raise KeyboardInterrupt("User requested stop")

            if _task_was_done:
                raise KeyboardInterrupt("Done")

            history = getattr(agent_instance, 'history', [])
            if hasattr(history, 'history'): history = history.history

            if len(history) > last_processed_step:
                for i in range(last_processed_step, len(history)):
                    step = history[i]
                    # Log logic here
                    try:
                        actions = []
                        if hasattr(step, 'model_output') and hasattr(step.model_output, 'action'):
                            raw = step.model_output.action
                            actions = raw if isinstance(raw, list) else [raw]

                        # æ£€æŸ¥è¿™ä¸€æ­¥æ˜¯å¦è°ƒç”¨äº†mark_task_complete
                        step_has_task_complete = False
                        step_marked_task_id = None
                        for action in actions:
                            action_dict = action.model_dump() if hasattr(action, 'model_dump') else getattr(action,
                                                                                                            '_action_dict',
                                                                                                            {})
                            if 'mark_task_complete' in action_dict:
                                step_has_task_complete = True
                                step_marked_task_id = action_dict['mark_task_complete'].get('task_id')
                                last_marked_task_id = step_marked_task_id
                                break

                        # æ£€æŸ¥è¿™ä¸€æ­¥æ˜¯å¦æœ‰å®é™…æ“ä½œï¼ˆémark_task_completeçš„æ“ä½œï¼‰
                        has_real_action = False
                        for action in actions:
                            action_dict = action.model_dump() if hasattr(action, 'model_dump') else getattr(action,
                                                                                                            '_action_dict',
                                                                                                            {})
                            for key in action_dict.keys():
                                if key not in ['mark_task_complete', 'done']:
                                    has_real_action = True
                                    break
                            if has_real_action:
                                break

                        action_str = " | ".join([self._format_action(a) for a in actions])
                        log_content = f"\n[Step {i + 1}]\næ‰§è¡Œ: {action_str}\n"

                        if callback:
                            if asyncio.iscoroutinefunction(callback):
                                await callback({'type': 'log', 'content': log_content})
                            else:
                                callback({'type': 'log', 'content': log_content})

                        # å…³é”®ä¿®å¤ï¼šå¦‚æœè¿™ä¸€æ­¥æœ‰å®é™…æ“ä½œä½†æ²¡æœ‰è°ƒç”¨mark_task_completeï¼Œ
                        # ä¸”planned_tasksä¸­ä¸‹ä¸€ä¸ªæœªæ ‡è®°çš„ä»»åŠ¡IDåº”è¯¥è¢«æ ‡è®°
                        if has_real_action and not step_has_task_complete and planned_tasks:
                            # æ‰¾å‡ºä¸‹ä¸€ä¸ªåº”è¯¥æ ‡è®°çš„ä»»åŠ¡ID
                            next_expected_task_id = last_marked_task_id + 1
                            if next_expected_task_id <= len(planned_tasks):
                                # æ£€æŸ¥è¿™ä¸ªä»»åŠ¡æ˜¯å¦è¿˜æ²¡æœ‰è¢«æ ‡è®°
                                task_already_marked = False
                                for task in planned_tasks:
                                    if task['id'] == next_expected_task_id and task.get('status') == 'completed':
                                        task_already_marked = True
                                        break

                                if not task_already_marked:
                                    # è‡ªåŠ¨è¡¥å……æ ‡è®°è¿™ä¸ªä»»åŠ¡
                                    logger.warning(
                                        f"âš ï¸ Auto-fixing: Step {i + 1} had actions but no mark_task_complete. Auto-marking task {next_expected_task_id} as completed.")
                                    data = {'task_id': int(next_expected_task_id), 'status': 'completed'}
                                    if asyncio.iscoroutinefunction(callback):
                                        await callback(data)
                                    else:
                                        callback(data)
                                    last_marked_task_id = next_expected_task_id

                    except Exception as e:
                        logger.warning(f"âš ï¸ Error in on_step_end processing: {e}")
                last_processed_step = len(history)

        try:
            # Try to pass callback
            import inspect
            sig = inspect.signature(agent.run)
            if 'on_step_end' in sig.parameters:
                await agent.run(max_steps=100, on_step_end=on_step_end)
            else:
                await agent.run(max_steps=100)
        except KeyboardInterrupt:
            pass
        except Exception as e:
            logger.error(f"Agent execution error: {e}")
            raise

        # åœ¨ä»»åŠ¡ç»“æŸæ—¶æ£€æŸ¥ä¸ä¸€è‡´çš„ä»»åŠ¡çŠ¶æ€
        history = getattr(agent, 'history', [])
        if history:
            logger.info("ğŸ” Performing final task status consistency check")
            # æ£€æŸ¥æ˜¯å¦æœ‰ä»»åŠ¡æ‰§è¡Œäº†ä½†æœªæ ‡è®°å®Œæˆ
            executed_tasks_info = self._find_executed_tasks(history)
            if executed_tasks_info and executed_tasks_info.get('unmarked_actions'):
                logger.warning(
                    f"âš ï¸ Found {executed_tasks_info['executed_actions']} executed actions, but only {len(executed_tasks_info['marked_tasks'])} tasks were explicitly marked complete")
                logger.warning(f"âš ï¸ Unmarked actions: {executed_tasks_info['unmarked_actions']}")
                logger.warning("âš ï¸ This indicates the AI agent did not follow the 'mark_task_complete' rule properly.")

        return history

    def _find_executed_tasks(self, history):
        """
        é€šè¿‡åˆ†ææ‰§è¡Œå†å²æ‰¾å‡ºå·²æ‰§è¡Œä½†æœªæ ‡è®°å®Œæˆçš„ä»»åŠ¡
        """
        if not history or not hasattr(history, 'steps'):
            return []

        executed_actions = {}  # å·²æ‰§è¡Œçš„æ“ä½œç±»å‹å’Œç´¢å¼•ï¼Œä»¥åŠå¯¹åº”çš„æ­¥éª¤
        marked_tasks = set()  # å·²æ ‡è®°å®Œæˆçš„ä»»åŠ¡ID

        # åˆ†ææ‰§è¡Œå†å²
        for step_idx, step in enumerate(getattr(history, 'steps', [])):
            # æ£€æŸ¥æ¯ä¸€æ­¥ä¸­çš„actions
            actions = getattr(step, 'actions', [])
            for action in actions:
                # è®°å½•å·²æ‰§è¡Œçš„æ“ä½œ
                if hasattr(action, 'input'):
                    action_key = f"input_{action.input.index}"
                    executed_actions[action_key] = {
                        'step': step_idx,
                        'action': 'input',
                        'index': action.input.index
                    }
                elif hasattr(action, 'click'):
                    action_key = f"click_{action.click.index}"
                    executed_actions[action_key] = {
                        'step': step_idx,
                        'action': 'click',
                        'index': action.click.index
                    }
                elif hasattr(action, 'switch_tab'):
                    action_key = f"switch_tab_{action.switch_tab.tab_id}"
                    executed_actions[action_key] = {
                        'step': step_idx,
                        'action': 'switch_tab',
                        'tab_id': action.switch_tab.tab_id
                    }

                # è®°å½•å·²æ ‡è®°å®Œæˆçš„ä»»åŠ¡
                if hasattr(action, 'mark_task_complete'):
                    marked_tasks.add(action.mark_task_complete.task_id)

        # ç†æƒ³æƒ…å†µä¸‹åº”è¯¥æœ‰ä¸€ä¸ªæ˜ å°„æœºåˆ¶æ¥å…³è”æ“ä½œå’Œä»»åŠ¡ï¼Œä½†ç”±äºæˆ‘ä»¬æ²¡æœ‰è¿™ä¸ªæ˜ å°„ï¼Œ
        # æˆ‘ä»¬åªèƒ½è®°å½•æœªæ ‡è®°å®Œæˆçš„æ‰§è¡Œæ“ä½œä½œä¸ºè°ƒè¯•ä¿¡æ¯
        unmarked_actions = []
        for action_key, action_info in executed_actions.items():
            unmarked_actions.append({
                'action': action_info['action'],
                'step': action_info['step'],
                'details': action_key
            })

        return {
            'marked_tasks': list(marked_tasks),
            'executed_actions': len(executed_actions),
            'unmarked_actions': unmarked_actions
        }

    async def run_full_process(self, task_description: str, analysis_callback=None, step_callback=None,
                               should_stop=None):
        planned_tasks = await self.analyze_task(task_description)
        if analysis_callback:
            if asyncio.iscoroutinefunction(analysis_callback):
                await analysis_callback(planned_tasks)
            else:
                analysis_callback(planned_tasks)

        return await self.run_task(task_description, planned_tasks, step_callback, should_stop)
