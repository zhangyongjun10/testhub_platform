import asyncio
import logging
import re
import os  # Added import
import json
import time
from rest_framework import viewsets, status
from django.conf import settings  # Added import
from rest_framework.decorators import action, permission_classes
from rest_framework.response import Response
from rest_framework.renderers import BaseRenderer
from rest_framework.permissions import AllowAny


class PassThroughRenderer(BaseRenderer):
    """ç›´æ¥é€ä¼ StreamingHttpResponseï¼Œä¸è¿›è¡Œä»»ä½•æ¸²æŸ“å¤„ç†"""
    media_type = 'text/event-stream'
    format = 'event-stream'
    render_level = 0

    def render(self, data, accepted_media_type=None, renderer_context=None):
        # ç›´æ¥è¿”å›dataï¼Œä¸åšä»»ä½•å¤„ç†
        return data


from rest_framework.parsers import MultiPartParser, FormParser
from django.http import JsonResponse, StreamingHttpResponse
from django.views.decorators.csrf import csrf_exempt
from django.utils.decorators import method_decorator
from django.utils import timezone
from asgiref.sync import sync_to_async
from django.db import models

from .models import (
    RequirementDocument, RequirementAnalysis, BusinessRequirement,
    GeneratedTestCase, AnalysisTask, AIModelConfig, PromptConfig, TestCaseGenerationTask,
    GenerationConfig, AIModelService
)
from .serializers import (
    RequirementDocumentSerializer, RequirementAnalysisSerializer,
    BusinessRequirementSerializer, GeneratedTestCaseSerializer,
    AnalysisTaskSerializer, DocumentUploadSerializer,
    TestCaseGenerationRequestSerializer, TestCaseReviewRequestSerializer,
    AIModelConfigSerializer, PromptConfigSerializer, TestCaseGenerationTaskSerializer,
    GenerationConfigSerializer
)
from .services import RequirementAnalysisService, DocumentProcessor

logger = logging.getLogger(__name__)


class RequirementDocumentViewSet(viewsets.ModelViewSet):
    """éœ€æ±‚æ–‡æ¡£è§†å›¾é›†"""
    queryset = RequirementDocument.objects.all()
    serializer_class = RequirementDocumentSerializer
    parser_classes = [MultiPartParser, FormParser]

    def get_serializer_class(self):
        if self.action == 'create':
            return DocumentUploadSerializer
        return RequirementDocumentSerializer

    @action(detail=True, methods=['post'])
    def analyze(self, request, pk=None):
        """åˆ†æéœ€æ±‚æ–‡æ¡£"""
        document = self.get_object()

        if document.status == 'analyzing':
            return Response(
                {'error': 'æ–‡æ¡£æ­£åœ¨åˆ†æä¸­ï¼Œè¯·ç¨åå†è¯•'},
                status=status.HTTP_400_BAD_REQUEST
            )

        if document.status == 'analyzed':
            return Response(
                {'message': 'æ–‡æ¡£å·²ç»åˆ†æè¿‡äº†', 'analysis_id': document.analysis.id},
                status=status.HTTP_200_OK
            )

        try:
            # æ›´æ–°çŠ¶æ€ä¸ºåˆ†æä¸­
            document.status = 'analyzing'
            document.save()

            # å¼‚æ­¥æ‰§è¡Œåˆ†æ
            def run_analysis():
                try:
                    # ç®€åŒ–ç‰ˆåŒæ­¥åˆ†æ
                    # æå–æ–‡æ¡£æ–‡æœ¬
                    if not document.extracted_text:
                        document.extracted_text = DocumentProcessor.extract_text(document)
                        document.save()

                    # åˆ›å»ºæ¨¡æ‹Ÿåˆ†æç»“æœ
                    analysis_result = {
                        'analysis_report': f'å¯¹æ–‡æ¡£"{document.title}"çš„éœ€æ±‚åˆ†æå·²å®Œæˆã€‚\n\næ–‡æ¡£å†…å®¹ï¼š{document.extracted_text[:200]}...\n\nè¯†åˆ«åˆ°è‹¥å¹²åŠŸèƒ½æ€§éœ€æ±‚ã€‚',
                        'requirements_count': 2,
                        'requirements': [
                            {
                                'requirement_id': 'REQ001',
                                'requirement_name': 'åŸºç¡€åŠŸèƒ½éœ€æ±‚',
                                'requirement_type': 'functional',
                                'module': 'æ ¸å¿ƒæ¨¡å—',
                                'requirement_level': 'high',
                                'estimated_hours': 8,
                                'description': 'åŸºäºæ–‡æ¡£å†…å®¹è¯†åˆ«çš„åŠŸèƒ½éœ€æ±‚',
                                'acceptance_criteria': 'åŠŸèƒ½æ­£å¸¸è¿è¡Œï¼Œæ»¡è¶³ç”¨æˆ·éœ€æ±‚'
                            },
                            {
                                'requirement_id': 'REQ002',
                                'requirement_name': 'ç”¨æˆ·äº¤äº’éœ€æ±‚',
                                'requirement_type': 'usability',
                                'module': 'å‰ç«¯æ¨¡å—',
                                'requirement_level': 'medium',
                                'estimated_hours': 6,
                                'description': 'ç”¨æˆ·ç•Œé¢å’Œäº¤äº’ç›¸å…³éœ€æ±‚',
                                'acceptance_criteria': 'ç•Œé¢å‹å¥½ï¼Œæ“ä½œç®€å•'
                            }
                        ]
                    }

                    # åˆ›å»ºåˆ†æè®°å½•
                    analysis = RequirementAnalysis.objects.create(
                        document=document,
                        analysis_report=analysis_result['analysis_report'],
                        requirements_count=analysis_result['requirements_count'],
                        analysis_time=2.5
                    )

                    # ä¿å­˜éœ€æ±‚æ•°æ®
                    for req_data in analysis_result['requirements']:
                        BusinessRequirement.objects.create(
                            analysis=analysis,
                            **req_data
                        )

                    # æ›´æ–°æ–‡æ¡£çŠ¶æ€
                    document.status = 'analyzed'
                    document.save()

                    return analysis

                except Exception as e:
                    logger.error(f"åˆ†æå¤±è´¥: {e}")
                    document.status = 'failed'
                    document.save()
                    raise e

            analysis = run_analysis()

            return Response({
                'message': 'åˆ†æå®Œæˆ',
                'analysis_id': analysis.id,
                'requirements_count': analysis.requirements_count
            }, status=status.HTTP_200_OK)

        except Exception as e:
            logger.error(f"åˆ†ææ–‡æ¡£æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'åˆ†æå¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['get'])
    def extract_text(self, request, pk=None):
        """æå–æ–‡æ¡£æ–‡æœ¬"""
        document = self.get_object()

        try:
            if not document.extracted_text:
                text = DocumentProcessor.extract_text(document)
                document.extracted_text = text
                document.save()

            return Response({
                'extracted_text': document.extracted_text,
                'text_length': len(document.extracted_text)
            }, status=status.HTTP_200_OK)

        except Exception as e:
            logger.error(f"æå–æ–‡æœ¬æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'æå–æ–‡æœ¬å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )


class RequirementAnalysisViewSet(viewsets.ReadOnlyModelViewSet):
    """éœ€æ±‚åˆ†æè§†å›¾é›†"""
    queryset = RequirementAnalysis.objects.all()
    serializer_class = RequirementAnalysisSerializer

    @action(detail=True, methods=['get'])
    def requirements(self, request, pk=None):
        """è·å–åˆ†æçš„éœ€æ±‚åˆ—è¡¨"""
        analysis = self.get_object()
        requirements = analysis.requirements.all()
        serializer = BusinessRequirementSerializer(requirements, many=True)
        return Response(serializer.data)


class BusinessRequirementViewSet(viewsets.ReadOnlyModelViewSet):
    """ä¸šåŠ¡éœ€æ±‚è§†å›¾é›†"""
    queryset = BusinessRequirement.objects.all()
    serializer_class = BusinessRequirementSerializer

    def get_queryset(self):
        queryset = super().get_queryset()
        analysis_id = self.request.query_params.get('analysis_id')
        if analysis_id:
            queryset = queryset.filter(analysis_id=analysis_id)
        return queryset

    @classmethod
    def _generate_test_case_content(cls, requirement, case_number, test_level):
        """æ ¹æ®éœ€æ±‚ç±»å‹å’Œåºå·ç”Ÿæˆä¸åŒçš„æµ‹è¯•ç”¨ä¾‹å†…å®¹"""

        # åŸºç¡€æµ‹è¯•åœºæ™¯æ¨¡æ¿
        test_scenarios = {
            1: {
                'type': 'æ­£å¸¸è·¯å¾„æµ‹è¯•',
                'focus': 'åŸºæœ¬åŠŸèƒ½éªŒè¯',
                'steps_template': [
                    "å‡†å¤‡æµ‹è¯•ç¯å¢ƒå’Œæ•°æ®",
                    "æ‰§è¡Œæ­£å¸¸ä¸šåŠ¡æµç¨‹",
                    "éªŒè¯åŠŸèƒ½æ‰§è¡Œç»“æœ",
                    "æ£€æŸ¥ç³»ç»ŸçŠ¶æ€"
                ]
            },
            2: {
                'type': 'å¼‚å¸¸è·¯å¾„æµ‹è¯•',
                'focus': 'å¼‚å¸¸æƒ…å†µå¤„ç†',
                'steps_template': [
                    "å‡†å¤‡å¼‚å¸¸æµ‹è¯•æ•°æ®",
                    "è§¦å‘å¼‚å¸¸ä¸šåŠ¡åœºæ™¯",
                    "éªŒè¯å¼‚å¸¸å¤„ç†æœºåˆ¶",
                    "ç¡®è®¤ç³»ç»ŸçŠ¶æ€æ­£å¸¸"
                ]
            },
            3: {
                'type': 'è¾¹ç•Œå€¼æµ‹è¯•',
                'focus': 'è¾¹ç•Œæ¡ä»¶éªŒè¯',
                'steps_template': [
                    "è®¾ç½®è¾¹ç•Œå€¼æµ‹è¯•æ¡ä»¶",
                    "æ‰§è¡Œè¾¹ç•Œå€¼æ“ä½œ",
                    "éªŒè¯è¾¹ç•Œå€¼å¤„ç†",
                    "æ£€æŸ¥ç»“æœå‡†ç¡®æ€§"
                ]
            },
            4: {
                'type': 'æ€§èƒ½æµ‹è¯•',
                'focus': 'æ€§èƒ½æŒ‡æ ‡éªŒè¯',
                'steps_template': [
                    "é…ç½®æ€§èƒ½æµ‹è¯•ç¯å¢ƒ",
                    "æ‰§è¡Œæ€§èƒ½æµ‹è¯•æ“ä½œ",
                    "ç›‘æ§æ€§èƒ½æŒ‡æ ‡",
                    "éªŒè¯æ€§èƒ½è¦æ±‚"
                ]
            },
            5: {
                'type': 'å®‰å…¨æµ‹è¯•',
                'focus': 'å®‰å…¨æœºåˆ¶éªŒè¯',
                'steps_template': [
                    "è®¾ç½®å®‰å…¨æµ‹è¯•ç¯å¢ƒ",
                    "æ‰§è¡Œå®‰å…¨ç›¸å…³æ“ä½œ",
                    "éªŒè¯å®‰å…¨æ§åˆ¶æœºåˆ¶",
                    "ç¡®è®¤å®‰å…¨åˆè§„æ€§"
                ]
            }
        }

        # å¾ªç¯ä½¿ç”¨æµ‹è¯•åœºæ™¯
        scenario_key = ((case_number - 1) % 5) + 1
        scenario = test_scenarios[scenario_key]

        # æ ¹æ®éœ€æ±‚åç§°ç”Ÿæˆå…·ä½“å†…å®¹
        req_name = requirement.requirement_name
        req_module = requirement.module
        req_type = requirement.requirement_type

        # ç”Ÿæˆæ ‡é¢˜
        title = f"{req_name} - {scenario['type']}ç”¨ä¾‹"

        # ç”Ÿæˆå‰ç½®æ¡ä»¶
        if "ç™»å½•" in req_name:
            precondition = f"1. ç³»ç»Ÿæ­£å¸¸è¿è¡Œ\n2. æµ‹è¯•ç”¨æˆ·è´¦å·å·²å‡†å¤‡\n3. {req_module}æ¨¡å—å¯è®¿é—®"
        elif "æ•°æ®" in req_name:
            precondition = f"1. ç³»ç»Ÿæ­£å¸¸è¿è¡Œ\n2. æ•°æ®åº“è¿æ¥æ­£å¸¸\n3. æµ‹è¯•æ•°æ®å·²å‡†å¤‡\n4. {req_module}æ¨¡å—å¯è®¿é—®"
        elif "æ”¯ä»˜" in req_name:
            precondition = f"1. ç³»ç»Ÿæ­£å¸¸è¿è¡Œ\n2. æ”¯ä»˜æ¥å£è¿æ¥æ­£å¸¸\n3. æµ‹è¯•è´¦æˆ·ä½™é¢å……è¶³\n4. {req_module}æ¨¡å—å¯è®¿é—®"
        else:
            precondition = f"1. ç³»ç»Ÿæ­£å¸¸è¿è¡Œ\n2. ç”¨æˆ·å·²ç™»å½•ç³»ç»Ÿ\n3. {req_module}æ¨¡å—å¯è®¿é—®\n4. ç›¸å…³æƒé™å·²é…ç½®"

        # ç”Ÿæˆæµ‹è¯•æ­¥éª¤
        steps = []
        for i, step_template in enumerate(scenario['steps_template'], 1):
            if "ç™»å½•" in req_name:
                if i == 1:
                    steps.append(f"{i}. æ‰“å¼€ç™»å½•é¡µé¢ï¼Œå‡†å¤‡æµ‹è¯•ç”¨æˆ·å‡­è¯")
                elif i == 2:
                    if scenario_key == 1:
                        steps.append(f"{i}. è¾“å…¥æ­£ç¡®çš„ç”¨æˆ·åå’Œå¯†ç ï¼Œç‚¹å‡»ç™»å½•")
                    elif scenario_key == 2:
                        steps.append(f"{i}. è¾“å…¥é”™è¯¯çš„ç”¨æˆ·åæˆ–å¯†ç ï¼Œç‚¹å‡»ç™»å½•")
                    else:
                        steps.append(f"{i}. æ‰§è¡Œ{scenario['focus']}ç›¸å…³çš„ç™»å½•æ“ä½œ")
                elif i == 3:
                    steps.append(f"{i}. éªŒè¯ç™»å½•ç»“æœå’Œé¡µé¢è·³è½¬")
                else:
                    steps.append(f"{i}. æ£€æŸ¥ç”¨æˆ·ç™»å½•çŠ¶æ€å’Œç³»ç»Ÿå“åº”")
            elif "æ•°æ®" in req_name:
                if i == 1:
                    steps.append(f"{i}. è¿›å…¥{req_module}ï¼Œå‡†å¤‡æ•°æ®æ“ä½œ")
                elif i == 2:
                    if scenario_key == 1:
                        steps.append(f"{i}. æ‰§è¡Œæ­£å¸¸çš„æ•°æ®å½•å…¥/æŸ¥è¯¢æ“ä½œ")
                    elif scenario_key == 2:
                        steps.append(f"{i}. æ‰§è¡Œå¼‚å¸¸æ•°æ®æ“ä½œï¼ˆå¦‚æ ¼å¼é”™è¯¯ã€è¶…é•¿æ•°æ®ç­‰ï¼‰")
                    else:
                        steps.append(f"{i}. æ‰§è¡Œ{scenario['focus']}ç›¸å…³çš„æ•°æ®æ“ä½œ")
                elif i == 3:
                    steps.append(f"{i}. éªŒè¯æ•°æ®æ“ä½œç»“æœå’Œå®Œæ•´æ€§")
                else:
                    steps.append(f"{i}. æ£€æŸ¥æ•°æ®çŠ¶æ€å’Œç³»ç»Ÿå“åº”")
            else:
                steps.append(f"{i}. {step_template}ï¼ˆé’ˆå¯¹{req_name}ï¼‰")

        test_steps = "\n".join(steps)

        # ç”Ÿæˆé¢„æœŸç»“æœ
        if scenario_key == 1:  # æ­£å¸¸è·¯å¾„
            expected_result = f"{req_name}åŠŸèƒ½æ­£å¸¸æ‰§è¡Œï¼Œæ»¡è¶³ä¸šåŠ¡éœ€æ±‚ï¼Œç³»ç»Ÿå“åº”æ­£ç¡®"
        elif scenario_key == 2:  # å¼‚å¸¸è·¯å¾„
            expected_result = f"ç³»ç»Ÿæ­£ç¡®å¤„ç†å¼‚å¸¸æƒ…å†µï¼Œç»™å‡ºé€‚å½“æç¤ºï¼Œ{req_name}åŠŸèƒ½ä¿æŒç¨³å®š"
        elif scenario_key == 3:  # è¾¹ç•Œå€¼
            expected_result = f"{req_name}åœ¨è¾¹ç•Œæ¡ä»¶ä¸‹æ­£å¸¸å·¥ä½œï¼Œæ•°æ®å¤„ç†å‡†ç¡®ï¼Œæ— å¼‚å¸¸é”™è¯¯"
        elif scenario_key == 4:  # æ€§èƒ½æµ‹è¯•
            expected_result = f"{req_name}æ€§èƒ½æ»¡è¶³è¦æ±‚ï¼Œå“åº”æ—¶é—´åœ¨å¯æ¥å—èŒƒå›´å†…ï¼Œç³»ç»Ÿç¨³å®šè¿è¡Œ"
        else:  # å®‰å…¨æµ‹è¯•
            expected_result = f"{req_name}å®‰å…¨æœºåˆ¶æœ‰æ•ˆï¼Œæƒé™æ§åˆ¶æ­£å¸¸ï¼Œæ•æ„Ÿä¿¡æ¯å¾—åˆ°ä¿æŠ¤"

        return {
            'title': title,
            'precondition': precondition,
            'test_steps': test_steps,
            'expected_result': expected_result
        }

    @action(detail=False, methods=['post'])
    def generate_test_cases(self, request):
        """ä¸ºé€‰ä¸­çš„éœ€æ±‚ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹"""
        serializer = TestCaseGenerationRequestSerializer(data=request.data)
        if not serializer.is_valid():
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        try:
            requirement_ids = serializer.validated_data['requirement_ids']
            test_level = serializer.validated_data['test_level']
            test_priority = serializer.validated_data['test_priority']
            test_case_count = serializer.validated_data['test_case_count']

            # ç”Ÿæˆå”¯ä¸€case_idçš„è¾…åŠ©å‡½æ•°
            def generate_unique_case_id(requirement, base_index):
                """ç”Ÿæˆå”¯ä¸€çš„æµ‹è¯•ç”¨ä¾‹ID"""
                base_case_id = f"TC{requirement.requirement_id}_{base_index:03d}"
                case_id = base_case_id
                counter = 1

                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™æ·»åŠ åç¼€
                while GeneratedTestCase.objects.filter(requirement=requirement, case_id=case_id).exists():
                    case_id = f"{base_case_id}_{counter}"
                    counter += 1

                return case_id

            # åŒæ­¥ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
            def run_generation():
                try:
                    # è·å–éœ€æ±‚æ•°æ®
                    requirements = BusinessRequirement.objects.filter(id__in=requirement_ids)
                    generated_test_cases = []

                    for requirement in requirements:
                        # è·å–è¯¥éœ€æ±‚ç°æœ‰æµ‹è¯•ç”¨ä¾‹çš„æ•°é‡ï¼Œä½œä¸ºèµ·å§‹ç´¢å¼•
                        existing_count = GeneratedTestCase.objects.filter(requirement=requirement).count()

                        for i in range(test_case_count):
                            # ç”Ÿæˆå”¯ä¸€çš„case_id
                            case_id = generate_unique_case_id(requirement, existing_count + i + 1)

                            # æ ¹æ®éœ€æ±‚ç±»å‹å’Œåºå·ç”Ÿæˆä¸åŒçš„æµ‹è¯•ç”¨ä¾‹å†…å®¹
                            test_case_content = BusinessRequirementViewSet._generate_test_case_content(requirement,
                                                                                                       i + 1,
                                                                                                       test_level)

                            # åˆ›å»ºæµ‹è¯•ç”¨ä¾‹
                            test_case = GeneratedTestCase.objects.create(
                                requirement=requirement,
                                case_id=case_id,
                                title=test_case_content['title'],
                                priority=test_priority,
                                precondition=test_case_content['precondition'],
                                test_steps=test_case_content['test_steps'],
                                expected_result=test_case_content['expected_result'],
                                status='generated',
                                generated_by_ai='AI-Generator-v1.0'
                            )
                            generated_test_cases.append(test_case)

                    return generated_test_cases

                except Exception as e:
                    logger.error(f"ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å¤±è´¥: {e}")
                    raise e

            test_cases = run_generation()

            # åºåˆ—åŒ–è¿”å›ç»“æœ
            test_case_serializer = GeneratedTestCaseSerializer(test_cases, many=True)

            return Response({
                'message': f'æˆåŠŸç”Ÿæˆ{len(test_cases)}ä¸ªæµ‹è¯•ç”¨ä¾‹',
                'test_cases': test_case_serializer.data
            }, status=status.HTTP_201_CREATED)

        except Exception as e:
            logger.error(f"ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )


from rest_framework.pagination import PageNumberPagination


class GeneratedTestCasePagination(PageNumberPagination):
    """ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹åˆ†é¡µå™¨"""
    page_size = 10
    page_size_query_param = 'page_size'
    max_page_size = 100


class TestCaseGenerationTaskPagination(PageNumberPagination):
    """æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆä»»åŠ¡åˆ†é¡µå™¨"""
    page_size = 10
    page_size_query_param = 'page_size'
    max_page_size = 100


class GeneratedTestCaseViewSet(viewsets.ModelViewSet):
    """ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹è§†å›¾é›†"""
    queryset = GeneratedTestCase.objects.all()
    serializer_class = GeneratedTestCaseSerializer
    pagination_class = GeneratedTestCasePagination
    http_method_names = ['get', 'patch']  # åªå…è®¸GETå’ŒPATCHæ–¹æ³•

    def get_queryset(self):
        queryset = super().get_queryset()

        # æŒ‰éœ€æ±‚IDè¿‡æ»¤
        requirement_id = self.request.query_params.get('requirement_id')
        if requirement_id:
            queryset = queryset.filter(requirement_id=requirement_id)

        # æŒ‰çŠ¶æ€è¿‡æ»¤
        status_param = self.request.query_params.get('status')
        if status_param:
            queryset = queryset.filter(status=status_param)

        # æŒ‰ä¼˜å…ˆçº§è¿‡æ»¤
        priority_param = self.request.query_params.get('priority')
        if priority_param:
            queryset = queryset.filter(priority=priority_param)

        return queryset

    @action(detail=False, methods=['post'])
    def review_test_cases(self, request):
        """è¯„å®¡æµ‹è¯•ç”¨ä¾‹"""
        serializer = TestCaseReviewRequestSerializer(data=request.data)
        if not serializer.is_valid():
            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        try:
            test_case_ids = serializer.validated_data['test_case_ids']
            review_criteria = serializer.validated_data['review_criteria']

            # åŒæ­¥æ‰§è¡Œè¯„å®¡
            def run_review():
                try:
                    # è·å–æµ‹è¯•ç”¨ä¾‹
                    test_cases = GeneratedTestCase.objects.filter(id__in=test_case_ids)

                    passed_count = 0
                    reviewed_cases = []

                    for test_case in test_cases:
                        # æ¨¡æ‹Ÿè¯„å®¡é€»è¾‘
                        is_passed = len(test_case.title) > 10 and len(test_case.test_steps) > 20

                        if is_passed:
                            passed_count += 1
                            test_case.status = 'approved'
                            test_case.review_comments = 'æµ‹è¯•ç”¨ä¾‹è®¾è®¡åˆç†ï¼Œæ»¡è¶³è¯„å®¡æ ‡å‡†'
                        else:
                            test_case.status = 'rejected'
                            test_case.review_comments = 'æµ‹è¯•ç”¨ä¾‹éœ€è¦å®Œå–„ï¼Œè¯·è¡¥å……è¯¦ç»†çš„æµ‹è¯•æ­¥éª¤'

                        test_case.reviewed_by_ai = 'AI-Reviewer-v1.0'
                        test_case.save()

                        reviewed_cases.append({
                            'id': test_case.id,
                            'case_id': test_case.case_id,
                            'title': test_case.title,
                            'status': test_case.status,
                            'review_comments': test_case.review_comments
                        })

                    total_count = len(test_cases)
                    pass_rate = (passed_count / total_count * 100) if total_count > 0 else 0

                    return {
                        'total_count': total_count,
                        'passed_count': passed_count,
                        'pass_rate': pass_rate,
                        'reviewed_cases': reviewed_cases
                    }

                except Exception as e:
                    logger.error(f"è¯„å®¡æµ‹è¯•ç”¨ä¾‹å¤±è´¥: {e}")
                    raise e

            review_result = run_review()

            return Response({
                'message': f'è¯„å®¡å®Œæˆï¼Œé€šè¿‡ç‡: {review_result["pass_rate"]:.2f}%',
                'review_result': review_result
            }, status=status.HTTP_200_OK)

        except Exception as e:
            logger.error(f"è¯„å®¡æµ‹è¯•ç”¨ä¾‹æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'è¯„å®¡å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )


class AnalysisTaskViewSet(viewsets.ReadOnlyModelViewSet):
    """åˆ†æä»»åŠ¡è§†å›¾é›†"""
    queryset = AnalysisTask.objects.all()
    serializer_class = AnalysisTaskSerializer

    def get_queryset(self):
        queryset = super().get_queryset()
        document_id = self.request.query_params.get('document_id')
        if document_id:
            queryset = queryset.filter(document_id=document_id)
        return queryset

    @action(detail=True, methods=['get'])
    def progress(self, request, pk=None):
        """è·å–ä»»åŠ¡è¿›åº¦"""
        task = self.get_object()
        return Response({
            'task_id': task.task_id,
            'status': task.status,
            'progress': task.progress,
            'error_message': task.error_message
        })


from rest_framework.decorators import api_view, permission_classes
from rest_framework.permissions import AllowAny
from django.views.decorators.csrf import csrf_exempt


@csrf_exempt
@api_view(['POST'])
@permission_classes([AllowAny])
def upload_and_analyze(request):
    """ä¸Šä¼ æ–‡æ¡£å¹¶ç«‹å³å¼€å§‹åˆ†æ"""
    try:
        # åˆ›å»ºæ–‡æ¡£
        serializer = DocumentUploadSerializer(data=request.data, context={'request': request})
        if not serializer.is_valid():
            return Response({'error': serializer.errors}, status=status.HTTP_400_BAD_REQUEST)

        document = serializer.save()

        # ç«‹å³å¼€å§‹åˆ†æ
        document.status = 'analyzing'
        document.save()

        def run_analysis():
            try:
                # ç®€åŒ–ç‰ˆåŒæ­¥åˆ†æ
                # æå–æ–‡æ¡£æ–‡æœ¬
                if not document.extracted_text:
                    document.extracted_text = DocumentProcessor.extract_text(document)
                    document.save()

                # åˆ›å»ºæ¨¡æ‹Ÿåˆ†æç»“æœ
                analysis_result = {
                    'analysis_report': f'å¯¹æ–‡æ¡£"{document.title}"çš„éœ€æ±‚åˆ†æå·²å®Œæˆã€‚\n\næ–‡æ¡£å†…å®¹ï¼š{document.extracted_text[:200]}...\n\nè¯†åˆ«åˆ°è‹¥å¹²åŠŸèƒ½æ€§éœ€æ±‚ã€‚',
                    'requirements_count': 2,
                    'requirements': [
                        {
                            'requirement_id': 'REQ001',
                            'requirement_name': 'åŸºç¡€åŠŸèƒ½éœ€æ±‚',
                            'requirement_type': 'functional',
                            'module': 'æ ¸å¿ƒæ¨¡å—',
                            'requirement_level': 'high',
                            'estimated_hours': 8,
                            'description': 'åŸºäºæ–‡æ¡£å†…å®¹è¯†åˆ«çš„åŠŸèƒ½éœ€æ±‚',
                            'acceptance_criteria': 'åŠŸèƒ½æ­£å¸¸è¿è¡Œï¼Œæ»¡è¶³ç”¨æˆ·éœ€æ±‚'
                        },
                        {
                            'requirement_id': 'REQ002',
                            'requirement_name': 'ç”¨æˆ·äº¤äº’éœ€æ±‚',
                            'requirement_type': 'usability',
                            'module': 'å‰ç«¯æ¨¡å—',
                            'requirement_level': 'medium',
                            'estimated_hours': 6,
                            'description': 'ç”¨æˆ·ç•Œé¢å’Œäº¤äº’ç›¸å…³éœ€æ±‚',
                            'acceptance_criteria': 'ç•Œé¢å‹å¥½ï¼Œæ“ä½œç®€å•'
                        }
                    ]
                }

                # åˆ›å»ºåˆ†æè®°å½•
                analysis = RequirementAnalysis.objects.create(
                    document=document,
                    analysis_report=analysis_result['analysis_report'],
                    requirements_count=analysis_result['requirements_count'],
                    analysis_time=2.5
                )

                # ä¿å­˜éœ€æ±‚æ•°æ®
                for req_data in analysis_result['requirements']:
                    BusinessRequirement.objects.create(
                        analysis=analysis,
                        **req_data
                    )

                # æ›´æ–°æ–‡æ¡£çŠ¶æ€
                document.status = 'analyzed'
                document.save()

                return analysis

            except Exception as e:
                logger.error(f"åˆ†æå¤±è´¥: {e}")
                document.status = 'failed'
                document.save()
                raise e

        analysis = run_analysis()

        return Response({
            'message': 'ä¸Šä¼ å¹¶åˆ†æå®Œæˆ',
            'document_id': document.id,
            'analysis_id': analysis.id,
            'requirements_count': analysis.requirements_count
        })

    except Exception as e:
        logger.error(f"ä¸Šä¼ å¹¶åˆ†æå¤±è´¥: {e}")
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@csrf_exempt
@api_view(['POST'])
@permission_classes([AllowAny])
def analyze_text(request):
    """ç›´æ¥åˆ†ææ–‡æœ¬å†…å®¹"""
    try:
        title = request.data.get('title', '')
        description = request.data.get('description', '')
        project_id = request.data.get('project')

        if not title or not description:
            return Response({'error': 'æ ‡é¢˜å’Œæè¿°ä¸èƒ½ä¸ºç©º'}, status=status.HTTP_400_BAD_REQUEST)

        # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„éœ€æ±‚æ–‡æ¡£è®°å½•
        document = RequirementDocument.objects.create(
            title=title,
            document_type='txt',
            status='analyzing',
            uploaded_by_id=1,  # ä½¿ç”¨é»˜è®¤ç”¨æˆ·IDï¼Œæˆ–è€…ä»request.userè·å–
            project_id=project_id if project_id else None,
            extracted_text=description
        )

        def run_analysis():
            try:
                # åˆ›å»ºæ¨¡æ‹Ÿåˆ†æç»“æœ
                analysis_result = {
                    'analysis_report': f'å¯¹éœ€æ±‚"{title}"çš„åˆ†æå·²å®Œæˆã€‚\n\néœ€æ±‚æè¿°ï¼š{description[:200]}...\n\nè¯†åˆ«åˆ°è‹¥å¹²åŠŸèƒ½æ€§éœ€æ±‚ã€‚',
                    'requirements_count': 2,
                    'requirements': [
                        {
                            'requirement_id': 'REQ001',
                            'requirement_name': 'åŸºç¡€åŠŸèƒ½éœ€æ±‚',
                            'requirement_type': 'functional',
                            'module': 'æ ¸å¿ƒæ¨¡å—',
                            'requirement_level': 'high',
                            'estimated_hours': 8,
                            'description': f'åŸºäºéœ€æ±‚æè¿°è¯†åˆ«çš„åŠŸèƒ½éœ€æ±‚ï¼š{description[:100]}...',
                            'acceptance_criteria': 'åŠŸèƒ½æ­£å¸¸è¿è¡Œï¼Œæ»¡è¶³ç”¨æˆ·éœ€æ±‚'
                        },
                        {
                            'requirement_id': 'REQ002',
                            'requirement_name': 'ç”¨æˆ·äº¤äº’éœ€æ±‚',
                            'requirement_type': 'usability',
                            'module': 'å‰ç«¯æ¨¡å—',
                            'requirement_level': 'medium',
                            'estimated_hours': 6,
                            'description': 'ç”¨æˆ·ç•Œé¢å’Œäº¤äº’ç›¸å…³éœ€æ±‚',
                            'acceptance_criteria': 'ç•Œé¢å‹å¥½ï¼Œæ“ä½œç®€å•'
                        }
                    ]
                }

                # åˆ›å»ºåˆ†æè®°å½•
                analysis = RequirementAnalysis.objects.create(
                    document=document,
                    analysis_report=analysis_result['analysis_report'],
                    requirements_count=analysis_result['requirements_count'],
                    analysis_time=1.5
                )

                # ä¿å­˜éœ€æ±‚æ•°æ®
                for req_data in analysis_result['requirements']:
                    BusinessRequirement.objects.create(
                        analysis=analysis,
                        **req_data
                    )

                # æ›´æ–°æ–‡æ¡£çŠ¶æ€
                document.status = 'analyzed'
                document.save()

                return analysis

            except Exception as e:
                logger.error(f"åˆ†æå¤±è´¥: {e}")
                document.status = 'failed'
                document.save()
                raise e

        analysis = run_analysis()

        return Response({
            'message': 'æ–‡æœ¬åˆ†æå®Œæˆ',
            'document_id': document.id,
            'analysis_id': analysis.id,
            'requirements_count': analysis.requirements_count
        })

    except Exception as e:
        logger.error(f"æ–‡æœ¬åˆ†æå¤±è´¥: {e}")
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


@csrf_exempt
@api_view(['POST'])
@permission_classes([AllowAny])
def analyze_text(request):
    """åˆ†ææ‰‹åŠ¨è¾“å…¥çš„éœ€æ±‚æ–‡æœ¬"""
    try:
        title = request.data.get('title')
        description = request.data.get('description')
        project_id = request.data.get('project')

        if not title or not description:
            return Response({'error': 'éœ€æ±‚æ ‡é¢˜å’Œæè¿°ä¸èƒ½ä¸ºç©º'}, status=status.HTTP_400_BAD_REQUEST)

        # åˆ›å»ºä¸€ä¸ªè™šæ‹Ÿçš„éœ€æ±‚æ–‡æ¡£è®°å½•
        document = RequirementDocument.objects.create(
            title=title,
            file=None,  # æ‰‹åŠ¨è¾“å…¥æ²¡æœ‰æ–‡ä»¶
            document_type='txt',
            status='analyzing',
            uploaded_by_id=1,  # ä½¿ç”¨é»˜è®¤ç”¨æˆ·IDï¼Œæˆ–è€…ä»request.userè·å–
            project_id=project_id if project_id else None,
            extracted_text=description
        )

        # ç«‹å³å¼€å§‹åˆ†æ
        def run_analysis():
            try:
                # ä½¿ç”¨æ–°çš„å…ˆè¿›åˆ†æç³»ç»Ÿ
                import asyncio
                from .services import AIService

                logger.info(f"å¼€å§‹ä½¿ç”¨å…ˆè¿›åˆ†æå™¨åˆ†æéœ€æ±‚: {title}")

                # è°ƒç”¨å…ˆè¿›çš„éœ€æ±‚åˆ†æ
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

                try:
                    analysis_result = loop.run_until_complete(
                        AIService.analyze_requirements(description, title)
                    )
                    logger.info(f"å…ˆè¿›åˆ†æå®Œæˆï¼Œè¯†åˆ«éœ€æ±‚: {analysis_result.get('requirements_count', 0)}ä¸ª")
                finally:
                    loop.close()

                # åˆ›å»ºåˆ†æè®°å½•
                analysis = RequirementAnalysis.objects.create(
                    document=document,
                    analysis_report=analysis_result['analysis_report'],
                    requirements_count=analysis_result['requirements_count'],
                    analysis_time=analysis_result.get('analysis_time', 2.0)
                )

                # ä¿å­˜éœ€æ±‚æ•°æ®
                for req_data in analysis_result['requirements']:
                    BusinessRequirement.objects.create(
                        analysis=analysis,
                        **req_data
                    )

                # æ›´æ–°æ–‡æ¡£çŠ¶æ€
                document.status = 'analyzed'
                document.save()

                return analysis

            except Exception as e:
                logger.error(f"å…ˆè¿›åˆ†æå¤±è´¥: {e}ï¼Œä½¿ç”¨å¤‡ç”¨åˆ†æ")
                # fallbackåˆ°ç®€å•åˆ†æ
                analysis_result = {
                    'analysis_report': f'å¯¹éœ€æ±‚"{title}"çš„åˆ†æå·²å®Œæˆã€‚\n\néœ€æ±‚æè¿°ï¼š{description[:200]}...\n\nåŸºäºæè¿°å†…å®¹è¯†åˆ«åˆ°è‹¥å¹²åŠŸèƒ½æ€§éœ€æ±‚ã€‚',
                    'requirements_count': 2,
                    'requirements': [
                        {
                            'requirement_id': 'REQ001',
                            'requirement_name': title + ' - æ ¸å¿ƒåŠŸèƒ½',
                            'requirement_type': 'functional',
                            'module': 'æ ¸å¿ƒæ¨¡å—',
                            'requirement_level': 'high',
                            'estimated_hours': 8,
                            'description': description[:100] + '...',
                            'acceptance_criteria': 'åŠŸèƒ½æ­£å¸¸è¿è¡Œï¼Œæ»¡è¶³ç”¨æˆ·éœ€æ±‚'
                        },
                        {
                            'requirement_id': 'REQ002',
                            'requirement_name': title + ' - äº¤äº’åŠŸèƒ½',
                            'requirement_type': 'usability',
                            'module': 'å‰ç«¯æ¨¡å—',
                            'requirement_level': 'medium',
                            'estimated_hours': 6,
                            'description': 'ç”¨æˆ·ç•Œé¢å’Œäº¤äº’ç›¸å…³éœ€æ±‚',
                            'acceptance_criteria': 'ç•Œé¢å‹å¥½ï¼Œæ“ä½œç®€å•'
                        }
                    ]
                }

                # åˆ›å»ºåˆ†æè®°å½•
                analysis = RequirementAnalysis.objects.create(
                    document=document,
                    analysis_report=analysis_result['analysis_report'],
                    requirements_count=analysis_result['requirements_count'],
                    analysis_time=1.5
                )

                # ä¿å­˜éœ€æ±‚æ•°æ®
                for req_data in analysis_result['requirements']:
                    BusinessRequirement.objects.create(
                        analysis=analysis,
                        **req_data
                    )

                # æ›´æ–°æ–‡æ¡£çŠ¶æ€
                document.status = 'analyzed'
                document.save()

                return analysis

            except Exception as e:
                logger.error(f"åˆ†æå¤±è´¥: {e}")
                document.status = 'failed'
                document.save()
                raise e

        analysis = run_analysis()

        return Response({
            'message': 'æ–‡æœ¬åˆ†æå®Œæˆ',
            'document_id': document.id,
            'analysis_id': analysis.id,
            'requirements_count': analysis.requirements_count
        })

    except Exception as e:
        logger.error(f"æ–‡æœ¬åˆ†æå¤±è´¥: {e}")
        return Response({'error': str(e)}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class AIModelConfigViewSet(viewsets.ModelViewSet):
    """AIæ¨¡å‹é…ç½®è§†å›¾é›†"""
    queryset = AIModelConfig.objects.all()
    serializer_class = AIModelConfigSerializer

    def get_queryset(self):
        queryset = super().get_queryset()

        # æŒ‰æ¨¡å‹ç±»å‹è¿‡æ»¤
        model_type = self.request.query_params.get('model_type')
        if model_type:
            queryset = queryset.filter(model_type=model_type)

        # æŒ‰è§’è‰²è¿‡æ»¤
        role = self.request.query_params.get('role')
        if role:
            queryset = queryset.filter(role=role)
        else:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šè§’è‰²ï¼Œé»˜è®¤æ’é™¤ AIæ™ºèƒ½æ¨¡å¼ä¸“ç”¨æ¨¡å‹
            queryset = queryset.exclude(role__in=['browser_use_text', 'browser_use_vision'])

        # æŒ‰æ˜¯å¦å¯ç”¨è¿‡æ»¤
        is_active = self.request.query_params.get('is_active')
        if is_active is not None:
            queryset = queryset.filter(is_active=is_active.lower() == 'true')

        return queryset.order_by('-created_at')

    @action(detail=True, methods=['post'])
    def test_connection(self, request, pk=None):
        """æµ‹è¯•æ¨¡å‹è¿æ¥"""
        try:
            config = self.get_object()

            logger.info(f"=== å¼€å§‹æµ‹è¯•æ¨¡å‹è¿æ¥ ===")
            logger.info(f"æ¨¡å‹ç±»å‹: {config.model_type}")
            logger.info(f"æ¨¡å‹åç§°: {config.model_name}")
            logger.info(f"API URL: {config.base_url}")
            logger.info(
                f"API Keyå‰ç¼€: {config.api_key[:10]}..." if len(config.api_key) > 10 else f"API Key: {config.api_key}")

            # å‡†å¤‡æµ‹è¯•æ¶ˆæ¯
            test_messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªAIåŠ©æ‰‹"},
                {"role": "user", "content": "è¯·å›å¤'è¿æ¥æˆåŠŸ'"}
            ]

            # å¼‚æ­¥æµ‹è¯•è¿æ¥ - ç»Ÿä¸€ä½¿ç”¨OpenAIå…¼å®¹API
            def test_api_connection():
                try:
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)

                    try:
                        logger.info("å¼€å§‹è°ƒç”¨API...")
                        # è®¾ç½®60ç§’è¶…æ—¶ï¼Œç»Ÿä¸€ä½¿ç”¨OpenAIå…¼å®¹API
                        result = loop.run_until_complete(
                            asyncio.wait_for(
                                AIModelService.call_openai_compatible_api(config, test_messages),
                                timeout=60.0
                            )
                        )

                        logger.info(f"APIè°ƒç”¨æˆåŠŸ: {result}")
                        return {
                            'success': True,
                            'message': 'è¿æ¥æµ‹è¯•æˆåŠŸ',
                            'response': result.get('choices', [{}])[0].get('message', {}).get('content', '')
                        }
                    except asyncio.TimeoutError:
                        logger.error(f"APIè¿æ¥æµ‹è¯•è¶…æ—¶ (60ç§’), URL: {config.base_url}, Model: {config.model_name}")
                        return {
                            'success': False,
                            'message': 'è¿æ¥æµ‹è¯•è¶…æ—¶: è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–APIåœ°å€æ˜¯å¦æ­£ç¡®'
                        }
                    finally:
                        try:
                            loop.run_until_complete(loop.shutdown_asyncgens())
                        except Exception:
                            pass
                        finally:
                            loop.close()

                except Exception as e:
                    logger.error(f"APIè¿æ¥æµ‹è¯•å¼‚å¸¸: {repr(e)}, URL: {config.base_url}, Model: {config.model_name}")
                    import traceback
                    logger.error(f"è¯¦ç»†é”™è¯¯å †æ ˆ:\n{traceback.format_exc()}")
                    return {
                        'success': False,
                        'message': f'è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}'
                    }

            result = test_api_connection()

            if result['success']:
                return Response(result, status=status.HTTP_200_OK)
            else:
                return Response(result, status=status.HTTP_400_BAD_REQUEST)

        except Exception as e:
            logger.error(f"æµ‹è¯•è¿æ¥æ—¶å‡ºé”™: {e}")
            return Response(
                {'success': False, 'message': f'æµ‹è¯•å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['post'])
    def enable(self, request, pk=None):
        """å¯ç”¨é…ç½®"""
        try:
            config = self.get_object()
            config.is_active = True
            config.save()
            return Response({
                'message': 'AIæ¨¡å‹é…ç½®å·²å¯ç”¨',
                'id': config.id,
                'is_active': True
            }, status=status.HTTP_200_OK)
        except Exception as e:
            logger.error(f"å¯ç”¨AIæ¨¡å‹é…ç½®å¤±è´¥: {e}")
            return Response({
                'error': f'å¯ç”¨å¤±è´¥: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    @action(detail=True, methods=['post'])
    def disable(self, request, pk=None):
        """ç¦ç”¨é…ç½®"""
        try:
            config = self.get_object()
            config.is_active = False
            config.save()
            return Response({
                'message': 'AIæ¨¡å‹é…ç½®å·²ç¦ç”¨',
                'id': config.id,
                'is_active': False
            }, status=status.HTTP_200_OK)
        except Exception as e:
            logger.error(f"ç¦ç”¨AIæ¨¡å‹é…ç½®å¤±è´¥: {e}")
            return Response({
                'error': f'ç¦ç”¨å¤±è´¥: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class PromptConfigViewSet(viewsets.ModelViewSet):
    """æç¤ºè¯é…ç½®è§†å›¾é›†"""
    queryset = PromptConfig.objects.all()
    serializer_class = PromptConfigSerializer

    def get_queryset(self):
        queryset = super().get_queryset()

        # æŒ‰æç¤ºè¯ç±»å‹è¿‡æ»¤
        prompt_type = self.request.query_params.get('prompt_type')
        if prompt_type:
            queryset = queryset.filter(prompt_type=prompt_type)

        # æŒ‰æ˜¯å¦å¯ç”¨è¿‡æ»¤
        is_active = self.request.query_params.get('is_active')
        if is_active is not None:
            queryset = queryset.filter(is_active=is_active.lower() == 'true')

        return queryset.order_by('-created_at')

    @action(detail=False, methods=['get'])
    def load_defaults(self, request):
        """åŠ è½½é»˜è®¤æç¤ºè¯"""
        try:
            # è¯»å–ç”¨ä¾‹ç¼–å†™æç¤ºè¯
            writer_prompt_path = os.path.join(settings.BASE_DIR, 'docs/tester.md')
            # è¯»å–ç”¨ä¾‹è¯„å®¡æç¤ºè¯
            reviewer_prompt_path = os.path.join(settings.BASE_DIR, 'docs/tester_pro.md')

            defaults = {}

            try:
                with open(writer_prompt_path, 'r', encoding='utf-8') as f:
                    defaults['writer'] = f.read()
            except FileNotFoundError:
                defaults['writer'] = """ä½ æ˜¯ä¸€ä½æ‹¥æœ‰10å¹´ç»éªŒçš„èµ„æ·±æµ‹è¯•ç”¨ä¾‹ç¼–å†™ä¸“å®¶ï¼Œèƒ½å¤Ÿæ ¹æ®éœ€æ±‚ç²¾ç¡®ç”Ÿæˆé«˜è´¨é‡çš„æµ‹è¯•ç”¨ä¾‹ã€‚

# æ ¸å¿ƒç›®æ ‡
ç”Ÿæˆé«˜è¦†ç›–ç‡ã€é¢—ç²’åº¦ç»†è‡´çš„æµ‹è¯•ç”¨ä¾‹ï¼Œç¡®ä¿ä¸é—æ¼ä»»ä½•åŠŸèƒ½é€»è¾‘ã€å¼‚å¸¸åœºæ™¯å’Œè¾¹ç•Œæ¡ä»¶ã€‚

# è§’è‰²è®¾å®š
1. èº«ä»½ï¼šç²¾é€šå…¨æ ˆæµ‹è¯•ï¼ˆWeb/App/APIï¼‰çš„é«˜çº§QAä¸“å®¶
2. æµ‹è¯•é£æ ¼ï¼šç ´åæ€§æµ‹è¯•æ€ç»´ï¼Œå–„äºå‘ç°æ½œåœ¨Bug
3. è¾“å‡ºåŸåˆ™ï¼šè¯¦ç»†ã€ç‹¬ç«‹ã€å¯æ‰§è¡Œ

# ç”¨ä¾‹è®¾è®¡è§„èŒƒ
1. **ç‹¬ç«‹æ€§**ï¼šæ¯æ¡ç”¨ä¾‹åªéªŒè¯ä¸€ä¸ªå…·ä½“çš„æµ‹è¯•ç‚¹ï¼Œä¸¥ç¦åˆå¹¶å¤šä¸ªåœºæ™¯ã€‚
2. **å®Œæ•´æ€§**ï¼š
   - åŒ…å«ç”¨ä¾‹IDï¼ˆ[æ¨¡å—]_[åºå·]ï¼‰
   - æ¸…æ™°çš„æµ‹è¯•ç›®æ ‡
   - å‡†ç¡®çš„å‰ç½®æ¡ä»¶
   - æ­¥éª¤åŒ–æ“ä½œæè¿°
   - å…·ä½“çš„é¢„æœŸç»“æœ
3. **è¦†ç›–ç»´åº¦**ï¼š
   - âœ… åŠŸèƒ½æ­£å‘æµç¨‹ï¼ˆHappy Pathï¼‰
   - âš ï¸ å¼‚å¸¸æµç¨‹ï¼ˆè¾“å…¥é”™è¯¯ã€æƒé™ä¸è¶³ã€ç½‘ç»œå¼‚å¸¸ï¼‰
   - ğŸ”„ è¾¹ç•Œå€¼ï¼ˆæœ€å¤§/æœ€å°å€¼ã€ç©ºå€¼ã€ç‰¹æ®Šå­—ç¬¦ï¼‰
   - ğŸ”’ ä¸šåŠ¡çº¦æŸï¼ˆçŠ¶æ€æœºæµè½¬ã€æ•°æ®ä¾èµ–ï¼‰

# è¾“å‡ºæ ¼å¼
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹Markdownè¡¨æ ¼æ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å«ä»»ä½•å¼€åœºç™½æˆ–ç»“æŸè¯­ï¼š

## âš ï¸ é‡è¦ï¼šè¾“å‡ºé¡ºåºè¦æ±‚
1. **å¿…é¡»æŒ‰ç”¨ä¾‹ç¼–å·ä»å°åˆ°å¤§çš„é¡ºåºè¾“å‡º**ï¼ˆå¦‚ï¼š001, 002, 003...ï¼‰
2. **ç»å¯¹ä¸èƒ½è·³å·ã€é‡å¤æˆ–ä¹±åºè¾“å‡º**
3. ç¼–å·å¿…é¡»è¿ç»­ï¼Œä¸­é—´ä¸èƒ½æœ‰é—æ¼
4. æ‰€æœ‰ç”¨ä¾‹å¿…é¡»ä¸€æ¬¡æ€§å®Œæ•´è¾“å‡ºï¼Œä¸èƒ½ä¸­æ–­

```markdown
| ç”¨ä¾‹ID | æµ‹è¯•ç›®æ ‡ | å‰ç½®æ¡ä»¶ | æ“ä½œæ­¥éª¤ | é¢„æœŸç»“æœ | ä¼˜å…ˆçº§ | æµ‹è¯•ç±»å‹ | å…³è”éœ€æ±‚ |
|--------|--------|--------|--------|--------|--------|--------|--------|
| LOGIN_001 | éªŒè¯æ‰‹æœºå·æ ¼å¼æ ¡éªŒ | åœ¨ç™»å½•é¡µ | 1. è¾“å…¥10ä½æ‰‹æœºå·<br>2. ç‚¹å‡»è·å–éªŒè¯ç  | æç¤º"æ‰‹æœºå·æ ¼å¼ä¸æ­£ç¡®"ï¼Œå‘é€æŒ‰é’®ä¸å¯ç‚¹ | P1 | åŠŸèƒ½éªŒè¯ | ç™»å½•æ¨¡å— |
```"""

            try:
                with open(reviewer_prompt_path, 'r', encoding='utf-8') as f:
                    defaults['reviewer'] = f.read()
            except FileNotFoundError:
                defaults['reviewer'] = """ä½ æ˜¯ä¸€åèµ„æ·±æµ‹è¯•ä¸“å®¶ï¼ˆTest Architectï¼‰ï¼Œæ‹¥æœ‰æé«˜çš„è´¨é‡æ ‡å‡†ã€‚ä½ çš„ä»»åŠ¡æ˜¯å¯¹ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹è¿›è¡Œä¸¥æ ¼çš„è¯„å®¡ã€‚

# æ ¸å¿ƒèŒè´£
ä¸åªæ˜¯ç®€å•é€šè¿‡ï¼Œè€Œæ˜¯è¦ä½œä¸ºâ€œè´¨é‡å®ˆé—¨å‘˜â€ï¼Œæ•é”åœ°å‘ç°é—æ¼çš„åœºæ™¯ã€é€»è¾‘æ¼æ´å’Œæè¿°ä¸æ¸…çš„é—®é¢˜ã€‚

# è¯„å®¡ç»´åº¦
1. **è¦†ç›–ç‡æ£€æŸ¥**ï¼š
   - æ˜¯å¦é—æ¼äº†éœ€æ±‚æ–‡æ¡£ä¸­çš„å…³é”®åŠŸèƒ½ç‚¹ï¼Ÿ
   - æ˜¯å¦åŒ…å«äº†å¿…è¦çš„å¼‚å¸¸åœºæ™¯ï¼ˆå¦‚æ–­ç½‘ã€æœåŠ¡è¶…æ—¶ã€æ•°æ®é”™è¯¯ï¼‰ï¼Ÿ
   - æ˜¯å¦è¦†ç›–äº†è¾¹ç•Œæ¡ä»¶ï¼ˆå¦‚æœ€å¤§é•¿åº¦ã€ç©ºå€¼ã€ç‰¹æ®Šå­—ç¬¦ï¼‰ï¼Ÿ
2. **é€»è¾‘æ€§æ£€æŸ¥**ï¼š
   - å‰ç½®æ¡ä»¶æ˜¯å¦å……åˆ†ï¼Ÿï¼ˆä¾‹å¦‚æµ‹è¯•â€œæ”¯ä»˜åŠŸèƒ½â€å‰æ˜¯å¦æ£€æŸ¥äº†â€œä½™é¢å……è¶³â€ï¼‰
   - é¢„æœŸç»“æœæ˜¯å¦å…·ä½“ï¼Ÿï¼ˆæ‹’ç»æ¨¡ç³Šçš„â€œæ˜¾ç¤ºæ­£ç¡®â€ï¼Œå¿…é¡»è¯´æ˜å…·ä½“æç¤ºæ–‡æ¡ˆæˆ–çŠ¶æ€å˜åŒ–ï¼‰
3. **è§„èŒƒæ€§æ£€æŸ¥**ï¼š
   - ç”¨ä¾‹æ ‡é¢˜æ˜¯å¦æ¸…æ™°è¡¨è¾¾äº†æµ‹è¯•æ„å›¾ï¼Ÿ
   - æ­¥éª¤æ˜¯å¦å¯æ‰§è¡Œï¼Ÿ

# è¾“å‡ºè¦æ±‚
è¯·è¾“å‡ºä¸€ä»½ç»“æ„åŒ–çš„è¯„å®¡æŠ¥å‘Šï¼š
1. **æ€»ä½“è¯„ä»·**ï¼šç»™å‡ºä¸€ä¸ªè´¨é‡è¯„åˆ†ï¼ˆ0-100åˆ†ï¼‰å’Œæ€»ä½“ç»“è®ºï¼ˆé€šè¿‡/éœ€ä¿®æ”¹ï¼‰ã€‚
2. **å‘ç°çš„é—®é¢˜**ï¼šåˆ—å‡ºå…·ä½“çš„é—®é¢˜ç‚¹ï¼Œç²¾ç¡®åˆ°å…·ä½“çš„ç”¨ä¾‹IDã€‚
3. **è¡¥å……å»ºè®®**ï¼šç›´æ¥ç»™å‡ºå»ºè®®è¡¥å……çš„æµ‹è¯•åœºæ™¯æˆ–ç”¨ä¾‹ã€‚
4. **ä¿®æ­£åçš„ç”¨ä¾‹**ï¼ˆå¯é€‰ï¼‰ï¼šå¦‚æœå‘ç°ä¸¥é‡é—®é¢˜ï¼Œè¯·ç›´æ¥æä¾›ä¿®æ­£åçš„ç”¨ä¾‹ç‰ˆæœ¬ã€‚"""

            return Response({
                'message': 'é»˜è®¤æç¤ºè¯åŠ è½½æˆåŠŸ',
                'defaults': defaults
            }, status=status.HTTP_200_OK)

        except Exception as e:
            logger.error(f"åŠ è½½é»˜è®¤æç¤ºè¯å¤±è´¥: {e}")
            return Response(
                {'error': f'åŠ è½½å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['post'])
    def enable(self, request, pk=None):
        """å¯ç”¨é…ç½®"""
        try:
            config = self.get_object()
            config.is_active = True
            config.save()
            return Response({
                'message': 'æç¤ºè¯é…ç½®å·²å¯ç”¨',
                'id': config.id,
                'is_active': True
            }, status=status.HTTP_200_OK)
        except Exception as e:
            logger.error(f"å¯ç”¨æç¤ºè¯é…ç½®å¤±è´¥: {e}")
            return Response({
                'error': f'å¯ç”¨å¤±è´¥: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    @action(detail=True, methods=['post'])
    def disable(self, request, pk=None):
        """ç¦ç”¨é…ç½®"""
        try:
            config = self.get_object()
            config.is_active = False
            config.save()
            return Response({
                'message': 'æç¤ºè¯é…ç½®å·²ç¦ç”¨',
                'id': config.id,
                'is_active': False
            }, status=status.HTTP_200_OK)
        except Exception as e:
            logger.error(f"ç¦ç”¨æç¤ºè¯é…ç½®å¤±è´¥: {e}")
            return Response({
                'error': f'ç¦ç”¨å¤±è´¥: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class GenerationConfigViewSet(viewsets.ModelViewSet):
    """ç”Ÿæˆè¡Œä¸ºé…ç½®è§†å›¾é›†"""
    queryset = GenerationConfig.objects.all()
    serializer_class = GenerationConfigSerializer

    def get_queryset(self):
        queryset = super().get_queryset()
        return queryset.order_by('-created_at')

    @action(detail=False, methods=['get'])
    def active(self, request):
        """è·å–æ´»è·ƒçš„ç”Ÿæˆé…ç½®"""
        try:
            config = GenerationConfig.get_active_config()
            if not config:
                return Response({
                    'error': 'æœªæ‰¾åˆ°æ´»è·ƒçš„ç”Ÿæˆé…ç½®ï¼Œè¯·å…ˆåˆ›å»ºå¹¶å¯ç”¨ä¸€ä¸ªé…ç½®'
                }, status=status.HTTP_404_NOT_FOUND)

            serializer = self.get_serializer(config)
            return Response(serializer.data, status=status.HTTP_200_OK)
        except Exception as e:
            logger.error(f"è·å–æ´»è·ƒç”Ÿæˆé…ç½®å¤±è´¥: {e}")
            return Response({
                'error': f'è·å–å¤±è´¥: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    @action(detail=True, methods=['post'])
    def enable(self, request, pk=None):
        """å¯ç”¨é…ç½®"""
        try:
            # ç¦ç”¨å…¶ä»–æ‰€æœ‰é…ç½®
            GenerationConfig.objects.all().update(is_active=False)

            # å¯ç”¨å½“å‰é…ç½®
            config = self.get_object()
            config.is_active = True
            config.save()

            return Response({
                'message': 'ç”Ÿæˆé…ç½®å·²å¯ç”¨',
                'id': config.id,
                'is_active': True
            }, status=status.HTTP_200_OK)
        except Exception as e:
            logger.error(f"å¯ç”¨ç”Ÿæˆé…ç½®å¤±è´¥: {e}")
            return Response({
                'error': f'å¯ç”¨å¤±è´¥: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)

    @action(detail=True, methods=['post'])
    def disable(self, request, pk=None):
        """ç¦ç”¨é…ç½®"""
        try:
            config = self.get_object()
            config.is_active = False
            config.save()

            return Response({
                'message': 'ç”Ÿæˆé…ç½®å·²ç¦ç”¨',
                'id': config.id,
                'is_active': False
            }, status=status.HTTP_200_OK)
        except Exception as e:
            logger.error(f"ç¦ç”¨ç”Ÿæˆé…ç½®å¤±è´¥: {e}")
            return Response({
                'error': f'ç¦ç”¨å¤±è´¥: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)


class TestCaseGenerationTaskViewSet(viewsets.ModelViewSet):
    """æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆä»»åŠ¡è§†å›¾é›†"""
    queryset = TestCaseGenerationTask.objects.all()
    serializer_class = TestCaseGenerationTaskSerializer
    pagination_class = TestCaseGenerationTaskPagination
    http_method_names = ['get', 'post', 'patch', 'delete']  # å…è®¸GETã€POSTã€PATCHå’ŒDELETEæ–¹æ³•
    lookup_field = 'task_id'  # ä½¿ç”¨task_idä½œä¸ºæŸ¥æ‰¾å­—æ®µ

    def get_queryset(self):
        queryset = super().get_queryset()

        # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿requestæœ‰query_paramså±æ€§
        if not hasattr(self.request, 'query_params'):
            return queryset.order_by('-created_at')

        # æŒ‰çŠ¶æ€è¿‡æ»¤
        status_param = self.request.query_params.get('status')
        if status_param:
            queryset = queryset.filter(status=status_param)

        # æŒ‰åˆ›å»ºè€…è¿‡æ»¤
        created_by = self.request.query_params.get('created_by')
        if created_by:
            queryset = queryset.filter(created_by_id=created_by)

        return queryset.order_by('-created_at')

    @action(detail=False, methods=['post'])
    def generate(self, request):
        """åˆ›å»ºæ–°çš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆä»»åŠ¡"""
        try:
            serializer = TestCaseGenerationRequestSerializer(data=request.data)
            if not serializer.is_valid():
                return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)

            validated_data = serializer.validated_data

            # è·å–æ´»è·ƒçš„é…ç½®
            writer_config = None
            reviewer_config = None
            writer_prompt = None
            reviewer_prompt = None

            if validated_data.get('use_writer_model', True):
                # ä¼˜å…ˆæŸ¥æ‰¾ä»»æ„å¯ç”¨çš„ç¼–å†™æ¨¡å‹é…ç½®
                writer_config = AIModelConfig.objects.filter(role='writer', is_active=True).first()

                if not writer_config:
                    return Response(
                        {'error': 'æœªæ‰¾åˆ°å¯ç”¨çš„æµ‹è¯•ç”¨ä¾‹ç¼–å†™æ¨¡å‹é…ç½®'},
                        status=status.HTTP_400_BAD_REQUEST
                    )

                writer_prompt = PromptConfig.get_active_config('writer')
                if not writer_prompt:
                    return Response(
                        {'error': 'æœªæ‰¾åˆ°å¯ç”¨çš„æµ‹è¯•ç”¨ä¾‹ç¼–å†™æç¤ºè¯é…ç½®'},
                        status=status.HTTP_400_BAD_REQUEST
                    )

            if validated_data.get('use_reviewer_model', True):
                # ä¼˜å…ˆæŸ¥æ‰¾ä»»æ„å¯ç”¨çš„è¯„å®¡æ¨¡å‹é…ç½®
                reviewer_config = AIModelConfig.objects.filter(role='reviewer', is_active=True).first()

                if not reviewer_config:
                    return Response(
                        {'error': 'æœªæ‰¾åˆ°å¯ç”¨çš„æµ‹è¯•ç”¨ä¾‹è¯„å®¡æ¨¡å‹é…ç½®'},
                        status=status.HTTP_400_BAD_REQUEST
                    )

                reviewer_prompt = PromptConfig.get_active_config('reviewer')
                if not reviewer_prompt:
                    return Response(
                        {'error': 'æœªæ‰¾åˆ°å¯ç”¨çš„æµ‹è¯•ç”¨ä¾‹è¯„å®¡æç¤ºè¯é…ç½®'},
                        status=status.HTTP_400_BAD_REQUEST
                    )

            # åˆ›å»ºä»»åŠ¡
            task_data = {
                'title': validated_data['title'],
                'requirement_text': validated_data['requirement_text'],
                'writer_model_config': writer_config.id if writer_config else None,
                'reviewer_model_config': reviewer_config.id if reviewer_config else None,
                'writer_prompt_config': writer_prompt.id if writer_prompt else None,
                'reviewer_prompt_config': reviewer_prompt.id if reviewer_prompt else None,
            }

            # å¦‚æœè¯·æ±‚ä¸­åŒ…å«é¡¹ç›®IDï¼Œæ·»åŠ åˆ°ä»»åŠ¡æ•°æ®ä¸­
            if 'project' in validated_data and validated_data['project']:
                task_data['project'] = validated_data['project']

            # å¤„ç†è¾“å‡ºæ¨¡å¼ï¼šä¼˜å…ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ï¼Œå¦åˆ™ä½¿ç”¨ç”Ÿæˆè¡Œä¸ºé…ç½®çš„é»˜è®¤å€¼
            output_mode = request.data.get('output_mode')
            if output_mode and output_mode in ['stream', 'complete']:
                task_data['output_mode'] = output_mode
            else:
                # ä»ç”Ÿæˆè¡Œä¸ºé…ç½®ä¸­è¯»å–é»˜è®¤å€¼
                from .models import GenerationConfig
                gen_config = GenerationConfig.get_active_config()
                if gen_config:
                    task_data['output_mode'] = gen_config.default_output_mode
                else:
                    # å¦‚æœæ²¡æœ‰é…ç½®ï¼Œé»˜è®¤ä½¿ç”¨æµå¼è¾“å‡º
                    task_data['output_mode'] = 'stream'

            task_serializer = TestCaseGenerationTaskSerializer(
                data=task_data,
                context={'request': request}
            )

            if task_serializer.is_valid():
                task = task_serializer.save()

                # å¼‚æ­¥æ‰§è¡Œç”Ÿæˆä»»åŠ¡
                def run_generation_task():
                    try:
                        import threading

                        def execute_task():
                            try:
                                # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                                task.status = 'generating'
                                task.progress = 10
                                task.save()

                                # è¯»å–ç”Ÿæˆè¡Œä¸ºé…ç½®
                                from .models import GenerationConfig
                                gen_config = GenerationConfig.get_active_config()

                                # è·å–é…ç½®å‚æ•°ï¼Œè®¾ç½®é»˜è®¤å€¼
                                enable_auto_review = gen_config.enable_auto_review if gen_config else True
                                review_timeout = gen_config.review_timeout if gen_config else 120

                                logger.info(
                                    f"ä»»åŠ¡ {task.task_id} ä½¿ç”¨ç”Ÿæˆé…ç½®: auto_review={enable_auto_review}, review_timeout={review_timeout}s")

                                loop = asyncio.new_event_loop()
                                asyncio.set_event_loop(loop)

                                try:
                                    # æ ¹æ®è¾“å‡ºæ¨¡å¼é€‰æ‹©ä¸åŒçš„ç”Ÿæˆæ–¹å¼
                                    if task.output_mode == 'stream':
                                        # æµå¼æ¨¡å¼ï¼šå®æ—¶ä¿å­˜åˆ°stream_buffer
                                        # ç”Ÿæˆå‰å…ˆè®¾ç½®åˆå§‹çŠ¶æ€
                                        task.stream_buffer = ''
                                        task.stream_position = 0
                                        task.save()

                                        # å®šä¹‰åŒæ­¥ä¿å­˜å‡½æ•°
                                        def save_stream_buffer(content):
                                            """åŒæ­¥ä¿å­˜æµå¼å†…å®¹åˆ°æ•°æ®åº“"""
                                            task.stream_buffer = content
                                            task.stream_position = len(content)
                                            task.last_stream_update = timezone.now()
                                            task.save(update_fields=['stream_buffer', 'stream_position',
                                                                     'last_stream_update'])

                                        # è½¬æ¢ä¸ºå¼‚æ­¥å‡½æ•°
                                        async_save_stream_buffer = sync_to_async(save_stream_buffer)

                                        async def stream_callback(chunk):
                                            """æµå¼å›è°ƒï¼šå®æ—¶ä¿å­˜æ¯ä¸ªchunkåˆ°æ•°æ®åº“"""
                                            # å…ˆè¿½åŠ åˆ°å†…å­˜ä¸­çš„buffer
                                            task.stream_buffer += chunk
                                            task.stream_position = len(task.stream_buffer)
                                            task.last_stream_update = timezone.now()

                                            # æ¯10ä¸ªchunkæˆ–å½“chunkè¾ƒå¤§æ—¶ä¿å­˜ä¸€æ¬¡
                                            if task.stream_position % 500 < 20 or len(chunk) > 100:
                                                try:
                                                    await async_save_stream_buffer(task.stream_buffer)
                                                except Exception as save_error:
                                                    logger.warning(f"ä¿å­˜æµå¼å†…å®¹å¤±è´¥: {save_error}")

                                        # ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
                                        task.progress = 30
                                        task.save()

                                        generated_cases = loop.run_until_complete(
                                            AIModelService.generate_test_cases_stream(task, callback=stream_callback)
                                        )

                                        # ç”Ÿæˆå®Œæˆåï¼Œç¡®ä¿æœ€ç»ˆçš„æµå¼å†…å®¹è¢«ä¿å­˜
                                        if task.stream_buffer:
                                            save_stream_buffer(task.stream_buffer)

                                        task.generated_test_cases = generated_cases
                                        task.progress = 60
                                        task.save()

                                        # æµå¼è¯„å®¡å’Œæ”¹è¿›ï¼ˆæ ¹æ®ç”Ÿæˆé…ç½®å†³å®šæ˜¯å¦æ‰§è¡Œï¼‰
                                        if enable_auto_review and task.reviewer_model_config and task.reviewer_prompt_config:
                                            try:
                                                task.status = 'reviewing'
                                                task.progress = 70
                                                task.save()

                                                logger.info(f"å¼€å§‹æµå¼è¯„å®¡ä»»åŠ¡ {task.task_id}")

                                                # è¯„å®¡å†…å®¹ç¼“å­˜
                                                review_buffer = []

                                                def save_review_buffer(content):
                                                    """åŒæ­¥ä¿å­˜è¯„å®¡å†…å®¹"""
                                                    task.review_feedback = content
                                                    task.save(update_fields=['review_feedback'])

                                                async_save_review = sync_to_async(save_review_buffer)

                                                async def review_stream_callback(chunk):
                                                    """æµå¼è¯„å®¡å›è°ƒ"""
                                                    review_buffer.append(chunk)
                                                    current_length = sum(len(c) for c in review_buffer)

                                                    # æ¯100å­—ç¬¦ä¿å­˜ä¸€æ¬¡
                                                    if current_length % 100 < 20 or len(chunk) > 50:
                                                        try:
                                                            content = ''.join(review_buffer)
                                                            await async_save_review(content)
                                                        except Exception as save_error:
                                                            logger.warning(f"ä¿å­˜è¯„å®¡å†…å®¹å¤±è´¥: {save_error}")

                                                try:
                                                    # ç§»é™¤è¶…æ—¶é™åˆ¶ï¼Œå…è®¸å¤§æ–‡æ¡£å®Œæ•´è¯„å®¡
                                                    review_feedback = loop.run_until_complete(
                                                        AIModelService.review_test_cases_stream(
                                                            task, generated_cases, callback=review_stream_callback
                                                        )
                                                    )
                                                    # ä¿å­˜æœ€ç»ˆè¯„å®¡å†…å®¹
                                                    if review_buffer:
                                                        task.review_feedback = ''.join(review_buffer)
                                                        task.save(update_fields=['review_feedback'])
                                                    logger.info(f"ä»»åŠ¡ {task.task_id} æµå¼è¯„å®¡å®Œæˆ")

                                                    # æ ¹æ®è¯„å®¡æ„è§æ”¹è¿›æµ‹è¯•ç”¨ä¾‹ï¼ˆè‡ªåŠ¨æ‰§è¡Œï¼‰
                                                    logger.info(f"ä»»åŠ¡ {task.task_id} å¼€å§‹æ ¹æ®è¯„å®¡æ„è§æ”¹è¿›æµ‹è¯•ç”¨ä¾‹")
                                                    task.status = 'revising'
                                                    task.progress = 85
                                                    task.final_test_cases = ''  # æ¸…ç©ºï¼Œå‡†å¤‡æµå¼å†™å…¥
                                                    task.save()

                                                    try:
                                                        # å®šä¹‰åŒæ­¥ä¿å­˜å‡½æ•°
                                                        def save_final_buffer(content):
                                                            """åŒæ­¥ä¿å­˜æœ€ç»ˆç”¨ä¾‹å†…å®¹"""
                                                            task.final_test_cases = content
                                                            task.save(update_fields=['final_test_cases'])

                                                        # è½¬æ¢ä¸ºå¼‚æ­¥å‡½æ•°
                                                        async_save_final = sync_to_async(save_final_buffer)

                                                        # åˆ›å»ºæµå¼å›è°ƒå‡½æ•°ï¼Œå®æ—¶æ›´æ–°final_test_cases
                                                        async def final_callback(chunk):
                                                            """æµå¼å›è°ƒï¼šå®æ—¶ä¿å­˜æœ€ç»ˆç”¨ä¾‹åˆ°æ•°æ®åº“"""
                                                            # å®æ—¶è¿½åŠ åˆ°final_test_caseså¹¶ä¿å­˜
                                                            task.final_test_cases = (
                                                                                                task.final_test_cases or '') + chunk

                                                            # æ¯100å­—ç¬¦æˆ–chunkè¾ƒå¤§æ—¶ä¿å­˜ä¸€æ¬¡
                                                            current_length = len(task.final_test_cases)
                                                            if current_length % 100 < 20 or len(chunk) > 50:
                                                                try:
                                                                    await async_save_final(task.final_test_cases)
                                                                except Exception as save_error:
                                                                    logger.warning(f"ä¿å­˜æœ€ç»ˆç”¨ä¾‹å¤±è´¥: {save_error}")

                                                        # æ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼Œé¿å…ä»»åŠ¡ä¸€ç›´å¡ä½ï¼ˆä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´ï¼‰
                                                        try:
                                                            revised_cases = loop.run_until_complete(
                                                                asyncio.wait_for(
                                                                    AIModelService.revise_test_cases_based_on_review(
                                                                        task, generated_cases, task.review_feedback,
                                                                        callback=final_callback
                                                                    ),
                                                                    timeout=review_timeout  # ä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
                                                                )
                                                            )
                                                        except asyncio.TimeoutError:
                                                            logger.error(
                                                                f"ä»»åŠ¡ {task.task_id} æ”¹è¿›é˜¶æ®µè¶…æ—¶ï¼ˆ{review_timeout}ç§’ï¼‰ï¼Œä½¿ç”¨åŸå§‹ç”¨ä¾‹")
                                                            # è¶…æ—¶æ—¶ä½¿ç”¨åŸå§‹ç”Ÿæˆçš„ç”¨ä¾‹ï¼Œä¸å†æŠ›å‡ºå¼‚å¸¸
                                                            revised_cases = generated_cases
                                                        # å§‹ç»ˆä½¿ç”¨è¿”å›çš„å®Œæ•´å†…å®¹ï¼Œé¿å…æµå¼è¾“å‡ºè¢«æˆªæ–­å¯¼è‡´æ•°æ®ä¸¢å¤±
                                                        # revised_cases æ˜¯å®Œæ•´çš„è¿”å›å€¼ï¼Œtask.final_test_cases åªæ˜¯æµå¼å›è°ƒçš„ä¸­é—´çŠ¶æ€
                                                        if revised_cases and len(revised_cases) > 0:
                                                            # æ£€æµ‹å¹¶ä¿®å¤ä¸å®Œæ•´çš„æœ€åä¸€æ¡ç”¨ä¾‹
                                                            revised_cases = AIModelService.fix_incomplete_last_case(
                                                                revised_cases)

                                                            # æŒ‰ç”¨ä¾‹ç¼–å·æ’åºåå†ä¿å­˜
                                                            sorted_cases = AIModelService.sort_test_cases_by_id(
                                                                revised_cases)
                                                            # é‡æ–°ç¼–å·ä½¿ç¼–å·è¿ç»­
                                                            renumbered_cases = AIModelService.renumber_test_cases(
                                                                sorted_cases)
                                                            task.final_test_cases = renumbered_cases
                                                            logger.info(
                                                                f"ä»»åŠ¡ {task.task_id} æµ‹è¯•ç”¨ä¾‹æ”¹è¿›å®Œæˆ (revised_casesé•¿åº¦: {len(revised_cases)}, æœ€ç»ˆä¿å­˜é•¿åº¦: {len(task.final_test_cases)})")
                                                        else:
                                                            # å¦‚æœè¿”å›ä¸ºç©ºï¼Œä¿ç•™æµå¼å›è°ƒä¿å­˜çš„å†…å®¹
                                                            logger.warning(
                                                                f"ä»»åŠ¡ {task.task_id} æ”¹è¿›è¿”å›ä¸ºç©ºï¼Œä½¿ç”¨æµå¼å›è°ƒä¿å­˜çš„å†…å®¹ (é•¿åº¦: {len(task.final_test_cases) if task.final_test_cases else 0})")
                                                    except Exception as revise_error:
                                                        logger.warning(
                                                            f"ä»»åŠ¡ {task.task_id} æ”¹è¿›æµ‹è¯•ç”¨ä¾‹å¤±è´¥: {revise_error}ï¼Œä½¿ç”¨åŸå§‹ç”¨ä¾‹")
                                                        # æŒ‰ç”¨ä¾‹ç¼–å·æ’åºåå†ä¿å­˜
                                                        sorted_cases = AIModelService.sort_test_cases_by_id(
                                                            generated_cases)
                                                        # é‡æ–°ç¼–å·ä½¿ç¼–å·è¿ç»­
                                                        task.final_test_cases = AIModelService.renumber_test_cases(
                                                            sorted_cases)
                                                        task.save()

                                                except Exception as inner_error:
                                                    logger.warning(
                                                        f"ä»»åŠ¡ {task.task_id} æµå¼è¯„å®¡è¿‡ç¨‹å¼‚å¸¸: {inner_error}")
                                                    task.review_feedback = f"è¯„å®¡è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {str(inner_error)}\n\nå»ºè®®ï¼šæµ‹è¯•ç”¨ä¾‹ç»“æ„å®Œæ•´ï¼Œå¯ä»¥ä½¿ç”¨ã€‚"
                                                    # æŒ‰ç”¨ä¾‹ç¼–å·æ’åºåå†ä¿å­˜
                                                    sorted_cases = AIModelService.sort_test_cases_by_id(generated_cases)
                                                    # é‡æ–°ç¼–å·ä½¿ç¼–å·è¿ç»­
                                                    task.final_test_cases = AIModelService.renumber_test_cases(
                                                        sorted_cases)
                                                    task.save()

                                            except Exception as review_error:
                                                logger.error(f"æµå¼è¯„å®¡ä»»åŠ¡ {task.task_id} å¤±è´¥: {review_error}")
                                                # æŒ‰ç”¨ä¾‹ç¼–å·æ’åºåå†ä¿å­˜
                                                sorted_cases = AIModelService.sort_test_cases_by_id(generated_cases)
                                                task.final_test_cases = AIModelService.renumber_test_cases(sorted_cases)
                                                task.review_feedback = f"è¯„å®¡å¤±è´¥: {str(review_error)}\n\nå»ºè®®ï¼šæµ‹è¯•ç”¨ä¾‹ç»“æ„å®Œæ•´ï¼Œå¯ä»¥ä½¿ç”¨ã€‚"
                                                task.save()
                                        else:
                                            # æŒ‰ç”¨ä¾‹ç¼–å·æ’åºåå†ä¿å­˜
                                            sorted_cases = AIModelService.sort_test_cases_by_id(generated_cases)
                                            # é‡æ–°ç¼–å·ä½¿ç¼–å·è¿ç»­
                                            task.final_test_cases = AIModelService.renumber_test_cases(sorted_cases)
                                            logger.info(f"ä»»åŠ¡ {task.task_id} è·³è¿‡è¯„å®¡ï¼Œç›´æ¥ä½¿ç”¨ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹")
                                            task.save()

                                    else:
                                        # å®Œæ•´æ¨¡å¼ï¼šåŸæœ‰é€»è¾‘
                                        task.progress = 30
                                        task.save()

                                        generated_cases = loop.run_until_complete(
                                            AIModelService.generate_test_cases(task)
                                        )

                                        task.generated_test_cases = generated_cases
                                        task.progress = 60
                                        task.save()

                                        # è¯„å®¡å’Œæ”¹è¿›æµ‹è¯•ç”¨ä¾‹ï¼ˆæ ¹æ®ç”Ÿæˆé…ç½®å†³å®šæ˜¯å¦æ‰§è¡Œï¼‰
                                        if enable_auto_review and task.reviewer_model_config and task.reviewer_prompt_config:
                                            try:
                                                task.status = 'reviewing'
                                                task.progress = 70
                                                task.save()

                                                logger.info(f"å¼€å§‹è¯„å®¡ä»»åŠ¡ {task.task_id}")

                                                # ç§»é™¤è¶…æ—¶é™åˆ¶ï¼Œå…è®¸å¤§æ–‡æ¡£å®Œæ•´è¯„å®¡
                                                try:
                                                    review_feedback = loop.run_until_complete(
                                                        AIModelService.review_test_cases(task, generated_cases)
                                                    )
                                                    task.review_feedback = review_feedback
                                                    logger.info(f"ä»»åŠ¡ {task.task_id} è¯„å®¡å®Œæˆ")

                                                    # æ ¹æ®è¯„å®¡æ„è§æ”¹è¿›æµ‹è¯•ç”¨ä¾‹ï¼ˆè‡ªåŠ¨æ‰§è¡Œï¼‰
                                                    logger.info(f"ä»»åŠ¡ {task.task_id} å¼€å§‹æ ¹æ®è¯„å®¡æ„è§æ”¹è¿›æµ‹è¯•ç”¨ä¾‹")
                                                    task.status = 'revising'
                                                    task.progress = 85
                                                    task.final_test_cases = ''  # æ¸…ç©ºï¼Œå‡†å¤‡æµå¼å†™å…¥
                                                    task.save()

                                                    try:
                                                        # å®šä¹‰åŒæ­¥ä¿å­˜å‡½æ•°
                                                        def save_final_buffer_full(content):
                                                            """åŒæ­¥ä¿å­˜æœ€ç»ˆç”¨ä¾‹å†…å®¹"""
                                                            task.final_test_cases = content
                                                            task.save(update_fields=['final_test_cases'])

                                                        # è½¬æ¢ä¸ºå¼‚æ­¥å‡½æ•°
                                                        async_save_final_full = sync_to_async(save_final_buffer_full)

                                                        # åˆ›å»ºæµå¼å›è°ƒå‡½æ•°ï¼Œå®æ—¶æ›´æ–°final_test_cases
                                                        async def final_callback_full(chunk):
                                                            """æµå¼å›è°ƒï¼šå®æ—¶ä¿å­˜æœ€ç»ˆç”¨ä¾‹åˆ°æ•°æ®åº“"""
                                                            # å®æ—¶è¿½åŠ åˆ°final_test_caseså¹¶ä¿å­˜
                                                            task.final_test_cases = (
                                                                                                task.final_test_cases or '') + chunk

                                                            # æ¯100å­—ç¬¦æˆ–chunkè¾ƒå¤§æ—¶ä¿å­˜ä¸€æ¬¡
                                                            current_length = len(task.final_test_cases)
                                                            if current_length % 100 < 20 or len(chunk) > 50:
                                                                try:
                                                                    await async_save_final_full(task.final_test_cases)
                                                                except Exception as save_error:
                                                                    logger.warning(f"ä¿å­˜æœ€ç»ˆç”¨ä¾‹å¤±è´¥: {save_error}")

                                                        # æ·»åŠ è¶…æ—¶ä¿æŠ¤ï¼Œé¿å…ä»»åŠ¡ä¸€ç›´å¡ä½ï¼ˆä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´ï¼‰
                                                        try:
                                                            revised_cases = loop.run_until_complete(
                                                                asyncio.wait_for(
                                                                    AIModelService.revise_test_cases_based_on_review(
                                                                        task, generated_cases, task.review_feedback,
                                                                        callback=final_callback_full
                                                                    ),
                                                                    timeout=review_timeout  # ä½¿ç”¨é…ç½®çš„è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
                                                                )
                                                            )
                                                        except asyncio.TimeoutError:
                                                            logger.error(
                                                                f"ä»»åŠ¡ {task.task_id} æ”¹è¿›é˜¶æ®µè¶…æ—¶ï¼ˆ{review_timeout}ç§’ï¼‰ï¼Œä½¿ç”¨åŸå§‹ç”¨ä¾‹")
                                                            # è¶…æ—¶æ—¶ä½¿ç”¨åŸå§‹ç”Ÿæˆçš„ç”¨ä¾‹ï¼Œä¸å†æŠ›å‡ºå¼‚å¸¸
                                                            revised_cases = generated_cases
                                                        # å§‹ç»ˆä½¿ç”¨è¿”å›çš„å®Œæ•´å†…å®¹ï¼Œé¿å…æµå¼è¾“å‡ºè¢«æˆªæ–­å¯¼è‡´æ•°æ®ä¸¢å¤±
                                                        # revised_cases æ˜¯å®Œæ•´çš„è¿”å›å€¼ï¼Œtask.final_test_cases åªæ˜¯æµå¼å›è°ƒçš„ä¸­é—´çŠ¶æ€
                                                        if revised_cases and len(revised_cases) > 0:
                                                            # æ£€æµ‹å¹¶ä¿®å¤ä¸å®Œæ•´çš„æœ€åä¸€æ¡ç”¨ä¾‹
                                                            revised_cases = AIModelService.fix_incomplete_last_case(
                                                                revised_cases)

                                                            # æŒ‰ç”¨ä¾‹ç¼–å·æ’åºåå†ä¿å­˜
                                                            sorted_cases = AIModelService.sort_test_cases_by_id(
                                                                revised_cases)
                                                            # é‡æ–°ç¼–å·ä½¿ç¼–å·è¿ç»­
                                                            renumbered_cases = AIModelService.renumber_test_cases(
                                                                sorted_cases)
                                                            task.final_test_cases = renumbered_cases
                                                            logger.info(
                                                                f"ä»»åŠ¡ {task.task_id} æµ‹è¯•ç”¨ä¾‹æ”¹è¿›å®Œæˆ (revised_casesé•¿åº¦: {len(revised_cases)}, æœ€ç»ˆä¿å­˜é•¿åº¦: {len(task.final_test_cases)})")
                                                        else:
                                                            # å¦‚æœè¿”å›ä¸ºç©ºï¼Œä¿ç•™æµå¼å›è°ƒä¿å­˜çš„å†…å®¹
                                                            logger.warning(
                                                                f"ä»»åŠ¡ {task.task_id} æ”¹è¿›è¿”å›ä¸ºç©ºï¼Œä½¿ç”¨æµå¼å›è°ƒä¿å­˜çš„å†…å®¹ (é•¿åº¦: {len(task.final_test_cases) if task.final_test_cases else 0})")
                                                    except Exception as revise_error:
                                                        logger.warning(
                                                            f"ä»»åŠ¡ {task.task_id} æ”¹è¿›æµ‹è¯•ç”¨ä¾‹å¤±è´¥: {revise_error}ï¼Œä½¿ç”¨åŸå§‹ç”¨ä¾‹")
                                                        # æŒ‰ç”¨ä¾‹ç¼–å·æ’åºåå†ä¿å­˜
                                                        sorted_cases = AIModelService.sort_test_cases_by_id(
                                                            generated_cases)
                                                        # é‡æ–°ç¼–å·ä½¿ç¼–å·è¿ç»­
                                                        task.final_test_cases = AIModelService.renumber_test_cases(
                                                            sorted_cases)
                                                        task.save()

                                                except Exception as inner_error:
                                                    logger.warning(f"ä»»åŠ¡ {task.task_id} è¯„å®¡è¿‡ç¨‹å¼‚å¸¸: {inner_error}")
                                                    task.review_feedback = f"è¯„å®¡è¿‡ç¨‹å‡ºç°å¼‚å¸¸: {str(inner_error)}\n\nå»ºè®®ï¼šæµ‹è¯•ç”¨ä¾‹ç»“æ„å®Œæ•´ï¼Œå¯ä»¥ä½¿ç”¨ã€‚"
                                                    # æŒ‰ç”¨ä¾‹ç¼–å·æ’åºåå†ä¿å­˜
                                                    sorted_cases = AIModelService.sort_test_cases_by_id(generated_cases)
                                                    # é‡æ–°ç¼–å·ä½¿ç¼–å·è¿ç»­
                                                    task.final_test_cases = AIModelService.renumber_test_cases(
                                                        sorted_cases)
                                                    task.save()

                                            except Exception as review_error:
                                                logger.error(f"è¯„å®¡ä»»åŠ¡ {task.task_id} å¤±è´¥: {review_error}")
                                                # è¯„å®¡å¤±è´¥æ—¶ï¼Œä»ç„¶ä½¿ç”¨ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹ä½œä¸ºæœ€ç»ˆç»“æœ
                                                # æŒ‰ç”¨ä¾‹ç¼–å·æ’åºåå†ä¿å­˜
                                                sorted_cases = AIModelService.sort_test_cases_by_id(generated_cases)
                                                task.final_test_cases = AIModelService.renumber_test_cases(sorted_cases)
                                                task.review_feedback = f"è¯„å®¡å¤±è´¥: {str(review_error)}\n\nå»ºè®®ï¼šæµ‹è¯•ç”¨ä¾‹ç»“æ„å®Œæ•´ï¼Œå¯ä»¥ä½¿ç”¨ã€‚"
                                                task.save()
                                        else:
                                            # æŒ‰ç”¨ä¾‹ç¼–å·æ’åºåå†ä¿å­˜
                                            sorted_cases = AIModelService.sort_test_cases_by_id(generated_cases)
                                            # é‡æ–°ç¼–å·ä½¿ç¼–å·è¿ç»­
                                            task.final_test_cases = AIModelService.renumber_test_cases(sorted_cases)
                                            logger.info(f"ä»»åŠ¡ {task.task_id} è·³è¿‡è¯„å®¡ï¼Œç›´æ¥ä½¿ç”¨ç”Ÿæˆçš„æµ‹è¯•ç”¨ä¾‹")
                                            task.save()

                                    # å®Œæˆä»»åŠ¡
                                    # æ³¨æ„ï¼šä¸è¦ç›´æ¥è°ƒç”¨task.save()ï¼Œå› ä¸ºè¿™ä¼šè¦†ç›–æµå¼å›è°ƒä¿å­˜çš„final_test_cases
                                    # ä»æ•°æ®åº“é‡æ–°è·å–æœ€æ–°çš„ä»»åŠ¡å¯¹è±¡
                                    task.refresh_from_db()

                                    task.status = 'completed'
                                    task.progress = 100
                                    task.completed_at = timezone.now()
                                    task.save(update_fields=['status', 'progress', 'completed_at', 'final_test_cases'])
                                    logger.info(f"ä»»åŠ¡ {task.task_id} å·²å®Œæˆ")

                                finally:
                                    try:
                                        # æ¸…ç†å¼‚æ­¥ç”Ÿæˆå™¨ï¼Œé˜²æ­¢ "Task was destroyed but it is pending" è­¦å‘Š
                                        loop.run_until_complete(loop.shutdown_asyncgens())
                                    except Exception as e:
                                        logger.warning(f"Error shutting down asyncgens: {e}")
                                    finally:
                                        loop.close()

                            except Exception as e:
                                logger.error(f"ç”Ÿæˆä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
                                task.status = 'failed'
                                task.error_message = str(e)
                                task.save()

                        # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œä»»åŠ¡
                        thread = threading.Thread(target=execute_task)
                        thread.daemon = True
                        thread.start()

                    except Exception as e:
                        logger.error(f"å¯åŠ¨ç”Ÿæˆä»»åŠ¡å¤±è´¥: {e}")
                        task.status = 'failed'
                        task.error_message = str(e)
                        task.save()

                # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡
                run_generation_task()

                return Response({
                    'message': 'æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆä»»åŠ¡å·²åˆ›å»º',
                    'task_id': task.task_id,
                    'task': task_serializer.data
                }, status=status.HTTP_201_CREATED)
            else:
                return Response(task_serializer.errors, status=status.HTTP_400_BAD_REQUEST)

        except Exception as e:
            logger.error(f"åˆ›å»ºç”Ÿæˆä»»åŠ¡æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'åˆ›å»ºä»»åŠ¡å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['get'])
    def progress(self, request, task_id=None):
        """è·å–ä»»åŠ¡è¿›åº¦"""
        try:
            # DRFä¼šæ ¹æ®lookup_fieldè‡ªåŠ¨ä»URLæå–task_idå¹¶è°ƒç”¨get_object()
            task = self.get_object()

            return Response({
                'task_id': task.task_id,
                'status': task.status,
                'progress': task.progress,
                'generated_test_cases': task.generated_test_cases,
                'review_feedback': task.review_feedback,
                'final_test_cases': task.final_test_cases,
                'error_message': task.error_message,
                'completed_at': task.completed_at
            }, status=status.HTTP_200_OK)

        except Exception as e:
            logger.error(f"è·å–ä»»åŠ¡è¿›åº¦æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'è·å–è¿›åº¦å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(
        detail=True,
        methods=['get'],
        url_path='stream_progress',
        renderer_classes=[PassThroughRenderer],
        permission_classes=[]  # å…è®¸è®¿é—®ï¼Œtask_idæœ¬èº«å°±æ˜¯å®‰å…¨æ ‡è¯†
    )
    def stream_progress_sse(self, request, task_id=None):
        """
        SSEæµå¼è¿›åº¦æ¨é€æ¥å£
        å®æ—¶æ¨é€ä»»åŠ¡çš„æµå¼è¾“å‡ºå’Œè¿›åº¦æ›´æ–°
        ä¸ä½¿ç”¨DRFçš„Responseï¼Œé¿å…content negotiationé—®é¢˜
        æ³¨æ„ï¼šEventSourceä¸æ”¯æŒè‡ªå®šä¹‰headersï¼Œæ— æ³•å‘é€JWT tokenï¼Œæ‰€ä»¥å…è®¸é€šè¿‡session cookieè®¿é—®
        """
        try:
            # è®°å½•è¯·æ±‚ä¿¡æ¯ï¼ˆç”¨äºè°ƒè¯•ï¼‰
            request_origin = request.META.get('HTTP_ORIGIN', 'unknown')
            logger.info(
                f"SSEè¿æ¥è¯·æ±‚: task_id={task_id}, user={request.user}, authenticated={request.user.is_authenticated}, path={request.path}, origin={request_origin}")

            # åŠ¨æ€è·å–CORS origin - ä½¿ç”¨ Django é…ç½®ä¼˜å…ˆ
            def get_allowed_origin(origin):
                """è·å–å…è®¸çš„CORS originï¼Œä¼˜å…ˆä½¿ç”¨ settings é…ç½®"""
                if getattr(settings, 'CORS_ALLOW_ALL_ORIGINS', False):
                    return origin or '*'

                allowed_origins = getattr(settings, 'CORS_ALLOWED_ORIGINS', []) or []
                if origin in allowed_origins:
                    return origin

                # å…¼å®¹æœªé…ç½®æ—¶çš„æœ¬åœ°å¼€å‘é»˜è®¤
                local_defaults = ['http://localhost:3000', 'http://127.0.0.1:3000']
                if origin in local_defaults:
                    return origin

                # å¦‚æœæœªåŒ¹é…ï¼Œä¼˜å…ˆè¿”å›ç¬¬ä¸€ä¸ªå…è®¸çš„ originï¼ˆé¿å…è¿”å›é”™è¯¯çš„ localhostï¼‰
                if allowed_origins:
                    return allowed_origins[0]

                # æœ€åå…œåº•ï¼šè¿”å›è¯·æ±‚ originï¼ˆè‹¥å­˜åœ¨ï¼‰
                return origin or 'http://localhost:3000'

            cors_origin = get_allowed_origin(request_origin)

            # å¤„ç† CORS é¢„æ£€è¯·æ±‚
            if request.method == 'OPTIONS':
                from django.http import HttpResponse
                response = HttpResponse()
                response['Access-Control-Allow-Origin'] = cors_origin
                response['Access-Control-Allow-Methods'] = 'GET, OPTIONS'
                response['Access-Control-Allow-Headers'] = 'Content-Type'
                response['Access-Control-Allow-Credentials'] = 'true'
                response['Access-Control-Max-Age'] = '86400'
                return response

            # è·å–ä»»åŠ¡å¯¹è±¡
            task = TestCaseGenerationTask.objects.filter(task_id=task_id).first()
            if not task:
                logger.warning(f"SSEè¿æ¥å¤±è´¥: ä»»åŠ¡æœªæ‰¾åˆ°, task_id={task_id}")
                # è¿”å›JSONé”™è¯¯è€Œä¸æ˜¯SSE
                from django.http import HttpResponse
                response = HttpResponse(
                    json.dumps({'error': 'ä»»åŠ¡æœªæ‰¾åˆ°'}),
                    status=404,
                    content_type='application/json'
                )
                response['Access-Control-Allow-Origin'] = cors_origin
                response['Access-Control-Allow-Credentials'] = 'true'
                return response

            # è®°å½•ä¸Šæ¬¡å‘é€çš„stream_position
            last_sent_position = 0
            loop_count = 0  # å¾ªç¯è®¡æ•°å™¨
            last_review_length = 0  # è®°å½•ä¸Šæ¬¡å‘é€çš„è¯„å®¡å†…å®¹é•¿åº¦
            last_final_length = 0  # è®°å½•ä¸Šæ¬¡å‘é€çš„æœ€ç»ˆç”¨ä¾‹é•¿åº¦
            last_status = ''  # è®°å½•ä¸Šæ¬¡çš„ä»»åŠ¡çŠ¶æ€

            def event_stream():
                nonlocal last_sent_position, loop_count, last_review_length, last_final_length, last_status
                
                # Performance & Timeout Optimization
                start_time = time.time()
                last_heartbeat_time = time.time()
                last_progress_hash = None
                MAX_TIMEOUT = 3600  # 1 hour safety timeout

                while True:
                    loop_count += 1
                    current_time = time.time()
                    has_sent_data = False

                    # Safety Timeout Check
                    if current_time - start_time > MAX_TIMEOUT:
                        logger.error(f"SSE Connection timed out after {MAX_TIMEOUT}s: task_id={task_id}")
                        yield f"event: error\ndata: timeout\n\n"
                        break

                    # ä»æ•°æ®åº“é‡æ–°è·å–ä»»åŠ¡çŠ¶æ€
                    try:
                        task.refresh_from_db()
                    except TestCaseGenerationTask.DoesNotExist:
                        yield f"event: error\ndata: task_not_found\n\n"
                        break
                    except Exception as e:
                        logger.error(f"DB refresh failed: {e}")
                        time.sleep(1)
                        continue

                    # æ£€æµ‹çŠ¶æ€å˜åŒ–ï¼Œå¦‚æœè¿›å…¥revisingé˜¶æ®µï¼Œé‡ç½®last_final_length
                    if task.status != last_status:
                        logger.info(f"SSEæ£€æµ‹åˆ°çŠ¶æ€å˜åŒ–: {last_status} -> {task.status}")
                        if task.status == 'revising':
                            logger.info(f"SSE: è¿›å…¥revisingé˜¶æ®µï¼Œé‡ç½®last_final_length")
                            last_final_length = 0
                        last_status = task.status

                    # æ¯30æ¬¡å¾ªç¯è®°å½•ä¸€æ¬¡æ—¥å¿— (Reduced frequency)
                    if loop_count % 30 == 0:
                        logger.info(
                            f"SSE stream loop #{loop_count}: task_status={task.status}, progress={task.progress}%, buffer_len={len(task.stream_buffer) if task.stream_buffer else 0}")

                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²å®Œæˆæˆ–å¤±è´¥
                    if task.status in ['completed', 'failed', 'cancelled']:
                        logger.info(f"SSEä»»åŠ¡ç»“æŸ: status={task.status}")
                        # å‘é€æœ€ç»ˆçŠ¶æ€
                        final_status = json.dumps({'type': 'status', 'status': task.status, 'progress': task.progress},
                                                  ensure_ascii=False)
                        logger.info(f"SSEå‘é€æœ€ç»ˆçŠ¶æ€: {final_status}")
                        yield f"data: {final_status}\n\n"

                        # å¦‚æœæ˜¯æµå¼æ¨¡å¼ä¸”æœ‰ç¼“å†²åŒºå†…å®¹ï¼Œå‘é€å‰©ä½™å†…å®¹
                        if task.output_mode == 'stream' and task.stream_buffer:
                            if last_sent_position < len(task.stream_buffer):
                                new_content = task.stream_buffer[last_sent_position:]
                                content_data = json.dumps({'type': 'content', 'content': new_content},
                                                          ensure_ascii=False)
                                logger.info(f"SSEå‘é€å‰©ä½™å†…å®¹: {len(new_content)} å­—ç¬¦")
                                yield f"data: {content_data}\n\n"
                                last_sent_position = len(task.stream_buffer)

                        # å‘é€å‰©ä½™çš„è¯„å®¡å†…å®¹
                        if task.review_feedback:
                            if len(task.review_feedback) > last_review_length:
                                remaining_review = task.review_feedback[last_review_length:]
                                if remaining_review:
                                    review_data = json.dumps({'type': 'review_content', 'content': remaining_review},
                                                             ensure_ascii=False)
                                    logger.info(
                                        f"SSEå‘é€å‰©ä½™è¯„å®¡å†…å®¹: {len(remaining_review)} å­—ç¬¦, æ€»é•¿åº¦: {len(task.review_feedback)}")
                                    yield f"data: {review_data}\n\n"
                                    last_review_length = len(task.review_feedback)

                        # å‘é€å‰©ä½™çš„æœ€ç»ˆç”¨ä¾‹å†…å®¹
                        if task.final_test_cases:
                            if len(task.final_test_cases) > last_final_length:
                                remaining_final = task.final_test_cases[last_final_length:]
                                if remaining_final:
                                    final_data = json.dumps({'type': 'final_content', 'content': remaining_final},
                                                            ensure_ascii=False)
                                    logger.info(
                                        f"SSEå‘é€å‰©ä½™æœ€ç»ˆç”¨ä¾‹: {len(remaining_final)} å­—ç¬¦, æ€»é•¿åº¦: {len(task.final_test_cases)}")
                                    yield f"data: {final_data}\n\n"
                                    last_final_length = len(task.final_test_cases)

                        # å‘é€å®Œæˆä¿¡å·
                        yield f"data: {json.dumps({'type': 'done'}, ensure_ascii=False)}\n\n"
                        logger.info(f"SSEæµç»“æŸï¼Œæ€»å¾ªç¯æ¬¡æ•°: {loop_count}")

                        # æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œç¡®ä¿doneä¿¡å·è¢«å‘é€
                        time.sleep(0.1)
                        break

                    # å¦‚æœæ˜¯æµå¼æ¨¡å¼ï¼Œå‘é€æ–°å¢çš„å†…å®¹
                    if task.output_mode == 'stream' and task.stream_buffer:
                        current_position = task.stream_position
                        if current_position > last_sent_position:
                            # æå–æ–°å¢å†…å®¹
                            new_content = task.stream_buffer[last_sent_position:current_position]
                            if new_content:
                                content_data = json.dumps({'type': 'content', 'content': new_content},
                                                          ensure_ascii=False)
                                logger.info(f"SSEå‘é€æ–°å¢å†…å®¹: {len(new_content)} å­—ç¬¦, æ€»ä½ç½®: {current_position}")
                                yield f"data: {content_data}\n\n"
                                last_sent_position = current_position
                                has_sent_data = True

                    # å¦‚æœæ˜¯è¯„å®¡é˜¶æ®µï¼Œå‘é€è¯„å®¡å†…å®¹
                    if task.status == 'reviewing' and task.review_feedback:
                        review_feedback = task.review_feedback
                        if review_feedback:
                            # è®¡ç®—è¯„å®¡å†…å®¹çš„å¢é‡
                            if len(review_feedback) > last_review_length:
                                new_review = review_feedback[last_review_length:]
                                if new_review:
                                    review_data = json.dumps({'type': 'review_content', 'content': new_review},
                                                             ensure_ascii=False)
                                    logger.info(f"SSEå‘é€è¯„å®¡å†…å®¹: {len(new_review)} å­—ç¬¦")
                                    yield f"data: {review_data}\n\n"
                                    last_review_length = len(review_feedback)
                                    has_sent_data = True

                    # å¦‚æœæœ‰æœ€ç»ˆç”¨ä¾‹ï¼Œå‘é€æœ€ç»ˆç”¨ä¾‹å†…å®¹ï¼ˆåœ¨reviewingã€revisingæˆ–completedé˜¶æ®µï¼‰
                    if task.status in ['reviewing', 'revising', 'completed'] and task.final_test_cases:
                        final_cases = task.final_test_cases
                        if final_cases:
                            # è®¡ç®—æœ€ç»ˆç”¨ä¾‹çš„å¢é‡
                            if len(final_cases) > last_final_length:
                                new_final = final_cases[last_final_length:]
                                if new_final:
                                    final_data = json.dumps({'type': 'final_content', 'content': new_final},
                                                            ensure_ascii=False)
                                    logger.info(
                                        f"SSEå‘é€æœ€ç»ˆç”¨ä¾‹: {len(new_final)} å­—ç¬¦, æ€»é•¿åº¦: {len(final_cases)}, é˜¶æ®µ: {task.status}")
                                    yield f"data: {final_data}\n\n"
                                    last_final_length = len(final_cases)
                                    has_sent_data = True

                    # å‘é€è¿›åº¦æ›´æ–° (Optimized)
                    current_progress_hash = f"{task.status}_{task.progress}"
                    if current_progress_hash != last_progress_hash:
                        progress_data = json.dumps({'type': 'progress', 'status': task.status, 'progress': task.progress},
                                                   ensure_ascii=False)
                        yield f"data: {progress_data}\n\n"
                        last_progress_hash = current_progress_hash
                        has_sent_data = True

                    # Heartbeat
                    if has_sent_data:
                        last_heartbeat_time = current_time
                    elif current_time - last_heartbeat_time >= 15:
                        yield ": keep-alive\n\n"
                        last_heartbeat_time = current_time

                    # å¢åŠ ä¼‘çœ æ—¶é—´åˆ° 1.0sï¼Œå‡å°‘è´Ÿè½½
                    time.sleep(1.0)

            # è¿”å›SSEæµå¼å“åº” - ä½¿ç”¨æ›´ç¨³å¥çš„æ–¹å¼
            try:
                response = StreamingHttpResponse(
                    event_stream(),
                    content_type='text/event-stream; charset=utf-8'
                )
            except Exception as e:
                logger.error(f"åˆ›å»ºSSEå“åº”å¤±è´¥: {e}")
                raise

            # è®¾ç½®SSEç›¸å…³çš„å“åº”å¤´ - ç¡®ä¿æ­£ç¡®å¤„ç†é•¿è¿æ¥
            response['Cache-Control'] = 'no-cache, no-store, must-revalidate'
            response['Pragma'] = 'no-cache'
            response['Expires'] = '0'
            response['X-Accel-Buffering'] = 'no'
            response['X-Content-Type-Options'] = 'nosniff'
            # æ·»åŠ è¿æ¥ä¿æŒå¤´éƒ¨ï¼Œé˜²æ­¢è¿‡æ—©æ–­å¼€
            # æ³¨æ„ï¼šåœ¨æœ¬åœ°å¼€å‘æœåŠ¡å™¨(runserver)ä¸­ï¼Œwsgirefç¦æ­¢æ‰‹åŠ¨è®¾ç½®Hop-by-hop headers(å¦‚Connection)
            # åªæœ‰åœ¨ç”Ÿäº§ç¯å¢ƒ(Gunicorn/Nginx)ä¸‹æ‰éœ€è¦æ˜¾å¼è®¾ç½®
            if not settings.DEBUG:
                response['Connection'] = 'keep-alive'

            # è®¾ç½®CORSå¤´éƒ¨ - ä½¿ç”¨åŠ¨æ€è®¡ç®—çš„cors_origin
            response['Access-Control-Allow-Origin'] = cors_origin
            response['Access-Control-Allow-Credentials'] = 'true'
            response['Access-Control-Allow-Headers'] = 'Content-Type, Cache-Control'

            logger.info(f"SSEè¿æ¥å»ºç«‹æˆåŠŸ: task_id={task_id}, cors_origin={cors_origin}")
            return response

        except Exception as e:
            logger.error(f"SSEæµå¼æ¨é€å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            from django.http import HttpResponse
            # è·å–å…è®¸çš„origin
            request_origin = request.META.get('HTTP_ORIGIN', 'unknown')

            def get_allowed_origin(origin):
                if getattr(settings, 'CORS_ALLOW_ALL_ORIGINS', False):
                    return origin or '*'

                allowed_origins = getattr(settings, 'CORS_ALLOWED_ORIGINS', []) or []
                if origin in allowed_origins:
                    return origin

                local_defaults = ['http://localhost:3000', 'http://127.0.0.1:3000']
                if origin in local_defaults:
                    return origin

                if allowed_origins:
                    return allowed_origins[0]

                return origin or 'http://localhost:3000'

            cors_origin = get_allowed_origin(request_origin)
            response = HttpResponse(
                json.dumps({'error': f'æµå¼æ¨é€å¤±è´¥: {str(e)}'}),
                status=500,
                content_type='application/json'
            )
            response['Access-Control-Allow-Origin'] = cors_origin
            response['Access-Control-Allow-Credentials'] = 'true'
            return response

    @action(detail=True, methods=['post'])
    def cancel(self, request, task_id=None):
        """å–æ¶ˆæ­£åœ¨è¿è¡Œçš„ä»»åŠ¡"""
        try:
            # DRFä¼šæ ¹æ®lookup_fieldè‡ªåŠ¨ä»URLæå–task_idå¹¶è°ƒç”¨get_object()
            task = self.get_object()

            if task.status in ['completed', 'failed', 'cancelled']:
                return Response(
                    {'error': f'ä»»åŠ¡å·²ç»{task.get_status_display()}ï¼Œæ— æ³•å–æ¶ˆ'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            task.status = 'cancelled'
            task.save()

            return Response({
                'message': 'ä»»åŠ¡å·²å–æ¶ˆ',
                'task_id': task.task_id,
                'status': task.status
            })

        except Exception as e:
            logger.error(f"å–æ¶ˆä»»åŠ¡æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'å–æ¶ˆä»»åŠ¡å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['post'])
    def save_to_records(self, request, task_id=None):
        """ä¿å­˜æµ‹è¯•ç”¨ä¾‹åˆ°AIç”Ÿæˆç”¨ä¾‹è®°å½•å¹¶å¯¼å…¥åˆ°æµ‹è¯•ç”¨ä¾‹ç®¡ç†ç³»ç»Ÿ"""
        try:
            # DRFä¼šæ ¹æ®lookup_fieldè‡ªåŠ¨ä»URLæå–task_idå¹¶è°ƒç”¨get_object()
            task = self.get_object()

            if task.status != 'completed':
                return Response(
                    {'error': 'åªèƒ½ä¿å­˜å·²å®Œæˆçš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆä»»åŠ¡'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            if not task.final_test_cases:
                return Response(
                    {'error': 'æ²¡æœ‰æœ€ç»ˆæµ‹è¯•ç”¨ä¾‹å¯ä»¥ä¿å­˜'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # æ£€æŸ¥æ˜¯å¦å·²ç»ä¿å­˜è¿‡
            if hasattr(task, 'is_saved_to_records') and task.is_saved_to_records:
                return Response(
                    {'message': 'æµ‹è¯•ç”¨ä¾‹å·²ç»ä¿å­˜åˆ°è®°å½•ä¸­', 'already_saved': True},
                    status=status.HTTP_200_OK
                )

            # è§£æå¹¶å¯¼å…¥æµ‹è¯•ç”¨ä¾‹åˆ°æµ‹è¯•ç”¨ä¾‹ç®¡ç†ç³»ç»Ÿ
            test_cases = self._parse_test_cases_content(task.final_test_cases)

            if test_cases:
                try:
                    from apps.testcases.models import TestCase
                    from apps.projects.models import Project
                    from django.db import models

                    # ä¼˜å…ˆä½¿ç”¨ä»»åŠ¡å…³è”çš„é¡¹ç›®
                    if task.project:
                        project = task.project
                        logger.info(f"ä½¿ç”¨ä»»åŠ¡å…³è”çš„é¡¹ç›®: {project.name}")
                    else:
                        # å›é€€åˆ°é¡¹ç›®é€‰æ‹©é€»è¾‘
                        user = task.created_by
                        accessible_projects = Project.objects.filter(
                            models.Q(owner=user) | models.Q(members=user)
                        ).distinct()

                        # å°è¯•ä»å‰ç«¯è·å–é¡¹ç›®ID
                        project_id = request.data.get('project_id')

                        if project_id:
                            try:
                                project = accessible_projects.get(id=project_id)
                            except Project.DoesNotExist:
                                # å¦‚æœæŒ‡å®šé¡¹ç›®ä¸å­˜åœ¨æˆ–æ— æƒé™ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯è®¿é—®çš„é¡¹ç›®
                                project = accessible_projects.first()
                                if not project:
                                    # å¦‚æœç”¨æˆ·æ²¡æœ‰ä»»ä½•é¡¹ç›®ï¼Œåˆ›å»ºé»˜è®¤é¡¹ç›®
                                    project = Project.objects.create(
                                        name="é»˜è®¤é¡¹ç›®",
                                        owner=user,
                                        description='ç³»ç»Ÿè‡ªåŠ¨åˆ›å»ºçš„é»˜è®¤é¡¹ç›®'
                                    )
                        else:
                            # æ²¡æœ‰æŒ‡å®šé¡¹ç›®ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯è®¿é—®çš„é¡¹ç›®
                            project = accessible_projects.first()
                            if not project:
                                # å¦‚æœç”¨æˆ·æ²¡æœ‰ä»»ä½•é¡¹ç›®ï¼Œåˆ›å»ºé»˜è®¤é¡¹ç›®
                                project = Project.objects.create(
                                    name="é»˜è®¤é¡¹ç›®",
                                    owner=user,
                                    description='ç³»ç»Ÿè‡ªåŠ¨åˆ›å»ºçš„é»˜è®¤é¡¹ç›®'
                                )

                    adopted_count = 0
                    for test_case in test_cases:
                        TestCase.objects.create(
                            project=project,
                            author=task.created_by,
                            title=test_case.get('scenario', 'æµ‹è¯•ç”¨ä¾‹'),
                            description=test_case.get('scenario', ''),
                            preconditions=test_case.get('precondition', ''),
                            steps=test_case.get('steps', ''),
                            expected_result=test_case.get('expected', ''),
                            priority=self._map_priority(test_case.get('priority', 'ä¸­')),
                            test_type='functional',
                            status='draft'
                        )
                        adopted_count += 1

                    logger.info(f"æˆåŠŸå¯¼å…¥ {adopted_count} æ¡æµ‹è¯•ç”¨ä¾‹åˆ°é¡¹ç›® {project.name}")

                except Exception as import_error:
                    logger.error(f"å¯¼å…¥æµ‹è¯•ç”¨ä¾‹å¤±è´¥: {import_error}")
                    # å³ä½¿å¯¼å…¥å¤±è´¥ï¼Œä»ç„¶æ ‡è®°ä¸ºå·²ä¿å­˜

            # æ ‡è®°ä»»åŠ¡ä¸ºå·²ä¿å­˜
            task.is_saved_to_records = True
            task.saved_at = timezone.now()
            task.save(update_fields=['is_saved_to_records', 'saved_at'])

            return Response({
                'message': 'æµ‹è¯•ç”¨ä¾‹å·²æˆåŠŸä¿å­˜åˆ°AIç”Ÿæˆç”¨ä¾‹è®°å½•å¹¶å¯¼å…¥åˆ°æµ‹è¯•ç”¨ä¾‹ç®¡ç†ç³»ç»Ÿ',
                'task_id': task.task_id,
                'saved_at': task.saved_at,
                'imported_count': adopted_count if test_cases else 0
            }, status=status.HTTP_200_OK)

        except Exception as e:
            logger.error(f"ä¿å­˜æµ‹è¯•ç”¨ä¾‹åˆ°è®°å½•æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'ä¿å­˜å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=False, methods=['get'])
    def saved_records(self, request):
        """è·å–å·²ä¿å­˜çš„æµ‹è¯•ç”¨ä¾‹è®°å½•åˆ—è¡¨"""
        try:
            # è·å–å·²ä¿å­˜åˆ°è®°å½•çš„ä»»åŠ¡
            saved_tasks = TestCaseGenerationTask.objects.filter(
                is_saved_to_records=True,
                status='completed'
            ).order_by('-saved_at')

            # åºåˆ—åŒ–æ•°æ®
            serializer = TestCaseGenerationTaskSerializer(saved_tasks, many=True)

            return Response({
                'message': 'è·å–å·²ä¿å­˜è®°å½•æˆåŠŸ',
                'records': serializer.data
            }, status=status.HTTP_200_OK)

        except Exception as e:
            logger.error(f"è·å–å·²ä¿å­˜è®°å½•æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'è·å–è®°å½•å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['post'], url_path='batch_adopt')
    def batch_adopt(self, request, task_id=None):
        """æ‰¹é‡é‡‡çº³ä»»åŠ¡çš„æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹"""
        try:
            task = self.get_object()

            if task.status != 'completed':
                return Response(
                    {'error': 'åªèƒ½é‡‡çº³å·²å®Œæˆçš„æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆä»»åŠ¡'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            if not task.final_test_cases:
                return Response(
                    {'error': 'æ²¡æœ‰æœ€ç»ˆæµ‹è¯•ç”¨ä¾‹å¯ä»¥é‡‡çº³'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # è§£ææœ€ç»ˆæµ‹è¯•ç”¨ä¾‹
            test_cases = self._parse_test_cases_content(task.final_test_cases)

            if not test_cases:
                return Response(
                    {'error': 'æ— æ³•è§£ææµ‹è¯•ç”¨ä¾‹å†…å®¹'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # å¯¼å…¥åˆ°testcasesåº”ç”¨ï¼ˆä½¿ç”¨ä¸å•æ¡é‡‡çº³ç›¸åŒçš„é€»è¾‘ï¼‰
            try:
                from apps.testcases.models import TestCase
                from apps.projects.models import Project
                from django.db import models

                # ä¼˜å…ˆä½¿ç”¨ä»»åŠ¡å…³è”çš„é¡¹ç›®
                if task.project:
                    project = task.project
                    logger.info(f"ä½¿ç”¨ä»»åŠ¡å…³è”çš„é¡¹ç›®: {project.name}")
                else:
                    # å›é€€åˆ°é¡¹ç›®é€‰æ‹©é€»è¾‘
                    user = task.created_by
                    accessible_projects = Project.objects.filter(
                        models.Q(owner=user) | models.Q(members=user)
                    ).distinct()

                    # å°è¯•ä»å‰ç«¯è·å–é¡¹ç›®ID
                    project_id = request.data.get('project_id')

                    if project_id:
                        try:
                            project = accessible_projects.get(id=project_id)
                        except Project.DoesNotExist:
                            # å¦‚æœæŒ‡å®šé¡¹ç›®ä¸å­˜åœ¨æˆ–æ— æƒé™ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯è®¿é—®çš„é¡¹ç›®
                            project = accessible_projects.first()
                            if not project:
                                # å¦‚æœç”¨æˆ·æ²¡æœ‰ä»»ä½•é¡¹ç›®ï¼Œåˆ›å»ºé»˜è®¤é¡¹ç›®
                                project = Project.objects.create(
                                    name="é»˜è®¤é¡¹ç›®",
                                    owner=user,
                                    description='ç³»ç»Ÿè‡ªåŠ¨åˆ›å»ºçš„é»˜è®¤é¡¹ç›®'
                                )
                    else:
                        # æ²¡æœ‰æŒ‡å®šé¡¹ç›®ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯è®¿é—®çš„é¡¹ç›®
                        project = accessible_projects.first()
                        if not project:
                            # å¦‚æœç”¨æˆ·æ²¡æœ‰ä»»ä½•é¡¹ç›®ï¼Œåˆ›å»ºé»˜è®¤é¡¹ç›®
                            project = Project.objects.create(
                                name="é»˜è®¤é¡¹ç›®",
                                owner=user,
                                description='ç³»ç»Ÿè‡ªåŠ¨åˆ›å»ºçš„é»˜è®¤é¡¹ç›®'
                            )

                adopted_count = 0
                for test_case in test_cases:
                    TestCase.objects.create(
                        project=project,  # ä½¿ç”¨ç»Ÿä¸€çš„é¡¹ç›®é€‰æ‹©é€»è¾‘
                        author=task.created_by,
                        title=test_case.get('scenario', 'æµ‹è¯•ç”¨ä¾‹'),
                        description=test_case.get('scenario', ''),  # ä½¿ç”¨scenarioä½œä¸ºæè¿°
                        preconditions=test_case.get('precondition', ''),
                        steps=test_case.get('steps', ''),
                        expected_result=test_case.get('expected', ''),
                        priority=self._map_priority(test_case.get('priority', 'ä¸­')),
                        test_type='functional',
                        status='draft'
                    )
                    adopted_count += 1

                return Response({
                    'message': f'æˆåŠŸé‡‡çº³ {adopted_count} æ¡æµ‹è¯•ç”¨ä¾‹åˆ°é¡¹ç›® "{project.name}"',
                    'adopted_count': adopted_count,
                    'project_name': project.name
                }, status=status.HTTP_200_OK)

            except Exception as import_error:
                logger.error(f"å¯¼å…¥æµ‹è¯•ç”¨ä¾‹å¤±è´¥: {import_error}")
                return Response(
                    {'error': f'å¯¼å…¥æµ‹è¯•ç”¨ä¾‹å¤±è´¥: {str(import_error)}'},
                    status=status.HTTP_500_INTERNAL_SERVER_ERROR
                )

        except Exception as e:
            logger.error(f"æ‰¹é‡é‡‡çº³æµ‹è¯•ç”¨ä¾‹æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'æ‰¹é‡é‡‡çº³å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['post'], url_path='batch-adopt-selected')
    def batch_adopt_selected(self, request, task_id=None):
        """æ‰¹é‡é‡‡çº³é€‰ä¸­çš„æµ‹è¯•ç”¨ä¾‹"""
        try:
            task = self.get_object()
            test_cases_data = request.data.get('test_cases', [])

            if not test_cases_data:
                return Response(
                    {'error': 'æ²¡æœ‰æä¾›è¦é‡‡çº³çš„æµ‹è¯•ç”¨ä¾‹æ•°æ®'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # å¯¼å…¥åˆ°testcasesåº”ç”¨
            try:
                from apps.testcases.models import TestCase
                from apps.projects.models import Project
                from django.db import models

                # ä¼˜å…ˆä½¿ç”¨ä»»åŠ¡å…³è”çš„é¡¹ç›®
                if task.project:
                    project = task.project
                    logger.info(f"ä½¿ç”¨ä»»åŠ¡å…³è”çš„é¡¹ç›®: {project.name}")
                else:
                    # å›é€€åˆ°é¡¹ç›®é€‰æ‹©é€»è¾‘
                    user = task.created_by
                    accessible_projects = Project.objects.filter(
                        models.Q(owner=user) | models.Q(members=user)
                    ).distinct()

                    # å°è¯•ä»å‰ç«¯è·å–é¡¹ç›®ID
                    project_id = request.data.get('project_id')

                    if project_id:
                        try:
                            project = accessible_projects.get(id=project_id)
                        except Project.DoesNotExist:
                            # å¦‚æœæŒ‡å®šé¡¹ç›®ä¸å­˜åœ¨æˆ–æ— æƒé™ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯è®¿é—®çš„é¡¹ç›®
                            project = accessible_projects.first()
                            if not project:
                                # å¦‚æœç”¨æˆ·æ²¡æœ‰ä»»ä½•é¡¹ç›®ï¼Œåˆ›å»ºé»˜è®¤é¡¹ç›®
                                project = Project.objects.create(
                                    name="é»˜è®¤é¡¹ç›®",
                                    owner=user,
                                    description='ç³»ç»Ÿè‡ªåŠ¨åˆ›å»ºçš„é»˜è®¤é¡¹ç›®'
                                )
                    else:
                        # æ²¡æœ‰æŒ‡å®šé¡¹ç›®ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªå¯è®¿é—®çš„é¡¹ç›®
                        project = accessible_projects.first()
                        if not project:
                            # å¦‚æœç”¨æˆ·æ²¡æœ‰ä»»ä½•é¡¹ç›®ï¼Œåˆ›å»ºé»˜è®¤é¡¹ç›®
                            project = Project.objects.create(
                                name="é»˜è®¤é¡¹ç›®",
                                owner=user,
                                description='ç³»ç»Ÿè‡ªåŠ¨åˆ›å»ºçš„é»˜è®¤é¡¹ç›®'
                            )

                adopted_count = 0
                for case_data in test_cases_data:
                    TestCase.objects.create(
                        project=project,  # ä½¿ç”¨ç»Ÿä¸€çš„é¡¹ç›®é€‰æ‹©é€»è¾‘
                        author=task.created_by,
                        title=case_data.get('title', 'æµ‹è¯•ç”¨ä¾‹'),
                        description=case_data.get('description', ''),
                        preconditions=case_data.get('preconditions', ''),
                        steps=case_data.get('steps', ''),
                        expected_result=case_data.get('expected_result', ''),
                        priority=case_data.get('priority', 'medium'),
                        test_type=case_data.get('test_type', 'functional'),
                        status=case_data.get('status', 'draft')
                    )
                    adopted_count += 1

                return Response({
                    'message': f'æˆåŠŸé‡‡çº³ {adopted_count} æ¡æµ‹è¯•ç”¨ä¾‹åˆ°é¡¹ç›® "{project.name}"',
                    'adopted_count': adopted_count,
                    'project_name': project.name
                }, status=status.HTTP_200_OK)

            except Exception as import_error:
                logger.error(f"å¯¼å…¥é€‰ä¸­æµ‹è¯•ç”¨ä¾‹å¤±è´¥: {import_error}")
                return Response(
                    {'error': f'å¯¼å…¥æµ‹è¯•ç”¨ä¾‹å¤±è´¥: {str(import_error)}'},
                    status=status.HTTP_500_INTERNAL_SERVER_ERROR
                )

        except Exception as e:
            logger.error(f"æ‰¹é‡é‡‡çº³é€‰ä¸­æµ‹è¯•ç”¨ä¾‹æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'æ‰¹é‡é‡‡çº³å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['post'], url_path='batch_discard')
    def batch_discard(self, request, task_id=None):
        """æ‰¹é‡å¼ƒç”¨ä»»åŠ¡çš„æ‰€æœ‰æµ‹è¯•ç”¨ä¾‹ - åˆ é™¤æ•´ä¸ªä»»åŠ¡"""
        try:
            task = self.get_object()

            logger.info(f"å¼€å§‹æ‰¹é‡å¼ƒç”¨ä»»åŠ¡ {task.task_id}")

            # ç›´æ¥åˆ é™¤æ•´ä¸ªä»»åŠ¡è®°å½•
            task.delete()

            return Response({
                'message': 'ä»»åŠ¡å·²è¢«å¼ƒç”¨å¹¶åˆ é™¤ï¼Œä¸ä¼šå†åœ¨åˆ—è¡¨ä¸­æ˜¾ç¤º'
            }, status=status.HTTP_200_OK)

        except Exception as e:
            logger.error(f"æ‰¹é‡å¼ƒç”¨ä»»åŠ¡æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'æ‰¹é‡å¼ƒç”¨å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['post'], url_path='discard-selected-cases')
    def discard_selected_cases(self, request, task_id=None):
        """å¼ƒç”¨é€‰ä¸­çš„æµ‹è¯•ç”¨ä¾‹ - ä»final_test_casesä¸­åˆ é™¤"""
        try:
            task = self.get_object()
            case_indices = request.data.get('case_indices', [])

            if not case_indices:
                return Response(
                    {'error': 'æ²¡æœ‰æä¾›è¦å¼ƒç”¨çš„æµ‹è¯•ç”¨ä¾‹ç´¢å¼•'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            if not task.final_test_cases:
                return Response(
                    {'error': 'ä»»åŠ¡æ²¡æœ‰æœ€ç»ˆæµ‹è¯•ç”¨ä¾‹'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            logger.info(f"å¼€å§‹å¼ƒç”¨ä»»åŠ¡ {task.task_id} çš„æµ‹è¯•ç”¨ä¾‹ï¼Œç´¢å¼•: {case_indices}")

            # è§£æç°æœ‰çš„æµ‹è¯•ç”¨ä¾‹
            test_cases = self._parse_test_cases_content(task.final_test_cases)

            # æŒ‰ç´¢å¼•ä»å¤§åˆ°å°æ’åºï¼Œé¿å…åˆ é™¤æ—¶ç´¢å¼•å˜åŒ–
            case_indices.sort(reverse=True)

            discarded_count = 0
            for index in case_indices:
                if 0 <= index < len(test_cases):
                    removed_case = test_cases.pop(index)
                    discarded_count += 1
                    logger.debug(f"å¼ƒç”¨æµ‹è¯•ç”¨ä¾‹ {index}: {removed_case.get('scenario', 'unknown')}")

            # å¦‚æœæ‰€æœ‰ç”¨ä¾‹éƒ½è¢«å¼ƒç”¨äº†ï¼Œåˆ é™¤æ•´ä¸ªä»»åŠ¡
            if not test_cases:
                logger.info(f"ä»»åŠ¡ {task.task_id} çš„æ‰€æœ‰ç”¨ä¾‹éƒ½è¢«å¼ƒç”¨ï¼Œåˆ é™¤ä»»åŠ¡")
                task.delete()
                return Response({
                    'message': f'å·²å¼ƒç”¨ {discarded_count} æ¡æµ‹è¯•ç”¨ä¾‹ï¼Œä»»åŠ¡å·²è¢«åˆ é™¤',
                    'discarded_count': discarded_count,
                    'task_deleted': True
                }, status=status.HTTP_200_OK)

            # é‡æ–°ç”Ÿæˆfinal_test_caseså†…å®¹
            task.final_test_cases = self._reconstruct_test_cases_content(test_cases)
            task.save()

            logger.debug(f"é‡æ„åçš„æµ‹è¯•ç”¨ä¾‹å†…å®¹: {task.final_test_cases[:200]}...")

            return Response({
                'message': f'å·²å¼ƒç”¨ {discarded_count} æ¡æµ‹è¯•ç”¨ä¾‹',
                'discarded_count': discarded_count,
                'remaining_cases': len(test_cases),
                'task_deleted': False,
                'updated_test_cases': task.final_test_cases
            }, status=status.HTTP_200_OK)

        except Exception as e:
            logger.error(f"å¼ƒç”¨é€‰ä¸­æµ‹è¯•ç”¨ä¾‹æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'å¼ƒç”¨å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['post'], url_path='discard-single-case')
    def discard_single_case(self, request, task_id=None):
        """å¼ƒç”¨å•ä¸ªæµ‹è¯•ç”¨ä¾‹"""
        try:
            task = self.get_object()
            case_index = request.data.get('case_index')

            if case_index is None:
                return Response(
                    {'error': 'æ²¡æœ‰æä¾›æµ‹è¯•ç”¨ä¾‹ç´¢å¼•'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            if not task.final_test_cases:
                return Response(
                    {'error': 'ä»»åŠ¡æ²¡æœ‰æœ€ç»ˆæµ‹è¯•ç”¨ä¾‹'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            logger.info(f"å¼€å§‹å¼ƒç”¨ä»»åŠ¡ {task.task_id} çš„å•ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼Œç´¢å¼•: {case_index}")

            # è§£æç°æœ‰çš„æµ‹è¯•ç”¨ä¾‹
            test_cases = self._parse_test_cases_content(task.final_test_cases)

            if case_index < 0 or case_index >= len(test_cases):
                return Response(
                    {'error': f'æµ‹è¯•ç”¨ä¾‹ç´¢å¼• {case_index} è¶…å‡ºèŒƒå›´ï¼Œæ€»å…±æœ‰ {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            # åˆ é™¤æŒ‡å®šç´¢å¼•çš„æµ‹è¯•ç”¨ä¾‹
            removed_case = test_cases.pop(case_index)
            logger.debug(f"å¼ƒç”¨æµ‹è¯•ç”¨ä¾‹ {case_index}: {removed_case.get('scenario', 'unknown')}")

            # å¦‚æœæ‰€æœ‰ç”¨ä¾‹éƒ½è¢«å¼ƒç”¨äº†ï¼Œåˆ é™¤æ•´ä¸ªä»»åŠ¡
            if not test_cases:
                logger.info(f"ä»»åŠ¡ {task.task_id} çš„æ‰€æœ‰ç”¨ä¾‹éƒ½è¢«å¼ƒç”¨ï¼Œåˆ é™¤ä»»åŠ¡")
                task.delete()
                return Response({
                    'message': 'å·²å¼ƒç”¨æµ‹è¯•ç”¨ä¾‹ï¼Œä»»åŠ¡å·²è¢«åˆ é™¤',
                    'discarded_count': 1,
                    'task_deleted': True
                }, status=status.HTTP_200_OK)

            # é‡æ–°ç”Ÿæˆfinal_test_caseså†…å®¹
            task.final_test_cases = self._reconstruct_test_cases_content(test_cases)
            task.save()

            logger.debug(f"å•ä¸ªå¼ƒç”¨ - é‡æ„åçš„æµ‹è¯•ç”¨ä¾‹å†…å®¹: {task.final_test_cases[:200]}...")

            return Response({
                'message': 'å·²å¼ƒç”¨æµ‹è¯•ç”¨ä¾‹',
                'discarded_count': 1,
                'remaining_cases': len(test_cases),
                'task_deleted': False,
                'updated_test_cases': task.final_test_cases
            }, status=status.HTTP_200_OK)

        except Exception as e:
            logger.error(f"å¼ƒç”¨å•ä¸ªæµ‹è¯•ç”¨ä¾‹æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'å¼ƒç”¨å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    @action(detail=True, methods=['post'], url_path='update-test-cases')
    def update_test_cases(self, request, task_id=None):
        """æ›´æ–°æµ‹è¯•ç”¨ä¾‹å†…å®¹"""
        try:
            task = self.get_object()

            final_test_cases = request.data.get('final_test_cases')
            if not final_test_cases:
                return Response(
                    {'error': 'ç¼ºå°‘final_test_caseså‚æ•°'},
                    status=status.HTTP_400_BAD_REQUEST
                )

            logger.info(f"å¼€å§‹æ›´æ–°ä»»åŠ¡ {task.task_id} çš„æµ‹è¯•ç”¨ä¾‹å†…å®¹")

            # æ›´æ–°final_test_caseså­—æ®µ
            task.final_test_cases = final_test_cases
            task.save(update_fields=['final_test_cases'])

            logger.info(f"ä»»åŠ¡ {task.task_id} æµ‹è¯•ç”¨ä¾‹æ›´æ–°æˆåŠŸ")

            return Response({
                'message': 'æµ‹è¯•ç”¨ä¾‹æ›´æ–°æˆåŠŸ',
                'task_id': task.task_id,
                'final_test_cases': task.final_test_cases
            }, status=status.HTTP_200_OK)

        except Exception as e:
            logger.error(f"æ›´æ–°æµ‹è¯•ç”¨ä¾‹æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'æ›´æ–°å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )

    def _parse_test_cases_content(self, content):
        """è§£ææµ‹è¯•ç”¨ä¾‹å†…å®¹ - æ”¯æŒå¤šç§æ ¼å¼"""
        if not content:
            return []

        # å»é™¤markdownåŠ ç²—æ ‡è®°ï¼Œä¿ç•™çº¯å‡€æ–‡æœ¬
        import re
        clean_content = re.sub(r'\*\*([^*]+)\*\*', r'\1', content)

        logger.info(f"å¼€å§‹è§£ææµ‹è¯•ç”¨ä¾‹å†…å®¹ï¼Œå†…å®¹é•¿åº¦: {len(clean_content)}")
        logger.info(f"å†…å®¹å‰200å­—ç¬¦: {clean_content[:200]}")

        # å°è¯•è¡¨æ ¼æ ¼å¼è§£æ
        if '|' in clean_content:
            return self._parse_table_format(clean_content)

        # å°è¯•ç»“æ„åŒ–æ–‡æœ¬æ ¼å¼è§£æ
        return self._parse_text_format(clean_content)

    def _parse_table_format(self, content):
        """è§£æè¡¨æ ¼æ ¼å¼çš„æµ‹è¯•ç”¨ä¾‹"""
        lines = [line.strip() for line in content.split('\n') if line.strip()]
        test_cases = []
        table_data = []

        # æå–è¡¨æ ¼æ•°æ®
        for line in lines:
            if '|' in line and not line.startswith('|-'):
                # é’ˆå¯¹å†…å®¹ä¸­å¯èƒ½åŒ…å«è½¬ä¹‰åçš„ \| è¿›è¡Œé¢„å¤„ç†
                # å…ˆæŠŠ \| æ›¿æ¢ä¸ºä¸€ä¸ªä¸´æ—¶å ä½ç¬¦ï¼Œåˆ†å‰²å®Œåå†æ›¿æ¢å›æ¥
                temp_placeholder = "___PIPE___"
                processed_line = line.replace(r'\|', temp_placeholder)
                
                # ç§»é™¤é¦–å°¾çš„ |
                if processed_line.startswith('|'):
                    processed_line = processed_line[1:]
                if processed_line.endswith('|'):
                    processed_line = processed_line[:-1]
                
                cells = []
                for cell in processed_line.split('|'):
                    # æ¢å¤åŸæ¥çš„è½¬ä¹‰ç®¡é“ç¬¦ï¼Œå¹¶æ¸…ç†ç©ºæ ¼
                    cell_content = cell.replace(temp_placeholder, '|').replace('&#124;', '|').strip()
                    cells.append(cell_content)
                    
                if len(cells) > 1:
                    table_data.append(cells)

        if len(table_data) < 2:
            return []

        # è§£æè¡¨å¤´å’Œæ•°æ®
        headers = [h.lower() for h in table_data[0]]
        logger.debug(f"è¡¨æ ¼æ ‡é¢˜: {headers}")

        for row in table_data[1:]:
            if len(row) < len(headers):
                continue

            test_case = {}
            for i, header in enumerate(headers):
                value = row[i] if i < len(row) else ''

                if any(keyword in header for keyword in ['ç¼–å·', 'id', 'åºå·', 'ç”¨ä¾‹id']):
                    test_case['caseId'] = value
                elif any(keyword in header for keyword in ['åœºæ™¯', 'æ ‡é¢˜', 'åç§°', 'title', 'scenario', 'æµ‹è¯•ç›®æ ‡']):
                    test_case['scenario'] = value
                elif any(keyword in header for keyword in ['å‰ç½®', 'å‰æ', 'precondition']):
                    test_case['precondition'] = value
                elif any(keyword in header for keyword in ['æ­¥éª¤', 'step', 'æµ‹è¯•æ­¥éª¤', 'æ“ä½œæ­¥éª¤']):
                    test_case['steps'] = value
                elif any(keyword in header for keyword in ['é¢„æœŸ', 'ç»“æœ', 'expected', 'result']):
                    test_case['expected'] = value
                elif any(keyword in header for keyword in ['ä¼˜å…ˆçº§', 'priority']):
                    test_case['priority'] = value

            if test_case.get('scenario') or test_case.get('steps'):
                test_cases.append(test_case)
                logger.debug(f"è§£æå‡ºè¡¨æ ¼æµ‹è¯•ç”¨ä¾‹: {test_case}")

        return test_cases

    def _parse_text_format(self, content):
        """è§£ææ–‡æœ¬æ ¼å¼çš„æµ‹è¯•ç”¨ä¾‹"""
        lines = content.split('\n')
        test_cases = []
        current_case = {}

        for line in lines:
            line = line.strip()
            if not line:
                continue

            logger.debug(f"å¤„ç†è¡Œ: {line}")

            # æ£€æµ‹æµ‹è¯•ç”¨ä¾‹å¼€å§‹
            is_case_start = (
                    'æµ‹è¯•ç”¨ä¾‹' in line or
                    'Test Case' in line or
                    line.startswith(('1.', '2.', '3.', '4.', '5.', '6.', '7.', '8.', '9.', '10.')) or
                    line.startswith(('ä¸€ã€', 'äºŒã€', 'ä¸‰ã€', 'å››ã€', 'äº”ã€')) or
                    bool(re.match(r'^\d+[\.\)ã€]', line))
            )

            if is_case_start:
                if current_case:
                    logger.debug(f"æ·»åŠ æµ‹è¯•ç”¨ä¾‹: {current_case}")
                    test_cases.append(current_case)

                # æ¸…ç†æ ‡é¢˜
                scenario = line
                scenario = scenario.replace('æµ‹è¯•ç”¨ä¾‹', '').replace('Test Case', '')
                scenario = scenario.replace(':', '').replace('ï¼š', '')
                scenario = re.sub(r'^\d+[\.\)ã€]\s*', '', scenario)
                scenario = scenario.strip()

                current_case = {'scenario': scenario}

            elif current_case:  # åªæœ‰åœ¨å·²ç»å¼€å§‹ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹åæ‰å¤„ç†å­—æ®µ
                # æ£€æµ‹å„ä¸ªå­—æ®µ
                if any(keyword in line for keyword in ['å‰ç½®æ¡ä»¶', 'å‰ææ¡ä»¶', 'å‰ç½®', 'å‰æ']):
                    current_case['precondition'] = self._extract_field_value(line)
                elif any(keyword in line for keyword in ['æµ‹è¯•æ­¥éª¤', 'æ“ä½œæ­¥éª¤', 'æ‰§è¡Œæ­¥éª¤', 'æ­¥éª¤']):
                    current_case['steps'] = self._extract_field_value(line)
                elif any(keyword in line for keyword in ['é¢„æœŸç»“æœ', 'æœŸæœ›ç»“æœ', 'é¢„æœŸ']):
                    current_case['expected'] = self._extract_field_value(line)
                elif 'ä¼˜å…ˆçº§' in line:
                    current_case['priority'] = self._extract_field_value(line)

        if current_case:
            logger.debug(f"æ·»åŠ æœ€åä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹: {current_case}")
            test_cases.append(current_case)

        logger.info(f"è§£æå®Œæˆï¼Œå…±è§£æå‡º {len(test_cases)} ä¸ªæµ‹è¯•ç”¨ä¾‹")
        for i, case in enumerate(test_cases):
            logger.debug(f"æµ‹è¯•ç”¨ä¾‹ {i + 1}: {case}")

        return test_cases

    def _extract_field_value(self, line):
        """æå–å­—æ®µå€¼"""
        # å°è¯•å¤šç§åˆ†éš”ç¬¦
        for sep in [':', 'ï¼š', 'ã€‘', 'ã€‘:', 'ã€‘ï¼š']:
            if sep in line:
                return line.split(sep, 1)[-1].strip()

        # å¦‚æœæ²¡æœ‰åˆ†éš”ç¬¦ï¼Œç§»é™¤å¸¸è§çš„å‰ç¼€
        for prefix in ['å‰ç½®æ¡ä»¶', 'æµ‹è¯•æ­¥éª¤', 'æ“ä½œæ­¥éª¤', 'é¢„æœŸç»“æœ', 'ä¼˜å…ˆçº§']:
            if line.startswith(prefix):
                return line[len(prefix):].strip()

        return line.strip()

    def _reconstruct_test_cases_content(self, test_cases):
        """é‡æ–°æ„å»ºæµ‹è¯•ç”¨ä¾‹å†…å®¹ - ä¿æŒåŸæœ‰æ ¼å¼å’Œç¼–å·"""
        if not test_cases:
            return ""

        # æ£€æŸ¥æ˜¯å¦æœ‰caseIdå­—æ®µï¼Œå¦‚æœæœ‰ï¼Œè¯´æ˜æ˜¯è¡¨æ ¼æ ¼å¼
        has_case_ids = any(test_case.get('caseId') for test_case in test_cases)

        if has_case_ids:
            # é‡æ„ä¸ºè¡¨æ ¼æ ¼å¼ï¼Œä¿æŒåŸæœ‰ç¼–å·
            return self._reconstruct_table_format(test_cases)
        else:
            # é‡æ„ä¸ºæ–‡æœ¬æ ¼å¼
            return self._reconstruct_text_format(test_cases)

    def _reconstruct_table_format(self, test_cases):
        """é‡æ„ä¸ºè¡¨æ ¼æ ¼å¼"""
        content_lines = []
        content_lines.append("```markdown")

        # æ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•æµ‹è¯•ç”¨ä¾‹åŒ…å«stepså­—æ®µ
        has_steps = any(
            test_case.get('steps') and test_case.get('steps') != 'å‚è€ƒæµ‹è¯•ç›®æ ‡æ‰§è¡Œç›¸åº”æ“ä½œ' for test_case in test_cases)

        if has_steps:
            # åŒ…å«æµ‹è¯•æ­¥éª¤çš„è¡¨æ ¼æ ¼å¼
            content_lines.append(
                "| ç”¨ä¾‹ID | æµ‹è¯•ç›®æ ‡ | å‰ç½®æ¡ä»¶ | æµ‹è¯•æ­¥éª¤ | é¢„æœŸç»“æœ | ä¼˜å…ˆçº§ | æµ‹è¯•ç±»å‹ | å…³è”éœ€æ±‚ |")
            content_lines.append("|--------|--------|--------|--------|--------|--------|--------|--------|")

            for test_case in test_cases:
                case_id = test_case.get('caseId', '')
                scenario = test_case.get('scenario', '')
                precondition = test_case.get('precondition', '')
                steps = test_case.get('steps', 'å‚è€ƒæµ‹è¯•ç›®æ ‡æ‰§è¡Œç›¸åº”æ“ä½œ')
                expected = test_case.get('expected', '')
                priority = test_case.get('priority', 'P2')

                # ä¿æŒåŸæœ‰æ ¼å¼ï¼Œå°†æ¢è¡Œç¬¦è½¬æ¢ä¸º<br>
                precondition = precondition.replace('\n', '<br>')
                steps = steps.replace('\n', '<br>')
                expected = expected.replace('\n', '<br>')

                content_lines.append(
                    f"| {case_id} | {scenario} | {precondition} | {steps} | {expected} | {priority} | åŠŸèƒ½éªŒè¯ | éœ€æ±‚1 |")
        else:
            # åŸå§‹æ ¼å¼ï¼ˆæ²¡æœ‰æµ‹è¯•æ­¥éª¤åˆ—ï¼‰
            content_lines.append("| ç”¨ä¾‹ID | æµ‹è¯•ç›®æ ‡ | å‰ç½®æ¡ä»¶ | é¢„æœŸç»“æœ | ä¼˜å…ˆçº§ | æµ‹è¯•ç±»å‹ | å…³è”éœ€æ±‚ |")
            content_lines.append("|--------|--------|--------|--------|--------|--------|--------|")

            for test_case in test_cases:
                case_id = test_case.get('caseId', '')
                scenario = test_case.get('scenario', '')
                precondition = test_case.get('precondition', '')
                expected = test_case.get('expected', '')
                priority = test_case.get('priority', 'P2')

                # ä¿æŒåŸæœ‰æ ¼å¼ï¼Œå°†æ¢è¡Œç¬¦è½¬æ¢ä¸º<br>
                precondition = precondition.replace('\n', '<br>')
                expected = expected.replace('\n', '<br>')

                content_lines.append(
                    f"| {case_id} | {scenario} | {precondition} | {expected} | {priority} | åŠŸèƒ½éªŒè¯ | éœ€æ±‚1 |")

        content_lines.append("```")
        return "\n".join(content_lines)

    def _reconstruct_text_format(self, test_cases):
        """é‡æ„ä¸ºæ–‡æœ¬æ ¼å¼"""
        content_lines = []
        for test_case in test_cases:
            # è·å–åŸæœ‰çš„scenario
            scenario = test_case.get('scenario', 'æœªå‘½åæµ‹è¯•ç”¨ä¾‹')

            # ç¡®ä¿scenarioèƒ½è¢«å‰ç«¯æ­£ç¡®è¯†åˆ«
            # å¦‚æœscenarioä¸æ˜¯ä»¥æ•°å­—å¼€å¤´æˆ–ä¸åŒ…å«"æµ‹è¯•ç”¨ä¾‹"ï¼Œåˆ™æ·»åŠ æ ‡è¯†
            if not (bool(re.match(r'^\d+[\.\)ã€]', scenario)) or
                    'æµ‹è¯•ç”¨ä¾‹' in scenario or
                    'Test Case' in scenario):
                # æ·»åŠ "æµ‹è¯•ç”¨ä¾‹:"å‰ç¼€ç¡®ä¿èƒ½è¢«è¯†åˆ«
                content_lines.append(f"\næµ‹è¯•ç”¨ä¾‹: {scenario}")
            else:
                content_lines.append(f"\n{scenario}")

            if test_case.get('precondition'):
                content_lines.append(f"å‰ç½®æ¡ä»¶: {test_case['precondition']}")

            if test_case.get('steps'):
                content_lines.append(f"æµ‹è¯•æ­¥éª¤: {test_case['steps']}")

            if test_case.get('expected'):
                content_lines.append(f"é¢„æœŸç»“æœ: {test_case['expected']}")

            if test_case.get('priority'):
                content_lines.append(f"ä¼˜å…ˆçº§: {test_case['priority']}")

            content_lines.append("")  # ç©ºè¡Œåˆ†éš”

        return "\n".join(content_lines)

    def _map_priority(self, priority_str):
        """æ˜ å°„ä¼˜å…ˆçº§"""
        priority_map = {
            'æœ€é«˜': 'critical',
            'é«˜': 'high',
            'ä¸­': 'medium',
            'ä½': 'low',
            'P0': 'critical',
            'P1': 'high',
            'P2': 'medium',
            'P3': 'low'
        }
        return priority_map.get(priority_str, 'medium')

    @action(detail=False, methods=['get'])
    def statistics(self, request):
        """è·å–æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆä»»åŠ¡çš„ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # è·å–æŸ¥è¯¢å‚æ•°
            status_param = request.query_params.get('status')
            created_by = request.query_params.get('created_by')
            
            # æ„å»ºæŸ¥è¯¢
            queryset = TestCaseGenerationTask.objects.all()
            
            if status_param:
                queryset = queryset.filter(status=status_param)
            
            if created_by:
                queryset = queryset.filter(created_by_id=created_by)
            
            # ä½¿ç”¨èšåˆæŸ¥è¯¢è·å–ç»Ÿè®¡ä¿¡æ¯
            from django.db.models import Count
            
            stats = queryset.aggregate(
                total=Count('id'),
                completed=Count('id', filter=models.Q(status='completed')),
                pending=Count('id', filter=models.Q(status='pending')),
                generating=Count('id', filter=models.Q(status='generating')),
                reviewing=Count('id', filter=models.Q(status='reviewing')),
                revising=Count('id', filter=models.Q(status='revising')),
                failed=Count('id', filter=models.Q(status='failed')),
                cancelled=Count('id', filter=models.Q(status='cancelled'))
            )
            
            # è®¡ç®—è¿è¡Œä¸­çš„ä»»åŠ¡ï¼ˆpending + generating + reviewing + revisingï¼‰
            stats['running'] = (
                stats['pending'] + stats['generating'] + 
                stats['reviewing'] + stats['revising']
            )
            
            return Response({
                'total': stats['total'],
                'completed': stats['completed'],
                'running': stats['running'],
                'failed': stats['failed'],
                'pending': stats['pending'],
                'generating': stats['generating'],
                'reviewing': stats['reviewing'],
                'revising': stats['revising'],
                'cancelled': stats['cancelled']
            }, status=status.HTTP_200_OK)
            
        except Exception as e:
            logger.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return Response(
                {'error': f'è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {str(e)}'},
                status=status.HTTP_500_INTERNAL_SERVER_ERROR
            )


class ConfigStatusViewSet(viewsets.ViewSet):
    """é…ç½®çŠ¶æ€æ£€æŸ¥è§†å›¾é›†"""
    permission_classes = []  # å…è®¸æœªè®¤è¯ç”¨æˆ·è®¿é—®

    @action(detail=False, methods=['get'])
    def check(self, request):
        """æ£€æŸ¥AIé…ç½®çŠ¶æ€"""
        try:
            # æ£€æŸ¥AIæ¨¡å‹é…ç½®
            ai_model_configs = AIModelConfig.objects.filter(
                role__in=['writer', 'reviewer']
            ).exclude(role__in=['browser_use_text', 'browser_use_vision'])

            # æ£€æŸ¥writeræ¨¡å‹é…ç½®
            writer_model_enabled = ai_model_configs.filter(
                role='writer',
                is_active=True
            ).first()

            writer_model_disabled = ai_model_configs.filter(
                role='writer',
                is_active=False
            ).first()

            # æ£€æŸ¥revieweræ¨¡å‹é…ç½®
            reviewer_model_enabled = ai_model_configs.filter(
                role='reviewer',
                is_active=True
            ).first()

            reviewer_model_disabled = ai_model_configs.filter(
                role='reviewer',
                is_active=False
            ).first()

            # æ£€æŸ¥writeræç¤ºè¯é…ç½®
            writer_prompt_enabled = PromptConfig.objects.filter(
                prompt_type='writer',
                is_active=True
            ).first()

            writer_prompt_disabled = PromptConfig.objects.filter(
                prompt_type='writer',
                is_active=False
            ).first()

            # æ£€æŸ¥revieweræç¤ºè¯é…ç½®
            reviewer_prompt_enabled = PromptConfig.objects.filter(
                prompt_type='reviewer',
                is_active=True
            ).first()

            reviewer_prompt_disabled = PromptConfig.objects.filter(
                prompt_type='reviewer',
                is_active=False
            ).first()

            # åˆ¤æ–­å¿…éœ€é…ç½®ï¼ˆwriterï¼‰
            writer_configured = (
                    writer_model_enabled is not None and
                    writer_prompt_enabled is not None
            )

            # åˆ¤æ–­å¯é€‰é…ç½®ï¼ˆreviewerï¼‰
            reviewer_configured = (
                    reviewer_model_enabled is not None and
                    reviewer_prompt_enabled is not None
            )

            # æ£€æŸ¥ç”Ÿæˆè¡Œä¸ºé…ç½®
            generation_config = GenerationConfig.get_active_config()

            # åˆ¤æ–­æ˜¯å¦æœ‰ç¦ç”¨çš„é…ç½®
            has_disabled = (
                    writer_model_disabled is not None or
                    writer_prompt_disabled is not None or
                    reviewer_model_disabled is not None or
                    reviewer_prompt_disabled is not None
            )

            # åˆ¤æ–­æ•´ä½“çŠ¶æ€
            if writer_configured:
                if has_disabled:
                    overall_status = 'disabled'
                    message = 'é…ç½®å®Œæ•´ï¼Œä½†éƒ¨åˆ†é…ç½®å¤„äºç¦ç”¨çŠ¶æ€'
                else:
                    overall_status = 'enabled'
                    message = 'é…ç½®å®Œæ•´ä¸”å·²å¯ç”¨'
            else:
                # writeré…ç½®ä¸å®Œæ•´
                if writer_model_enabled or writer_prompt_enabled:
                    overall_status = 'disabled'
                    message = 'æ£€æµ‹åˆ°å·²é…ç½®ä½†æœªå¯ç”¨çš„é…ç½®'
                else:
                    overall_status = 'not_configured'
                    message = 'å°šæœªé…ç½®AIæ¨¡å‹å’Œæç¤ºè¯'

            # æ„å»ºè¿”å›æ•°æ®
            response_data = {
                'overall_status': overall_status,
                'message': message,
                'writer_model': {
                    'configured': writer_model_enabled is not None or writer_model_disabled is not None,
                    'enabled': writer_model_enabled is not None,
                    'name': (writer_model_enabled or writer_model_disabled).name if (
                                writer_model_enabled or writer_model_disabled) else None,
                    'provider': (writer_model_enabled or writer_model_disabled).get_model_type_display() if (
                                writer_model_enabled or writer_model_disabled) else None,
                    'id': (writer_model_enabled or writer_model_disabled).id if (
                                writer_model_enabled or writer_model_disabled) else None,
                    'required': True
                },
                'writer_prompt': {
                    'configured': writer_prompt_enabled is not None or writer_prompt_disabled is not None,
                    'enabled': writer_prompt_enabled is not None,
                    'name': (writer_prompt_enabled or writer_prompt_disabled).name if (
                                writer_prompt_enabled or writer_prompt_disabled) else None,
                    'id': (writer_prompt_enabled or writer_prompt_disabled).id if (
                                writer_prompt_enabled or writer_prompt_disabled) else None,
                    'required': True
                },
                'reviewer_model': {
                    'configured': reviewer_model_enabled is not None or reviewer_model_disabled is not None,
                    'enabled': reviewer_model_enabled is not None,
                    'name': (reviewer_model_enabled or reviewer_model_disabled).name if (
                                reviewer_model_enabled or reviewer_model_disabled) else None,
                    'id': (reviewer_model_enabled or reviewer_model_disabled).id if (
                                reviewer_model_enabled or reviewer_model_disabled) else None,
                    'required': False
                },
                'reviewer_prompt': {
                    'configured': reviewer_prompt_enabled is not None or reviewer_prompt_disabled is not None,
                    'enabled': reviewer_prompt_enabled is not None,
                    'name': (reviewer_prompt_enabled or reviewer_prompt_disabled).name if (
                                reviewer_prompt_enabled or reviewer_prompt_disabled) else None,
                    'id': (reviewer_prompt_enabled or reviewer_prompt_disabled).id if (
                                reviewer_prompt_enabled or reviewer_prompt_disabled) else None,
                    'required': False
                },
                'generation_config': {
                    'configured': generation_config is not None,
                    'enabled': generation_config is not None,
                    'name': generation_config.name if generation_config else None,
                    'id': generation_config.id if generation_config else None,
                    'required': True,
                    'default_output_mode': generation_config.default_output_mode if generation_config else None,
                    'enable_auto_review': generation_config.enable_auto_review if generation_config else None
                }
            }

            return Response(response_data, status=status.HTTP_200_OK)

        except Exception as e:
            logger.error(f"æ£€æŸ¥é…ç½®çŠ¶æ€å¤±è´¥: {e}")
            return Response({
                'error': f'æ£€æŸ¥é…ç½®çŠ¶æ€å¤±è´¥: {str(e)}'
            }, status=status.HTTP_500_INTERNAL_SERVER_ERROR)